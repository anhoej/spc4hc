[["index.html", "Mastering Statistical Process Control Charts in Healthcare A practical, hands-on, step-by-step guide for data scientists using R What is Statistical Process Control?", " Mastering Statistical Process Control Charts in Healthcare A practical, hands-on, step-by-step guide for data scientists using R Jacob Anhøj &amp; Mohammed Amin Mohammed 2025-06-12 What is Statistical Process Control? This is the online version of Mastering Statistical Process Control Charts in Healthcare, a book currently under early development. The ultimate purpose of collecting and analysing data is to support better decision-making and actions that will lead to improvement. Statistical Process Control (SPC) is a proven methodology for doing just that. SPC methodology provides a philosophy and framework for continually learning about the behaviour of processes for analytical purposes – where the aim is to act on the underlying causes of variation to maintain or improve the performance of a process. SPC was initially developed by Walter A. Shewhart in the 1920s to improve the quality of manufactured products and has since been successfully used in many settings including healthcare. At is core, SPC methodology involves the plotting of data over time to detect unusual patterns or variations that might indicate a change or problem with a process. This simple graphical device is underpinned by an intuitive theory of variation, the hypothesis-generating testing-cycle of the scientific method, and statistical theory. To master SPC, it is essential to first understand the underlying theory of variation, which we explore in Part 1 of this book. Next, proficiency in using software to construct SPC charts is key, and this is covered in Part 2. In the later sections, we delve into specialized topics for more advanced SPC practitioners, offering deeper insights and expertise. "],["preface.html", "Preface What Sets This Book Apart? Prerequisites How to Use This Book About the Authors", " Preface This book is about the practical application of Statistical Process Control (SPC) methodology in healthcare. At its core, SPC is founded on a powerful, intuitive insight: processes are subject to two sources of variation – common cause and special cause. This distinction enables us to understand, monitor, and improve a wide range of processes. With this insight comes a suite of visual tools – run charts and control charts – that help differentiate between common and special cause variation with ease. However, while SPC tools are conceptually simple to use, applying them correctly can be a challenge. As noted in a systematic review of SPC in healthcare: … although SPC charts may be easy to use even for patients, clinicians, or managers without extensive SPC training, they may not be equally simple to construct correctly. To apply SPC is, paradoxically, both simple and difficult at the same time. – Thor et al. (2007) This book seeks to address this paradox by providing a straightforward, practical guide to the correct construction of SPC charts in healthcare using modern software. What Sets This Book Apart? This book is a step-by-step guide to easily and correctly producing SPC charts. Since this involves statistics, computing, and visualization, our software of choice is R – often referred to as the lingua franca of statistical computing and visualization. What makes this book unique is its specialized, practical, and modern approach, specifically tailored for data scientists and practitioners in the healthcare sector. Here’s what you can expect: Target audience This book is for anyone looking to produce SPC charts using modern tools. While it is specifically geared toward data scientists, we recognize that our readers may include analysts, practitioners, managers, educators, students, researchers, clinicians, or even patients. Regardless of your role, if you work with healthcare data and want to master SPC, then this book is for you. Why R? We’ve chosen R as our primary tool because it is popular, free, and open-source. While we are pro-R, we are not anti-other software; readers can adapt the concepts in this book to their preferred tools. R has several key advantages: Transparency and reproducibility: R’s programming capabilities ensure every step of data analysis and SPC chart construction is documented, making your work both readable and reproducible – something rarely achieved with “point-and-click” software. Automation: R allows for automating repetitive tasks such as generating monthly reports, slide decks, and SPC dashboards with customizable, high-quality graphics. Healthcare-focused Unlike general SPC books, this one focuses on healthcare-specific applications, addressing challenges like patient safety, clinical outcomes, and operational efficiency. It complements the foundational concepts in our companion book, Statistical Process Control: Elements of Improving Quality and Safety in Healthcare (M. A. Mohammed 2024). Practical and hands-on The book takes a hands-on approach, providing real-world examples and case studies to help readers produce and use SPC charts confidently. This practical emphasis bridges the gap between theory and application. Comprehensive coverage From foundational principles to advanced SPC techniques, this book covers it all. It’s designed to cater to both beginners and experienced data scientists, ensuring everyone finds value. Additional resources Readers will gain access to supplemental materials, including: R scripts Datasets A dedicated GitHub repository for continued learning and collaboration. Prerequisites No prior knowledge of SPC is assumed. However, basic familiarity with R is necessary to follow the steps and algorithms for constructing SPC charts. For those new to R, we recommend excellent (and free) resources such as the NHS-R Community. How to Use This Book New to SPC?: Start with Chapter 1 to learn about variation. Eager to start plotting?: Jump straight to Chapters 5 and 6. Want to go deeper?: Advanced chart types and topics are covered in later chapters for both beginners and experts. Need more resources?: Visit our GitHub repository for datasets, code, and updates. We hope this book proves valuable, and we welcome your feedback for ongoing improvement. About the Authors Jacob Anhøj: Medical doctor with over 30 years of experience and a diploma in Information Technology. With 45+ published papers, two books, and extensive teaching expertise, he is deeply passionate about patient safety and quality improvement in healthcare. Jacob is an experienced R user and the creator of several R packages, including qicharts2, widely used for SPC chart construction and analysis. Contact: jacob@anhoej.net Mohammed Amin Mohammed: Emeritus Professor of Healthcare Quality and Effectiveness at the University of Bradford, Mohammed has over 100 peer-reviewed publications. His landmark paper introducing SPC to healthcare (M. A. Mohammed, Cheng, and Marshall 2001) and his book Statistical Process Control: Elements of Improving Quality and Safety in Healthcare (M. A. Mohammed 2024) are seminal works in the field. He is also the founder of the NHS-R Community, promoting the use of R in healthcare. Contact: profmaminm@gmail.com; m.a.mohammed5@bradford.ac.uk References Mohammed, M A. 2024. Statistical Process Control. Elements of Improving Quality and Safety in Healthcare. Cambridge University Press. https://www.cambridge.org/core/elements/statistical-process-control/60B6025BF62017A9A203960A9E223C10. Mohammed, M A, Rouse Cheng KK, and T Marshall. 2001. “Bristol, Shipman, and Clinical Governance: Shewhart’s Forgotten Lessons.” Lancet 357. https://doi.org/10.1016/s0140-6736(00)04019-8. Thor, Johan, Jonas Lundberg, Jakob Ask, Jesper Olsson, Cheryl Carli, Karin Pukk Härenstam, and Mats Brommels. 2007. “Application of Statistical Process Control in Healthcare Improvement: Systematic Review.” BMJ Qual Saf 16: 387–99. https://doi.org/10.1136/qshc.2006.022194. "],["synopsis.html", "Synopsis Introduction Part 1: Understanding Variation Part 2: Constructing SPC Charts with R Part 3: Case Studies and Worked Examples Part 4: Advanced SPC Techniques Part 5: Best Practices, Controversies, and Tips Part 6: Conclusion and Final Thoughts Appendices", " Synopsis Introduction What is SPC? Preface Synopsis Part 1: Understanding Variation Understanding Variation Understanding SPC Charts Looking for Signals Charts Without Borders – using runs analysis as stand-alone rules with run charts Using SPC in Healthcare Part 2: Constructing SPC Charts with R Your First SPC Charts with Base R Calculating Control Limits Highlighting Freaks, Shifts, and Trends Core R Functions to Construct SPC Charts SPC Charts with ggplot2 Introducing qicharts2 Part 3: Case Studies and Worked Examples Case 1 Case 2 Case 3 Part 4: Advanced SPC Techniques Screened I Chart (eliminating freak moving ranges before calculating limits) SPC Charts for Rare Events T Charts for Time Between Events G Charts for Opportunities Between Cases Bernoulli CUSUM charts for binary data Prime Charts for Count Data with Very Large Subgroups I Prime Chart for Measurement Data With Variable Subgroup Sizes Funnel Plots for Categorical Subgroups Pareto Charts for Ranking Problems Dual charting (omit?) Part 5: Best Practices, Controversies, and Tips Tips for Effective SPC Implementation Automating production of SPC charts Engaging stakeholders Continuous monitoring and improvement. Problems and challenges with SPC Common Pitfalls to Avoid Data issues, misinterpretation of charts Overreacting to common cause variation (over-sensitive runs rules, too tight control limits) Automating recalculation of control limits One-to-one relation between PDSA cycles and dots on the plot The Control Charts vs Run Charts Debate A Note on Rational Subgrouping and Sampling High Volume Data Scaling Up Charts (technical issues, tabular charts, grids) When to Transform Data Before Plotting (omit?) Part 6: Conclusion and Final Thoughts Summary of Key Points Emerging trends in SPC and healthcare analytics Encouragement for Continuous Learning and Application Final Thoughts Appendices Included Data Sets Basic Statistical Concepts Diagnostic Properties of SPC Charts (Two Types of Errors When Using SPC) A Note on R Table of Critical Values for Longest Runs and Number of Crossings Resources and Further Readings Glossary of Terms Ideas for chapters / topics Improved Runs Analysis Using the Bestbox and Cutbox approaches CUSUM and EWMA Charts Multivariate charts Ideas for papers: RAGs to RICHes (two voices) Big data issues – CUSUM vs 3000 SPC charts Improved I chart The problem with SPC "],["variation.html", "Chapter 1 Understanding Variation 1.1 SPC and the nature of variation", " Chapter 1 Understanding Variation Imagine writing the letter a by hand using pen and paper. Figure 1.1 shows eight instances of this letter written by one of the authors. The first seven letters were produced with the dominant (right) hand, while the last one was written with the non-dominant hand. Figure 1.1: Hanwritten a’s Consider the seven leftmost a’s. Although these a’s were produced under identical conditions – same hand, date, time, place, pen, paper, temperature, lighting, and other factors – they are not identical. Instead, they exhibit controlled variation. This illustrates that a stable process, where the underlying conditions are the same, produces some degree of variation or “noise”. This controlled variation is known as common cause variation because it is caused by a stable process. When examining common cause variation, one might be tempted to rank the letters, identifying some as “better” or “worse” and attempting to emulate the best while avoiding the worst. However, this approach is misguided. Because all seven letters were produced under the same conditions, no single letter is inherently superior or inferior. From the process perspective, these seven letters are equivalent, and their differences are attributable to common cause variation – variation intrinsic to the process itself. So how can we improve these a’s? To improve the quality of the a’s we should focus on modifying the process rather than trying to draw lessons from the differences between individual a’s. To reduce variation and improve the quality of the letter a, we might consider changes such as using a different pen, paper, or training, or switching to a computer. Of these options, it is intuitive that using a computer will yield the most significant improvement. This insight is supported by the theory of constraints, which views a process as a chain of interconnected links. The strength of the entire chain is limited by its weakest link. Improving this weakest link will enhance the overall performance, while changes to other, non-constraint links, offer minimal benefit. In the context of handwriting, the weakest link is the manual use of the hand. The pen, paper, and lighting are not constraints in this process; altering them will not substantially impact the quality of the ‘a’. Switching to a computer addresses the key constraint, handwriting, resulting in a marked improvement in the quality of the letter. Now consider the rightmost letter in Figure 1.1, produced with the non-dominant hand. Its marked difference from the others suggests a special cause. Special cause variation arises from factors external to the usual process and requires investigation. When encountering special cause variation, the response involves detective work to identify the underlying cause. If the special cause undermines the quality of the process, efforts should focus on eliminating it. If the special cause enhances the quality of the process, then efforts should focus on trying to understand it and integrate it into the process where possible. The handwritten letters exemplify the two types of variation: Common Cause Variation: Intrinsic to the process, this variation is stable and predictable within a range. Addressing it requires systemic changes to the process as a whole. Special Cause Variation: Arising from external factors, this variation is unpredictable and requires investigation. The response depends on whether the variation is beneficial or harmful. In summary then, the handwritten a’s demonstrate that a process exhibits two types of variation –- common cause and special cause – and the action required to address each type of cause is fundamentally different. To address common cause variation, we must take action on a major portion of the process. To address special cause variation, we must first do some detective work to find the cause and then we can decide to eradicate that cause (if it is unfavourable) or keep it (if it is favourable). The originator of this theory was Walter A. Shewhart, who, in the 1920s, sought to improve industrial product quality. Shewhart recognized that quality involves more than meeting specifications; it requires understanding and managing variation. He distinguished between common cause variation, inherent to a stable process, and special cause variation, which results from specific, external factors (Shewhart 1931). There are various characteristics and descriptions of common and special cause variation which are highlighted below. Characteristics of common versus special cause variation Common Cause Variation Special Cause Variation Is caused by a stable process (like writing a signature) and is intrinsic to the process. Is caused by an assignable cause that it extrinsic to the process. Reflects the voice or behaviour of a stable process and affects all those who are part of the process. Is a distinct signal which differs from the usual voice or behaviour of the process and requires further detective work to identify the assignable cause. Is neither good or bad, it just is. Can be favourable or unfavourable and premediated (as part of an improvement project) or incidental (not part of an improvement project) Can be reduced (but not eliminated) by changing the underlying process. Such changes may be informed by special cause variation. Unfavourable special cause can be eliminated. Favourable special cause can be adopted and adapted into a new process. Is sometimes referred to as random variation, chance variation, or noise. Is sometimes referred to as non-random variation, systematic variation, or signal. 1.1 SPC and the nature of variation Statistical Process Control (SPC) revolves around understanding variation and identifying its causes – whether common or special – in order to drive meaningful improvement. Contrary to common misconceptions, SPC is not merely a method for spotting outliers; it’s a framework for enhancing processes and outcomes. Statistical Process Control is not about statistics, it is not about ‘process-hyphen-control’, and it is not about conformance to specifications. […] It is about the continual improvement of processes and outcomes. And it is, first and foremost, a way of thinking with some tools attached. – Wheeler (2000), p. 152 With this foundation in mind, most of this book focuses on the tools of SPC, particularly the SPC chart. In the next chapter, we delve into the “anatomy and physiology” of SPC charts, exploring their structure, function, and practical applications. References Shewhart, Walther A. 1931. Economic Control of Quality of Manufactured Product. New York: D. Van Nostrand Company. Wheeler, Donald J. 2000. Understanding Variation – the Key to Managing Chaos. Knoxville, Tennessee: SPC Press. "],["charts-intro.html", "Chapter 2 Understanding SPC Charts 2.1 Anatomy and physiology of SPC charts 2.2 Why 3-sigma limits? 2.3 Some common types of control charts: The Magnificent Seven 2.4 Summary of common SPC charts", " Chapter 2 Understanding SPC Charts Now that we’ve explored the concepts of common and special cause variation through the example of handwritten letters, the next step is understanding how to apply these ideas to healthcare processes. This application involves creating charts that represent the “voice” or behaviour of a process (usually) over time. By leveraging statistical theory, these charts help determine whether a process is exhibiting common or special cause variation. Such visualisations are known as SPC charts, control charts, or process behaviour charts. SPC charts are point-and-line plots of data collected over time. They serve as operational definitions for identifying common and special cause variation. An operational definition is one that is designed to be practical, useful, and ensures consistency in interpretation across different individuals. Figure 2.1: Control chart of systolic blood pressure Figure 2.1 illustrates a control chart showing daily blood pressure measurements. One data point (#6), marked with a red dot, stands out from the others. This deviation triggers a signal, indicating that the data point is likely due to a special cause. Special causes are signalled by unusual patterns in data. By “unusual” we mean something that is unlikely to have happened purely by chance, like a freak data point. Common cause variation is simply noise. The absence of signals of special cause variation is evidence that the behaviour of the process is consistent with common cause variation. The presence of signals is consistent with special cause variation. There are many different types of control charts and the chart to be used is determined mostly by the type of data to be plotted. But regardless of the type of data, (most) SPC charts look the same and are interpreted the same way, by employing a set of statistical tests (or rules) to help identify unusual patterns. In this chapter, we introduce seven of of the most common types of control charts (The Magnificent Seven) used in healthcare and their practical applications. In the following chapter (3), we delve into the rules and statistical tests for identifying unusual patterns in data. Later, in Part 2 of this book, we provide a detailed guide on performing the calculations necessary to construct and analyse control charts. 2.1 Anatomy and physiology of SPC charts Shewhart’s groundbreaking innovation was the introduction of control limits, which define the boundaries of common cause variation in data. Data points falling within these limits (without unusual patterns) indicate common cause variation, while those outside indicate special cause variation. Figure 2.2: Standardised control chart. SD = standard deviation; CL = centre line; LCL = lower control limit; UCL = upper control limit Figure 2.2 demonstrates a standardized Shewhart control chart, created using random numbers from a normal distribution with a mean of 0 and a standard deviation of 1. The x-axis represents time or sequence order, while the y-axis displays the indicator values. Each dot, connected by a line, represents a data point sampled sequentially. The data included in a data point is called a subgroup representing a set of observations (a sample) collected together at a specific point in time and under similar conditions. The chart features a Centre Line (CL), which represents the mean of the data values, and a Lower Control Limit (LCL) and an Upper Control Limit (UCL), defining the range of common cause variation. Because the control limits are (usually) positioned three standard deviations (sigma) on each side of the centre line they are often referred to as 3-sigma limits. The data points cluster symmetrically around the centre line, with most near the mean. As the distance from the centre line increases, data points become increasingly sparse. The control limits are positioned to encompass nearly all data points arising from common cause variation. Conversely, points outside the limits are likely to represent special causes. 2.2 Why 3-sigma limits? Shewhart’s choice of 3-sigma limits was based on empirical observations from real-world experiments. For data following a normal distribution, like in Figure 2.2, these limits contain about 99.7% of all data points, meaning the likelihood of a point falling outside the limits purely by chance is approximately 3 in 1000 (0.3%). In a control chart with a total of 20 data points the chance of all data points being within the control limits is about 95% (1 - 0.99720). But before we go down that rabbit hole we note that these theoretical considerations were rejected by Shewhart who found that most real-life data are not normally distributed. Shewhart argued that the choice of 3-sigma limits was made simply because they “work” (Shewhart (1931), p. 18), because this practical choice balances sensitivity (detecting special causes) with specificity (avoiding false alarms), regardless of the data type or distribution. More on this will be discussed in Appendix C. 2.3 Some common types of control charts: The Magnificent Seven As described above, the control limits are positioned at three standard deviations (SDs) above and below the centre line. Thus, all types of control charts follow this general formula for control lines: \\[CL \\pm 3SD\\] To construct a control chart, the essential components are the process mean and the process standard deviation. However, it is important to use the right standard deviation. Rather than using the overall SD of all data – which could include variation from special causes and artificially inflate the control limits – we rely on a pooled average of the within-subgroup SDs. This approach ensures that the calculated control limits reflect only the common cause variation inherent to the process. The exact method for determining the within-subgroup SD depends on the type of data being analysed. For readers eager to dive into the specifics, the formulas for constructing control limits can be found in Table 6.1 later in the book. Generally, data come in two flavours: count data and measurement data. 2.3.1 Counts Counts are positive integers representing the number of events or cases. While the distinction between events and cases may seem subtle, it is crucial for accurate analysis: Events are occurrences that happen in time and space, such as patient falls. Cases refer to individual units possessing (or lacking) a particular attribute, such as patients who have fallen. When counting events, every occurrence is recorded. For example, if a patient falls multiple times, each fall is counted as a separate event. In contrast, when counting cases, each unit (e.g. the patient) is counted only once, regardless of how many times the event (e.g. the fall) occurred for that individual. Both events and cases can be expressed as ratios, which are counts divided by a relevant denominator, also known as the area of opportunity. However, the way these ratios are constructed depends on whether we are analysing events or cases. Rates: Events are often expressed as rates, calculated as the number of events per unit of time. For instance, the rate of falls might be expressed as the number of falls per 1,000 patient-days. The denominator is a continuous variable (e.g., time) and is inherently different from the numerator, which counts discrete events. Proportions: Cases are expressed as proportions or percentages, calculated as the number of cases divided by the total number of cases and non-cases. For example, the proportion of patients who fell might represent the percentage of patients who experienced one or more falls. The numerator and denominator represent the same category of count (e.g., patients). The numerator is always a subset of the denominator, meaning it cannot exceed the denominator. The most common chart types for count data are: C chart: count of events, e.g. number of patient falls. U chart: event rates, e.g. number of patient falls per unit of time. P chart: case proportions, e.g. proportion of patients who fell. 2.3.2 Measurements Measurements refer to data collected on continuous scales, often including decimals. Examples include blood pressure, height, weight, or waiting times. As an example, consider waiting or “door-to-needle” times. These may be plotted as either individual times where each data point represents one patient or as an average time for all patients in a certain period of time, for example an hour, day, week, or month. When producing SPC charts for measurement data, the choice of control chart depends on how the measurement data are grouped. For individual measurements, we use an I chart (also called an X chart) where each subgroup represents one individual measurement. The I chart is often used in combination with a Moving Range (MR) chart to plot the variability between consecutive individual measurements. For subgroup averages, we use an X-bar chart where subgroups consist of multiple measurements, such as the average of several patients’ waiting times within a given period. the X-bar chart is often used in combination with an S chart to plot the within-subgroup standard deviations, which helps visualize the variability within each subgroup. I and MR charts: individual measurement, subgroup size = 1. X-bar and S charts: multiple measurements, subgroup size &gt; 1. 2.4 Summary of common SPC charts A Shewhart control chart is a point-and-line plot of data over time, augmented by three horizontal lines: Centre line (CL): Represents the overall mean of the data. Lower control limit (LCL) and upper control limit (UCL): Define the boundaries of natural process variation. While there are various types of SPC charts tailored to different types of data, all share a consistent structure and behaviour. When choosing the right chart we must first decide what type of data we have, count data or measurement data: For count data: C chart: For event counts. U chart: For event rates (events per unit of time or opportunity). P chart: For proportions (cases as a subset of the total). For measurement data: I chart with MR chart: For individual measurements and moving ranges. X-bar chart with S chart: For subgroup averages and within-subgroup variability. In the next chapter, we will explore the rules and techniques used to detect signals of special causes. We will present a validated set of rules that achieve a high sensitivity to special cause variation while maintaining a reasonable false alarm rate. References Shewhart, Walther A. 1931. Economic Control of Quality of Manufactured Product. New York: D. Van Nostrand Company. "],["testing.html", "Chapter 3 Looking for Signals on SPC charts – Beyond the 3-Sigma Rule 3.1 Patterns of non-random variation in time series data 3.2 SPC rules 3.3 SPC charts without borders – using run charts 3.4 A practical approach to SPC analysis 3.5 SPC rules in summary", " Chapter 3 Looking for Signals on SPC charts – Beyond the 3-Sigma Rule Until now, we have primarily focused on Shewhart’s 3-sigma rule, which identifies special cause variation when one or more data points fall outside the control limits. The 3-sigma rule is effective at detecting large shifts in data. To illustrate: Large shifts (3 SDs): Imagine a process with data following a normal distribution that suddenly shifts upward by three standard deviations (SDs). In this case, the old upper control limit (UCL) would effectively become the new centre line (CL). Consequently, about 50% of subsequent data points would fall above the old UCL, providing a clear signal of the shift. Smaller shifts (1 SD): For a smaller shift of one standard deviation, the old UCL would align with the new 2-sigma limit. As a result, about 2.5% of future data points would exceed this line, signalling the shift but with less frequency. The 3-sigma rule’s sensitivity makes it an invaluable guide for identifying material, easily detectable changes in the behaviour of a process. However, for smaller, subtler shifts, additional rules or techniques are often necessary to ensure reliable detection whilst balancing the number of false alarms (Figure 3.1). Figure 3.1: Control chart with progressive shifts in data The performance of the 3-sigma rule has been studied extensively (see, for instance, Montgomery (2020) or Anhøj and Wentzel-Larsen (2018)). To summarize, the 3-sigma rule is most effective when detecting shifts in data of at least 1.5 to 2 standard deviations (SDs). Minor to moderate shifts may go undetected for significant periods. To increase the sensitivity of SPC charts to smaller shifts, a variety of additional rules have been proposed. However, before diving into these rules, it is important to first explore the different patterns in data that often signal the presence of special causes. 3.1 Patterns of non-random variation in time series data In the iconic Western Electric Handbook (Western Electric Company 1956) a variety of control chart patterns are described to assist engineers in interpreting control charts based on the notion that certain patterns often reflect specific causes. In our experience, the most common special cause patterns found in healthcare data are freaks, shifts, and trends. 3.1.1 Freaks A freak is a data point or a small number of data points that are distinctly different from the rest, as shown in Figure 3.2. By definition, freaks are transient – they appear suddenly and then disappear. Figure 3.2: Control chart with a large (2 SD) transient shift in data Freaks are often caused by data or sampling errors, but they can also result from temporary external factors influencing the process, such as shifts in patient case mix during a holiday season. In some cases, a freak may simply be a false alarm. 3.1.2 Shifts Shifts are caused by sudden and sustained changes in process behaviour as in Figure 3.3. Figure 3.3: Control chart with a minor (1 SD) sustained shift in data introduced at data point #16 In fact, in healthcare improvement we strive to induce shifts in the desired direction by improving the structures and procedures that are behind data. 3.1.3 Trends A trend is a gradual change in the process centre, as shown in Figure 3.4. Figure 3.4: Control chart with a trend in data While some texts define a trend more specifically as a series of data points moving consistently up or down, in this book we use the term in a broader sense to refer to any gradual shift in one direction. Trends occur when external forces are consistently influencing the data in one direction, particularly when this influence is continuous and cumulative. Trends are commonly observed when improvements are implemented incrementally, such as in large organizations. In such cases, sequential shifts in data at the department level may accumulate into a broader trend at the organizational level. 3.1.4 Other unusual patterns There are numerous other types of “unusual” or mixed patterns that may appear in data. However, based on our experience in healthcare, process improvement or deterioration is most commonly associated with freaks, shifts, or trends. Learning to recognize these patterns is essential for uncovering the underlying causes of change. That being said, depending on the context and the purpose of using SPC, it may be valuable to look for other types of patterns in the data. This is particularly true for cyclic or seasonal data, where specific patterns repeat based on time of day, week, month, or year (Jeppegaard et al. 2023). For example, excess mortality linked to weekend admissions might not present itself as a freak, shift, or trend, but it is still an important pattern to recognize in order to address the issue effectively. 3.2 SPC rules If patterns of special cause variation were always as clear as in the figures 3.2, 3.3, and 3.4 there would be no need for SPC. However, in practice, special causes often manifest in more subtle ways and so we use additional statistical tests or SPC rules that are designed to signal the presence, or rather the likelihood, of special cause variation. Many additional rules have been developed to identify minor shifts, trends, and other specific patterns in data. While it may seem tempting to apply all known rules to the data, it’s important to remember that the more tests we apply, the more signals we generate and this increases the risk of false alarms where common cause variation is mistakenly identified as special cause variation. Therefore, it is crucial to strike a balance: we must select as few rules as necessary to minimize false alarms while ensuring the detection of true special cause signals. This topic will be discussed in greater detail in the chapter on Diagnostic Errors later in this book. For this book, we will concentrate on two sets of rules that have been thoroughly studied and validated for their effectiveness. 3.2.1 Tests based on sigma limits The best known tests for special cause variation are probably the Western Electric Rules (WE) described in the Statistical Quality Control Handbook (Western Electric Company 1956). The WE rules consist of four simple tests that can be applied to control charts by visual inspection and are based on the identification of unusual patterns in the distribution of data points relative to the centre lines and the control limits. One or more points outside of the 3-sigma limits (Shewhart’s original 3-sigma rule). Two out of three successive points beyond a 2-sigma limit (two thirds of the distance between the centre line and the control line). Four out of five successive points beyond a 1-sigma limit. A run of eight successive points on one side of the centre line. We leave it to the reader to apply WE rules #2-#4 to figures 3.3 and 3.4. The WE rules have proven their worth during most of a century. One thing to notice though is that the WE rules are most effective with control charts that have between 20 and 30 data points. With fewer data points, they lose sensitivity (more false negatives), and with more data points they lose specificity (more false positives). WE rule #4 is independent of the sigma limits. It is based on assumptions regarding the length of runs on either side of the centre line. A run is defined as one or more successive data points on the same side of the centre line. Rules based on runs analysis are further discussed below. 3.2.2 Runs analysis – tests based on the distribution of data points around the centre line If we assume that the centre line divides the data into two halves, the probability of any data point falling above or below the centre is fifty-fifty. Similarly, the probability that two neighbouring points fall on the same or opposite side of the centre line is also fifty-fifty. By dichotomizing the data into runs of points either above or below a certain value – such as the centre line – we enter the realm of runs analysis. The fundamental idea behind runs analysis is that the length and number of runs in a random process are governed by natural laws, making them predictable within certain limits. In essence, when a process shifts or trends, runs tend to become longer and fewer. Therefore, we can design runs tests to detect unusually long or unusually few runs. The key question is: what constitutes “unusually” long or “unusually” few runs? To illustrate, imagine flipping a coin ten times. Would you be surprised to get three or four heads in a row? Probably not. But what if you got ten heads in a row? That would definitely be surprising. Now, imagine tossing the coin 100 times. Would a sequence of ten heads be surprising then? Probably not, because as the number of trials increases, the likelihood of observing a run of ten heads also increases. This intuitive understanding highlights that what constitutes an “unusually” long run depends on the total number of observations or subgroups. The more subgroups we have in our SPC chart, the longer the longest runs are likely to be. From practical experiments, some theoretical considerations (Anhøj and Olesen 2014; Anhøj 2015; Anhøj and Wentzel-Larsen 2018), and years of experience we suggest these two runs tests: Unusually long runs: A run is one or more consecutive data points on the same side of the centre line. Data points that fall directly on the centre line neither break nor contribute to the run. The upper 95% prediction limit for longest run in a random process is approximately \\(log_2(n)+3\\) (rounded to the nearest integer), where \\(n\\) is the number of useful data points (data points not on the centre line). For example, in a run chart with 24 useful data points a run of more than round(log2(24) + 3) = 8 would suggest a shift in the process (Schilling 2012). Unusually few crossings: Rather than counting the number of runs, we count the number of crossings, which by definition is one less than the number of runs. A crossing is when two consecutive data points are on opposite sides of the centre line. In a random process, the number of crossings follows a binomial distribution. The lower 5% prediction limit for number of crossings is found using the cumulative probability distribution, qbinom(p = 0.05, size = n - 1, prob = 0.5). Thus, in a run chart with 24 useful data points, fewer than qbinom(0.05, 24 - 1, 0.5) = 8 crossings would suggest that the process is shifting (Chen 2010). The two runs rules are two sides of the same coin – when runs get longer, crossings get fewer and vice versa – and either of them may signal special cause variation. Figure 3.3 has 24 data points, the longest run consists of 12 data points (#13 - #24), and the line crosses the centre line 9 times. Since the longest run is longer than expected, we may conclude that there is reason to believe that the process is shifting. In Figure 3.4 there are two long runs with 9 data points and only 5 crossings also suggesting that data are shifting. It is important to note that the tests themselves do not identify the specific types of patterns in the data, nor do they reveal the underlying causes of shifts or trends. The responsibility for interpreting the results lies with the data analyst and the individuals involved in the process. This is the topic of the next chapter (4). Critical values for longest runs and number of crossings for 10-100 data points are tabulated in Appendix E. Apart from being comparable in sensitivity and specificity to WE rules #2-#4 with 20-30 data points (Anhøj and Wentzel-Larsen 2018), these runs rules have some advantages: They do not depend on sigma limits and thus are useful as stand-alone rules with run charts (more on run charts in the next section). They adapt dynamically to the number of available data points, and can be applied to charts with as few as 10 and up to indefinitely many data points without losing sensitivity or specificity. In practice these runs rules may be used as alternatives to WE rules #2-#4 to help identify shifts and trends alongside the WE rule #1 for freaks. 3.3 SPC charts without borders – using run charts As discussed in the previous section, some rules rely solely on a single line representing the centre of the data. We assumed that the centre line divides the data into two equal halves. While the process average typically serves as a good representation of this centre, this assumption may not hold if the data are skewed. However, if we use the median instead of the mean, the assumption always holds true, because the median is by definition the middle value. So, what happens if we remove the sigma lines and use the median as the centre line? We get a run chart, which is one of the most valuable tools in quality improvement and control. Figure 3.5: Run chart Figure 3.5 is a run chart of the data from Figure 2.2. We notice that the centre line is a little different from the control chart because we have used the empirical median rather than the theoretical mean. Consequently, data are now evenly distributed around the centre line with 12 data points on each side. The longest run have 3 data points (#13-#15 and #22-#24), and the data line crosses the centre line 13 times. Since there are no unusually long runs and not unusually few crossing we conclude that this process shows no signs of persistent shifts in data. Figure 3.6 is a run chart with data from Figure 3.4 containing a trend. The runs analysis confirms our “analysis-by-eye” by finding two unusually long runs with 9 data points and unusually few crossings (4). Figure 3.6: Run chart with a trend Run charts are a lot easier to construct than are control charts. They do not make assumptions about the distribution of data. And they have better sensitivity to minor and moderate persistent shifts and trends than control charts based on only the 3-sigma rule. So why do we bother making control charts at all? In fact, we can only think of two reasons: 1) control charts quickly pick up large, possibly transient, shifts (for example freaks) that may go unnoticed by run charts, and 2) the control limits reflect the common cause variability of the process and hence define its capability, that is the process’ ability to meet specifications. Fortunately, we do not need to choose between run and control charts. In fact, they are good companions for use at different stages of quality improvement and control. 3.4 A practical approach to SPC analysis Before we move on, let’s take a moment to clarify the purpose of SPC charts. As we will explore in detail in the next chapter (see 4), SPC charts support two distinct purposes: process improvement and process monitoring. When we are focused on process improvement, our goal is to create sustained shifts in the desired direction. Shifts are expected in this context, as improvements often happen gradually. Since we aim for lasting changes, runs analysis is our primary tool to detect these shifts. In process monitoring, the objective is to maintain process stability, with no expected shifts in the data. Here, our focus is on detecting any signs of process deterioration as quickly as possible. For this, the 3-sigma rule is effective. To improve sensitivity to minor or moderate shifts, we may combine the 3-sigma rule with either the rest of the Western Electric (WE) rules or the two runs rules. However, we must be mindful that adding more tests increases the risk of false alarms. Regardless of the task, we recommend starting any SPC analysis with an “assumption-free” run chart, using the median as the centre line. If runs analysis indicates non-random variation, calculating sigma limits becomes meaningless, as these values are irrelevant when shifts are already evident. In such cases, the focus should shift to identifying special causes, rather than calculating control limits. If the goal is process improvement, we continue with the run chart until we observe significant and sustained improvement, leading to a new and better process. Once this new process stabilizes and appears set to continue, we may transition to monitoring mode by adding control limits and using the mean as the centre line. Process monitoring is appropriate when the process is stable (common cause variation only) and the outcome is satisfactory. If either condition is not met, we should return to improvement mode. 3.5 SPC rules in summary SPC rules are statistical tests designed to detect special cause variation in time series data. Given the variety of patterns that can indicate special causes, many rules have been developed. However, applying too many rules increases the risk of false alarms. Therefore, it is important to choose a small set of rules that strike a balance: maximizing the ability to detect true alarms (special causes) while minimizing false alarms. We recommend starting any SPC analysis with a median-based run chart and using the two runs rules to test for unusually long runs or an unusually small number of crossings. If, and only if, the runs analysis indicates random variation (no special cause), and the process outcome is stable and satisfactory, we may proceed to use the mean as the centre line and add control limits to help identify large shifts and freak data points more easily. References Anhøj, Jacob. 2015. “Diagnostic Value of Run Chart Analysis: Using Likelihood Ratios to Compare Run Chart Rules on Simulated Data Series.” PLoS ONE. https://doi.org/10.1371/journal.pone.0121349. Anhøj, Jacob, and Anne Vingaard Olesen. 2014. “Run Charts Revisited: A Simulation Study of Run Chart Rules for Detection of Non-Random Variation in Health Care Processes.” PLoS ONE. https://doi.org/10.1371/journal.pone.0113825. Anhøj, Jacob, and Tore Wentzel-Larsen. 2018. “Sense and Sensibility: On the Diagnostic Value of Control Chart Rules for Detection of Shifts in Time Series Data.” BMC Medical Research Methodology. https://doi.org/10.1186/s12874-018-0564-0. Chen, Zhenmin. 2010. “A Note on the Runs Test.” Model Assisted Statistics and Applications 5: 73–77. https://doi.org/10.3233/MAS-2010-0142. Jeppegaard, Maria, Steen C. Rasmussen, Jacob Anhøj, and Lone Krebs. 2023. “Winter, Spring, Summer or Fall: Temporal Patterns in Placenta-Mediated Pregnancy Complications—an Exploratory Analysis.” Gynecol Obstet 309: 1991–98. https://doi.org/https://doi.org/10.1007/s00404-023-07094-6. Montgomery, Douglas C. 2020. Introduction to Statistical Quality Control, Eighths Ed. Wiley. Schilling, Mark F. 2012. “The Surprising Predictability of Long Runs.” Mathematics Magazine 85: 141–49. https://doi.org/10.4169/math.mag.85.2.141. Western Electric Company. 1956. Statistical Quality Control Handbook. New York: Western Electric Company inc. "],["using.html", "Chapter 4 Using SPC in healthcare 4.1 Using SPC to monitor a process 4.2 Using SPC to improve a process 4.3 Successful use of SPC in healthcare", " Chapter 4 Using SPC in healthcare As briefly discussed in the previous chapter, in healthcare, we use SPC methodology in two main ways: Monitoring the behaviour or performance of an existing process (e.g. complications following surgery), or Improving an existing process (e.g. redesigning the pathway for patients with fractured hips). 4.1 Using SPC to monitor a process In the monitoring mode, the primary aim is to determine if a process is deteriorating which is usually indicated by signals of special cause variation where detective work is needed to find the cause and then eliminate it. Such detective work can be undertaken by using the Pyramid Model of Investigation described below. The key aim of using statistical process control charts to monitor healthcare processes is to ensure that quality and safety of care are adequate and not deteriorating. So when a signal of special cause variation is seen on a control chart monitoring a given outcome, investigation is necessary. However, the chosen method must recognise that the link between recorded outcomes and quality of care is complex, ambiguous and subject to multiple explanations (Lilford et al. 2004). Failure to do so may inadvertently contribute to premature conclusions and a blame culture that undermines the engagement of clinical staff and the credibility of statistical process control. As Rogers note: If monitoring schemes are to be accepted by those whose outcomes are being assessed, an atmosphere of constructive evaluation, not ‘blaming’ or ‘naming and shaming’, is essential as apparent poor performance could arise for a number of reasons that should be explored systematically. – Rogers et al. (2004) To address this need, M. A. Mohammed et al. (2004) proposed the Pyramid Model for Investigation of Special Cause Variation in healthcare – a systematic approach of hypothesis generation and testing based on five a priori candidate explanations for special cause variation: data, patient casemix, structure/resources, process of care, and carer(s) (Figure 4.1). Figure 4.1: Pyramid Model for Investigation These broad categories of candidate explanations are arranged from most likely (data) to least likely (carers), so offering a road map for the investigation that begins at the base of the pyramid and stops at the level that provides a credible, evidence-based explanation for the special cause. The first two layers of the model (data and casemix factors) provide a check on the validity of the data and casemix-adjusted analyses, whereas the remaining upper layers focus more on quality of care related issues. A proper investigation requires a team of people with expertise in each of the layers. Such a team is also likely to include those staff whose outcomes or data are being investigated, so that their insights and expertise can inform the investigation while also ensuring their buy-in to the investigation process. Basic steps for using the model are shown below. Form a multidisciplinary team that has expertise in each layer of the pyramid, with a decision-making process that allows them to judge the extent to which a credible cause or explanation has been found, based on hypothesis generation and testing. Guided by what type(s) of pattern(s) exist in data (freaks, shifts, trends, mixed, or cyclic patterns) candidate hypotheses are generated and tested starting from the lowest level of the Pyramid Model and proceeding to upper levels only if the preceding levels provide no adequate explanation for the special cause. A credible cause requires quantitative and qualitative evidence, which is used by the team to test hypotheses and reach closure. If no credible explanation can be found, then the only plausible conclusion is that the signal itself was a false signal. The types of questions that can be asked when undertaking the detective work are highlighted below. Data: Data quality issues, e.g. coding accuracy, reliability of charts, definitions, and completeness. Are the data coded correctly? Has there been a change in data coding practices (e.g. are there less experienced coders)? Is clinical documentation clear, complete, and consistent? Casemix: Although differences in casemix are accounted for in the calculation, it is possible that some residual confounding may remain. Are factors peculiar to this hospital not taken into account in the risk adjustment? Has the pattern of referrals to this hospital changed in a way not considered in risk adjustment? Structure or resource: Availability of beds, staff, and medical equipment; institutional processes. Has there been a change in the distribution of patients in the hospital, with more patients in this speciality spread throughout the hospital rather than concentrated in a particular unit? Has the physical environment or organisational structures changed? Process of care: Medical treatments, clinical pathways, patient admission and discharge policies. Has there been a change in the care being provided? Have new treatment guidelines been introduced? Professional staff/carers: Practice and treatment methods etc. Has there been a change in staffing for treatment of patients? Has a key staff member gained additional training and introduced a new method that has led to improved outcomes? 4.2 Using SPC to improve a process SPC is also used to support efforts to improve a process. In healthcare, this usually involves making small scale changes and measuring their impact on an SPC chart. In the improving mode, the primary aim is to determine if changes made to a process have been successful (or not). For example, in the handwriting process considered earlier, do we get better a’s after switching to a computer? This is determined by looking to see the impact of the change in the form of signals of special cause variation on an SPC chart (provided we have a creditable measure of “letter quality”). The degree of alignment between changes to the process and subsequent signals of special cause variation provide a story which qualitatively and quantitatively describes the impact of changes. Common cause variation can only be addressed by changing a major portion of the process. What do we mean by a major portion? The Theory of Constraints (Goldratt and Cox 2022) offers the analogy of a chain to demonstrate that the strength of the chain is determined by the weakest link. If we increase the strength of the weakest link the whole chain is strengthened. If we increase the strength of other links but not the weakest link, then the chain does not get stronger. The weakest link is the constraint on the performance of the system, and it is argued that in real systems there are usually only a few, perhaps one or two, constraining factors, all other factors are non-constraints. The Model for Improvement, proposed by Langley et al. (2009), is a widely used framework in healthcare to guide improvement efforts. It consists of three fundamental questions and the Plan-Do-Study-Act (PDSA) cycle. What are we trying to accomplish? This question defines the aim of the improvement effort, which should be specific, measurable, and time-bound along with a rationale for why this is important. How will we know that a change is an improvement? This question focuses on measurement. The team identifies key performance indicators and other metrics to assess whether the change has led to improvement. This includes balancing measures designed to capture unintended negative consequences from changing a system or process. What changes can we make that will result in improvement? This question explores potential change ideas or interventions that could lead to the desired improvement. These ideas are undertaken according to the PDSA Cycle, which is a method for iterative small-scale testing of changes: Plan: Develop a plan to test the change, including who, what, when, and where. Do: Implement the change on a small scale. Study: Analyze the results, focusing on the impact of the change. Act: Decide whether to adopt, modify, or abandon the change based on the results. There are other approaches to improvement in healthcare, such as Lean, Six Sigma, and Systems Engineering. The SPC chart can support each of these approaches because it offers a robust and insightful way to test the success of change ideas. 4.3 Successful use of SPC in healthcare The successful use of SPC in healthcare requires a number of factors which is more than the production of an SPC chart – especially in complex adaptive systems like healthcare. These factors include: engaging the stakeholders; forming a team; defining the aim; selecting the process of interest; defining the metrics of interest; ensuring that data can be reliably measured, collected and fed back; and establishing baseline performance – all in a culture of continual learning and improvement that is supported by the leadership team. To see examples of SPC in action in healthcare, please see M. A. Mohammed (2024). Nevertheless, it is important to note that SPC charts are not necessarily easy to construct. After examining 64 statistical process control charts, Koetsier et al. (2012) found that that almost half the charts had technical problems which suggests a need for more training for those constructing charts – which is the primary motivation for this book. This is the end of Part 1. In Part 2, beginning with Chapter 5, we show you how to produce SPC charts using R. References Goldratt, Eliyahu M., and Jeff Cox. 2022. The Goal: A Process of Ongoing Improvement, 3rd Edition. Routledge. Koetsier, A., S. N. van der Veer, K. J. Jager, N. Peek, and N. F. de Keizer. 2012. “Control Charts in Healthcare Quality Improvement.” Methods of Information in Medicine. https://doi.org/10.3414/ME11-01-0055. Langley, Gerald J, Ronald D Moen, Kevin M Nolan, Thomas W Nolan, Clifford L Norman, and Lloyd P Provost. 2009. The Improvement Guide. San Fracisco, CA: Jossey-bass. Lilford, Richard, Mohammed A Mohammed, David Spiegelhalter, and Richard Thomson. 2004. “Use and Misuse of Process and Outcome Data in Managing Performance of Acute Medical Care: Avoiding Institutional Stigma.” The Lancet 363: 1147–54. https://doi.org/https://doi.org/10.1016/S0140-6736(04)15901-1. Mohammed, M A. 2024. Statistical Process Control. Elements of Improving Quality and Safety in Healthcare. Cambridge University Press. https://www.cambridge.org/core/elements/statistical-process-control/60B6025BF62017A9A203960A9E223C10. Mohammed, M A, Anthony Rathbone, Paulette Myers, Divya Patel, Helen Onions, and Andrew Stevens. 2004. “An Investigation into General Practitioners Associated with High Patient Mortality Flagged up Through the Shipman Inquiry: Retrospective Analysis of Routine Data.” BMJ 328 (7454): 1474–77. https://doi.org/10.1136/bmj.328.7454.1474. Rogers, Chris A., Barnaby C. Reeves, Massimo Caputo, J. Saravana Ganesh, Robert S. Bonser, and Gianni D. Angelini. 2004. “Control Chart Methods for Monitoring Cardiac Surgical Performance and Their Interpretation.” The Journal of Thoracic and Cardiovascular Surgery 128: 811–19. https://doi.org/https://doi.org/10.1016/j.jtcvs.2004.03.011. "],["first-chart.html", "Chapter 5 Your First SPC Charts With Base R 5.1 A run chart of blood pressure data 5.2 Adding control limits to produce a control chart 5.3 That’s all, Folks!", " Chapter 5 Your First SPC Charts With Base R From Part 1 of this book we have a good grasp of what SPC is and how SPC charts work. In this chapter we will start constructing SPC charts using functions from base R. In later chapters we will include functions from ggplot2 and qicharts2 (an R package developed by JA). In essence, an SPC charts is a (point-and-)line plot of data over time with a horizontal line to represent the data centre and – in case of a control chart – two lines to represent the estimated upper and lower boundaries of the natural variation in data. 5.1 A run chart of blood pressure data Consider the data from Figure 2.1, which show systolic blood pressure measurements (mm Hg) for a patient taken in the morning over 26 consecutive days (M. A. Mohammed, Worthington, and Woodall 2008). systolic &lt;- c(169, 172, 175, 174, 161, 142, 174, 171, 168, 174, 180, 194, 161, 181, 175, 176, 186, 166, 157, 183, 177, 171, 185, 176, 181, 174) First we plot a simple point-and-line chart without any additional lines (Figure 5.1): # Make point-and-line plot plot(systolic, type = &#39;o&#39;) Figure 5.1: Simple run chart (As a side note, this reminds me (JA) of a manager, who once said to me: “You make such beautiful graphs, but can’t you stop them from going up and down all the time.” 😁) To guide the runs analysis we will add a horizontal centre line, which in run charts is usually the median of the data points (Figure 5.2): # Create systolic-coordinates for the centre line cl &lt;- median(systolic) # calculate median cl &lt;- rep(cl, length(systolic)) # repeat to match the length of y # Plot data and add centre line plot(systolic, type = &#39;o&#39;) lines(cl) Figure 5.2: Run chart with centre line We find that the longest run has 4 data points (#14-#17) and that the curve crosses the centre line 9 times. Four data points (#4, #7, #10, #26) lie directly on the centre line, so we have 22 useful observations. With 22 useful observations and using the two runs rules proposed in Chapter 3, the upper limit for longest run is 7 as is (coincidentally) the lower limit for number of crossings. Consequently, there are no signs of sustained shifts or trends in data over time. 5.2 Adding control limits to produce a control chart We use the same technique to add the lower and upper control limits. Remember that the control limits are usually set to \\(CL \\pm 3 SD\\), where CL is the centre line, usually the mean, and SD is the estimated standard deviation – that is, the standard deviation of the natural variation in data, not the pooled standard deviation that would include both common cause and any special cause variation. For data consisting of single measurements, we choose the I chart (see Chapter 2). To estimate the common cause standard deviation we use the average moving range divided by a constant, 1.128. The moving ranges are the absolute pairwise differences between consecutive data points. We will talk much more about control limits in Chapter 6. # Calulate the centre line (mean) cl &lt;- rep(mean(systolic), length(systolic)) # Calculate the moving ranges of data mr &lt;- abs(diff(systolic)) # Print the moving ranges for our viewing pleasure mr ## [1] 3 3 1 13 19 32 3 3 6 6 14 33 20 6 1 10 20 9 26 6 6 14 9 5 7 # Calculate the average moving range amr &lt;- mean(mr) # Calculate the process standard deviation s &lt;- amr / 1.128 # Create y-coordinates for the control limits lcl &lt;- cl - 3 * s ucl &lt;- cl + 3 * s When plotting data, we need to expand the y-axis limits to make room not only for the data points but also the control limits (Figure 5.3): # Plot data while expanding the y-axis to make room for all data and lines plot(systolic, type = &#39;o&#39;, ylim = range(systolic, lcl, ucl)) # Add lines lines(ucl) lines(cl) lines(lcl) Figure 5.3: Standardised control chart One (freak) data point is below the lower control limit suggesting that this reading has most likely been influenced by something outside the natural process. The control chart itself does not tell what caused the special cause, but it tells us that this data point should be investigated with the purpose of learning and improvement. 5.3 That’s all, Folks! So constructing an SPC chart using R may be done using a few lines of code. In fact, most of the code in this chapter went to prepare the data to be plotted. The charts themselves are rather simple and plotting is the same every time: 1. plot the dots; 2. add the lines. Later we will wrap all the steps in a function that automates the calculation of centre and control lines, highlights signals of non-random variation in data, and makes plots that are a lot nicer to look at than the rather crude ones we have produces so far. In the next chapter we will produce SPC charts that are most commonly used in healthcare, “The Magnificent Seven”. References Mohammed, M A, P Worthington, and W H Woodall. 2008. “Plotting Basic Control Charts: Tutorial Notes for Healthcare Practitioners.” BMJ Qual Saf 17 (2): 137–45. https://doi.org/10.1136/qshc.2004.012047. "],["limits.html", "Chapter 6 Calculating Control Limits 6.1 Introducing the spc() function 6.2 Formulas for calculation of control limits 6.3 Count data 6.4 Measurement data 6.5 Control limits in short Control chart constants", " Chapter 6 Calculating Control Limits In the previous chapter we established the basis for constructing SPC charts with R using the I chart as an example. In this chapter we continue with the rest of The Magnificent Seven control charts and how to construct their control limits. 6.1 Introducing the spc() function To avoid repeating ourselves, let’s begin by creating a function to automate the plotting for us. spc &lt;- function( x, # x axis values y = NULL, # data values cl = NA, # centre line lcl = NA, # lower control limit ucl = NA, # upper control limit ... # other parameters passed to the plot() function ) { # if y is missing, set y to x and make a sequence for x if (is.null(y)) { y &lt;- x x &lt;- seq_along(y) } # repeat line values to match the length of y if (length(cl) == 1) cl &lt;- rep(cl, length(y)) if (length(lcl) == 1) lcl &lt;- rep(lcl, length(y)) if (length(ucl) == 1) ucl &lt;- rep(ucl, length(y)) # plot the dots and draw the lines plot(x, y, type = &#39;o&#39;, ylim = range(y, lcl, ucl, na.rm = TRUE), ...) lines(x, cl) lines(x, lcl) lines(x, ucl) } The spc() function takes five arguments of which only the first, x, is mandatory. If only x is provided, a simple point-and-line chart will be drawn from the x values. If y is also provided, x values will be used for the x axis. The line arguments (cl, lcl, ucl) are used (if provided) for the centre line and control limits respectively. Line arguments may be given as either single values or vectors of the same length as x. In addition, we may provide additional arguments for the plot() function, e.g. main, xlab, and ylab for title and axis labels. Let us test it with the blood pressure data from Chapter 5 (Figure 6.1). # create an x variable, not that is it necessary in this case, just because we can day &lt;- seq_along(systolic) # plot data spc(day, systolic, cl, lcl, ucl) Figure 6.1: Control chart of systolic blood pressure With this function we are now able to construct all kinds of control charts. All we need to know is how to calculate the centre line and the control limits. 6.2 Formulas for calculation of control limits The formulas for calculation control limits for The Magnificent Seven introduced in Chapter 2 are provided in Table 6.1. Don’t be alarmed by the number of strange symbols, we will translate the formulas to R code one by one as we move along. Table 6.1: Formulas for calculating control limits Subgroups Chart type Control limits Assumed distribution Count data Counts C \\(\\bar{c}\\pm3\\sqrt{\\bar{c}}\\) Poisson Rates U \\(\\bar{u}\\pm3\\sqrt{\\frac{\\bar{u}}{n_{i}}}\\) Poisson Proportions P \\(\\bar{p}\\pm3\\sqrt{\\frac{\\bar{p}(1-\\bar{p})}{n_{i}}}\\) Binomial Measurement data Individual measurements I \\(\\bar{x}\\pm2.66\\overline{MR}\\) Normal Moving ranges of individual measurements MR \\(3.267\\overline{MR}\\) Normal Averrages of 2 or more measurements X-bar \\(\\bar{\\bar{x}}\\pm A_{3}\\bar{s}\\) Normal Standard deviations of 2 or more measurements S \\(B_{3}\\bar{s};\\ B_{4}\\bar{s}\\) Normal As discussed in Chapter 2, data come in two flavours: count data and measurement data. Counts are positive integers that represent counts of events or cases, for example patient falls, surgical complications, or healthy babies. Measurements are data that are measured on continuous scales and may have decimals, for example blood pressure, height and weight, or waiting times. 6.3 Count data For count charts in this chapter we will use the bacteremia data set: # read data from file bact &lt;- read.csv(&#39;data/bacteremia.csv&#39;, # path to data file comment.char = &#39;#&#39;, # ignore lines that start with &quot;#&quot; colClasses = c( # specify variable types &#39;Date&#39;, &#39;integer&#39;, &#39;integer&#39;, &#39;integer&#39;, &#39;integer&#39; )) # print the first six rows head(bact) ## month ha_infections risk_days deaths patients ## 1 2017-01-01 24 32421 23 100 ## 2 2017-02-01 29 29349 22 105 ## 3 2017-03-01 26 32981 13 99 ## 4 2017-04-01 16 29588 14 85 ## 5 2017-05-01 28 30856 17 98 ## 6 2017-06-01 16 30544 15 85 The variables are: month (date): month of infection ha_infections (numeric): number of hospital acquired infections risk_days (numeric): number of patient days without infection deaths (numeric): number of patients who died within 30-day after a hospital or community acquired (all-cause) infection patients (numeric): number of patients with all-cause infection We use C charts for event counts and U chart for event rates. For case proportions we use the P chart. 6.3.1 C chart The C charts (C for counts) is the simplest of all control charts and the easiest to produce. The process standard deviation is simply estimated as the square root of the process mean. C charts are appropriate when counting events from (nearly) equally big chunks of time or space. Figure 6.2 shows a C chart of the monthly number of hospital acquired bacteremias. with(bact, { cl &lt;- mean(ha_infections) lcl &lt;- cl - 3 * sqrt(cl) ucl &lt;- cl + 3 * sqrt(cl) # print the limits cat(&#39;UCL =&#39;, ucl, &#39;\\n&#39;) cat(&#39;CL =&#39;, cl, &#39;\\n&#39;) cat(&#39;LCL = &#39;, lcl, &#39;\\n&#39;) # plot the chart spc(month, ha_infections, cl, lcl, ucl, ylab = &#39;Infections&#39;, # y-axis label xlab = &#39;Month&#39;) # x-axis label }) ## UCL = 36.94952 ## CL = 22.66667 ## LCL = 8.38381 Figure 6.2: C control chart of monthly numbers of hospital acquired bacteremias The average monthly number of cases is 22.7, and all data points are within the control limits ranging from 8.4 to 36.9. So if nothing changes, we should expect future infection counts to be around 23, and we should not be surprised if once in a while, we observe as little as 9 or as many as 36 infections in a single month. 6.3.2 U chart U charts are useful when events are counted over chunks of time or space that are not equally sized resulting in “unequal area of opportunity” (hence the U). In our case we might want to adjust for for the number of patient days that may vary depending on the time of year or between organisational units. The U chart adjust for this by presenting rates rather than raw counts. Events are often rare in comparison to their areas of opportunity. So to avoid very small numbers on the y-axis it may be useful to multiply the y-axis by some factor before plotting. In Figure 6.3 we multiply by 10,000 to display infections per 10,000 risk days rather than per day. with(bact, { y &lt;- ha_infections / risk_days # rates to plot cl &lt;- sum(ha_infections) / sum(risk_days) # overall mean rate, centre line s &lt;- sqrt(cl / risk_days) # standard deviation lcl &lt;- cl - 3 * s # lower control limit ucl &lt;- cl + 3 * s # upper control limit # multiply y axis to present infections per 10,000 risk days multiply &lt;- 10000 y &lt;- y * multiply cl &lt;- cl * multiply lcl &lt;- lcl * multiply ucl &lt;- ucl * multiply spc(month, y, cl, lcl, ucl, ylab = &#39;Infections per 10,000 risk days&#39;, xlab = &#39;Month&#39;) }) Figure 6.3: U chart of monthly number of infections per 10,000 risk days The U chart shows that on average we have 7.5 infections per 10,000 risk days, and that all data points are between the control limits ranging from about 3.5 to 12. We see that the control limits vary depending on the denominator (risk days), for each data point. Large denominator \\(\\rightarrow\\) narrow limits; small denominator \\(\\rightarrow\\) wide limits. In cases like this where the denominator – the area of opportunity – only varies little between subgroups, the U charts adds little compared to the C chart. For pedagogical reasons we may prefer the C chart, because it is a lot easier to relate to 23 infections per month than to 7.5 infections per 10,000 risk days. 6.3.3 P chart P charts are for proportions (or percentages). Figure 6.4 shows the monthly percentage of patients with bacteremia who died within 30 days. with(bact, { y &lt;- deaths / patients cl &lt;- sum(deaths) / sum(patients) # process mean, centre line s &lt;- sqrt((cl * (1 - cl) / patients)) # process standard deviation lcl &lt;- cl - 3 * s # lower control limit ucl &lt;- cl + 3 * s # upper control limit # multiply by 100 to get percentages rather than proportions multiply &lt;- 100 y &lt;- y * multiply cl &lt;- cl * multiply lcl &lt;- lcl * multiply ucl &lt;- ucl * multiply spc(month, y, cl, lcl, ucl, ylab = &#39;%&#39;, xlab = &#39;Month&#39;) }) Figure 6.4: P chart of monthly 30-day mortality rates On average the mortality is 21%, and all data points are within the control limits. As with U charts, the control limits vary depending on the size of the denominator. 6.4 Measurement data For this section we will use a data set on response times for grade 2 caesarean sections, that is, the time (in minutes) it took from the decision to perform a C-section to the baby was delivered. The goal is to keep the response times below 30 minutes. The csect data frame contains the date and time, the month, and the number of minutes from decision to delivery for 208 grade 2 section over a two-year period. # read raw data csect &lt;- read.csv(&#39;data/csection_delay.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(&#39;POSIXct&#39;, &#39;Date&#39;, &#39;integer&#39;)) csect &lt;- csect[order(csect$datetime), ] # show the first 6 rows head(csect) ## datetime month delay ## 1 2016-01-06 03:55:40 2016-01-01 22 ## 2 2016-01-06 20:52:34 2016-01-01 22 ## 3 2016-01-07 02:50:43 2016-01-01 29 ## 4 2016-01-07 22:32:27 2016-01-01 28 ## 5 2016-01-09 14:56:09 2016-01-01 22 ## 6 2016-01-09 21:21:24 2016-01-01 20 6.4.1 I chart (aka X chart) The “I” in I chart stand for “individuals” because it plots individual values from subgroups of size 1. I charts are also often referred to as X charts. I charts are useful when measurements come from individual units, for example waiting times or blood pressure measurements for individual patients. As we will see later, I charts are in fact useful for all kinds of data because they base their estimations on the actual variation that is present in data rather than theoretical parameters from assumed distributions. For this reason, the I chart is considered the Swiss army knife of SPC. When subgroups consist of single values we use the average absolute difference between neighbouring data points, the average moving range (\\(\\overline{MR}\\)), as an estimate of the within subgroup variation. By dividing this value with 1.128 we get an estimate of the process standard deviation. Alternatively, we may multiply \\(\\overline{MR}\\) by 3 / 1.128 = 2.66 to get 3 \\(SD\\)s. Let’s have a look at individual delay times for the latest 60 C-sections (Figure 6.5). with(tail(csect, 60), { xbar &lt;- mean(delay) # mean value, centre line mr &lt;- abs(diff(delay)) # moving ranges amr &lt;- mean(mr) # average moving range s &lt;- amr / 1.128 # process standard deviation spc(delay, cl = xbar, lcl = xbar - 3 * s, ucl = xbar + 3 * s) }) Figure 6.5: I-chart On average, the delay time for these cases is 24 minutes. Three data points are outside the control limits (#1, #4 and #31) suggesting that these cases were special and that it might be useful to have a closer look to find out what went well with case #1 and not so well with cases #4 and #31. 6.4.2 MR chart The MR chart plots the moving ranges, that is, the absolute pairwise differences of neighbouring data points. It is a companion to the I chart. Since moving ranges can always be zero but never negative, the MR chart has no lower control limit. with(tail(csect, 60), { mr &lt;- c(NA, abs(diff(delay))) # add NA in front to match the length of the I-chart amr &lt;- mean(mr, na.rm = TRUE) spc(mr, cl = amr, ucl = 3.267 * amr) }) Figure 6.6: MR-chart Note that there is one less moving range than individual values. To align the charts, we insert an NA value at the beginning of the MR-chart. We may plot the two charts together (Figure 6.7): with(tail(csect, 60), { xbar &lt;- mean(delay) mr &lt;- c(NA, abs(diff(delay))) amr &lt;- mean(mr, na.rm = TRUE) op &lt;- par(mfrow = c(2, 1), # setting up plotting area mar = c(5, 5, 2, 1)) spc(delay, cl = xbar, lcl = xbar - 2.66 * amr, ucl = xbar + 2.66 * amr, main = &#39;I-chart&#39;, ylab = &#39;Delay (minutes)&#39;, xlab = &#39;&#39;) spc(mr, cl = amr, ucl = 3.267 * amr, main = &#39;MR-chart&#39;, ylab = &#39;Moving range (minutes)&#39;, xlab = &#39;C-section #&#39;) par(op) # restoring plotting area }) Figure 6.7: I- and MR-charts The MR-chart also finds three data points outside the limits. These coincide with two of the special causes found by the I chart and support our conclusion that these deliveries were special. Note that each data point on the I chart (except the first and last ones) produces two moving ranges on the MR chart. 6.4.3 X-bar chart The X-bar chart is appropriate when the subgroups consist of samples of two or more measurements. To plot a control chart of the monthly average delays, we must first aggregate data to find the mean and the standard deviation of delay times and the number of sections per month. # split data frame by month csect.agg &lt;- split(csect, csect$month) # aggregate data by month csect.agg &lt;- lapply(csect.agg, function(x) { data.frame(month = x$month[1], mean = mean(x$delay), sd = sd(x$delay), n = nrow(x)) }) # put everything together again csect.agg &lt;- do.call(rbind, c(csect.agg, make.row.names = FALSE)) # print the first 6 rows head(csect.agg) ## month mean sd n ## 1 2016-01-01 23.85714 3.387653 7 ## 2 2016-02-01 24.45455 6.137811 11 ## 3 2016-03-01 22.45455 6.638729 11 ## 4 2016-04-01 22.66667 3.041381 9 ## 5 2016-05-01 22.50000 3.891382 8 ## 6 2016-06-01 22.00000 6.204837 5 See section Aggregating data frames in Appendix D for details on the split-apply-combine strategy. Next, we calculate the centre line and the control limits using the formula in Table 6.1 where \\(\\bar{\\bar{x}}\\) (pronounced x bar bar) is the weighted mean of the subgroup means, \\(\\bar{s}\\) (s bar) is the weighted mean of the subgroup standard deviations, and \\(A_3\\) is a constant that depends on the subgroup size. See the section on chart constants at the end of this chapter for the R code involved in calculating \\(A_3\\) and other constants for control chart construction. With the aggregated data we are now able to construct the X-bar chart (Figure 6.8). with(csect.agg, { xbarbar &lt;- weighted.mean(mean, n) # centre line sbar &lt;- weighted.mean(sd, n) # process standard deviation a3 &lt;- a3(n) # A3 constant spc(x = month, y = mean, cl = xbarbar, lcl = xbarbar - a3 * sbar, ucl = xbarbar + a3 * sbar) }) Figure 6.8: X bar chart Figure 6.8 shows the average delay time per month. On average the delay time is 23 minutes (= centre line) and all data points fall between the control limits suggesting that the process is stable and predictable. As with U and P charts the control limits vary from month to month reflecting the varying subgroup sizes – small subgroups \\(\\rightarrow\\) wide limits; large subgroups \\(\\rightarrow\\) narrow limits. Be careful not to fall for the temptation to conclude that just because no months are above the target of 30 minutes all is well. The 30-minute target applies to the delay time of individual sections, not the averages. Even if the averages are well below the target, individuals may be above, which we already noticed from the I chart above. 6.4.4 S chart The S chart is usually plotted alongside the X-bar chart and shows the within subgroup variation. It is useful for detecting changes in the spread of data over time. To calculate the centre and control limits for the S chart we need to know the process standard deviation, \\(\\bar{S}\\) (same as for the X-bar chart), and the two constants \\(B_3\\) and \\(B_4\\) From Table 6.1. with(csect.agg, { sbar &lt;- weighted.mean(sd, n) # pooled SD, centre line b3 &lt;- b3(n) # B3 constant b4 &lt;- b4(n) # B4 constant spc(x = month, y = sd, cl = sbar, lcl = b3 * sbar, ucl = b4 * sbar) }) Figure 6.9: S chart Figure 6.9 shows the average standard deviation of delay times per month. On average the standard deviation is 4.7 minutes and all data points fall between the control limits. We may plot the X-bar and S charts together (Figure 6.10): with(csect.agg, { xbarbar &lt;- weighted.mean(mean, n) # pooled average sbar &lt;- weighted.mean(sd, n) # pooled standard deviation a3 &lt;- a3(n) # A3 constant b3 &lt;- b3(n) # B3 constant b4 &lt;- b4(n) # B4 constant op &lt;- par(mfrow = c(2, 1), mar = c(3, 5, 2, 1)) spc(month, mean, cl = xbarbar, lcl = xbarbar - a3 * sbar, ucl = xbarbar + a3 * sbar, main = &#39;X-bar Chart&#39;, xlab = &#39;&#39;) spc(month, sd, cl = sbar, lcl = b3 * sbar, ucl = b4 * sbar, main = &#39;S chart&#39;, xlab = &#39;&#39;) par(op) }) Figure 6.10: X-bar and S charts 6.5 Control limits in short Control limits attempt to estimate the boundaries of the natural common cause process variation. They are placed 3 standard deviations above and below the centre line, which is the (weighted) mean of the subgroup means. The procedure for calculating control limits depends on the type of data involved, but the interpretation of charts are the same regardless of data type. In the next chapter we will improve our plots by adding visual clues to highlight signs of non-random variation. Control chart constants a3 &lt;- function(n) { 3 / (c4(n) * sqrt(n)) } b3 &lt;- function(n) { pmax(0, 1 - 3 * c5(n) / c4(n)) } b4 &lt;- function(n) { 1 + 3 * c5(n) / c4(n) } c4 &lt;- function(n) { n[n &lt;= 1] &lt;- NA sqrt(2 / (n - 1)) * exp(lgamma(n / 2) - lgamma((n - 1) / 2)) } c5 &lt;- function(n) { sqrt(1 - c4(n)^2) } "],["highlighting.html", "Chapter 7 Highlighting Freaks, Shifts, and Trends 7.1 Introducing the cdiff data set 7.2 Improved spc() function 7.3 Highlighting special cause variation in short R function for runs analysis", " Chapter 7 Highlighting Freaks, Shifts, and Trends In the Chapter 6 we calculated control limits for commonly used control charts. Control limits show the boundaries of the natural common cause process variation. Thus, data points outside the control limits (freaks) are signals of special cause variation in data – that is, unexpected change caused by something outside the usual system. Control limits are designed to signal rather large (&gt; 2SD), possibly transient, changes in the system. However, as discussed in detail in Chapter 3, minor to moderate changes in the form of shifts or trends in data may go unnoticed by the control limits for long periods of time. For this purpose, many supplementary tests (rules) have been suggested. To balance the need to quickly detect special causes while keeping the false alarm rate as low as possible we recommend using the 3-sigma rule to signal freaks and the two runs rules for unusually long runs and unusually few crossings to signal shifts and trends. In this chapter we will improve the spc() function to automatically visualise special cause variation in the form of freaks, shifts, and trends. 7.1 Introducing the cdiff data set The cdiff data set contains 24 observations of monthly numbers of hospital acquired Clostridioides difficile infections from an acute care hospital. # read data from file cdiff &lt;- read.csv(&#39;data/cdiff.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(&#39;Date&#39;, &#39;integer&#39;, &#39;integer&#39;)) # calculate centre line and control limits cdiff &lt;- within(cdiff, { cl &lt;- mean(infections) lcl &lt;- pmax(0, cl - 3 * sqrt(cl)) # censor lcl at zero ucl &lt;- cl + 3 * sqrt(cl) }) # print the first six rows of data head(cdiff) ## month infections risk_days ucl lcl cl ## 1 2020-01-01 12 19801 11.77776 0 5.041667 ## 2 2020-02-01 7 18674 11.77776 0 5.041667 ## 3 2020-03-01 1 15077 11.77776 0 5.041667 ## 4 2020-04-01 4 12062 11.77776 0 5.041667 ## 5 2020-05-01 4 14005 11.77776 0 5.041667 ## 6 2020-06-01 5 14840 11.77776 0 5.041667 Figure 7.1 shows data plotted with spc() function. We see that there is one data point (#1) above the upper control limit. If we look carefully we also find an unusually long run of 11 data points below the centre line (#14-#24) and that the curve crosses the centre line only 7 times. Thus, in addition to the freak, there is also a shift in data, which is not large enough to break the limits but sustained enough to trigger the runs rules. with(cdiff, { spc(month, infections, cl, lcl, ucl) }) Figure 7.1: C control chart of CDiff infections Notice that we censored the lower control limit at zero even if the exact value is negative (\\(\\bar{c}-3\\sqrt{\\bar{c}}\\)). This is purely cosmetic, but since the data values themselves cannot be negative it makes little sense to show negative control limits. For the same reason we usually censor P chart control limits at 0 and 1 (100%) respectively. To help us signal special cause variation we will improve the spc() function. 7.2 Improved spc() function The new, improved spc() function has a few changes: Line 10: Import a function, runs.analysis(), from a separate R script to test for unusually long runs and unusually few crossings. See this function in the R function for runs analysis section at the end of this chapter. Lines 19-20: If no cl argument is given, use the median for centre line. Lines 33-34: Create a logical vector identifying data points that lie outside the control limits. Line 37: Test for unusually long runs or unusually few crossings. Line 40: Start with an empty plot. Line 47-49: Format the centre line according to the result of runs analysis. Lines 56-49: Add the data line and points and colour data points outside control limits. spc &lt;- function( x, # x axis values y = NULL, # data values cl = NULL, # centre line lcl = NA, # lower control limit ucl = NA, # upper control limit ... # other parameters passed to the plot() function ) { # load runs analysis function from R script source(&#39;R/runs.analysis.R&#39;) # if y is missing, set y to x and make a sequence for x if (is.null(y)) { y &lt;- x x &lt;- seq_along(y) } # if cl is missing use median of y if (is.null(cl)) cl &lt;- median(y, na.rm = TRUE) # repeat line values to match the length of y if (length(cl) == 1) cl &lt;- rep(cl, length(y)) if (length(lcl) == 1) lcl &lt;- rep(lcl, length(y)) if (length(ucl) == 1) ucl &lt;- rep(ucl, length(y)) # find data points outside control limits (freaks) sigma.signal &lt;- y &lt; lcl | y &gt; ucl sigma.signal[is.na(sigma.signal)] &lt;- FALSE # check for sustained shifts and trends using runs analysis runs.signal &lt;- runs.analysis(y, cl) # make empty plot plot(x, y, type = &#39;n&#39;, ylim = range(y, cl, lcl, ucl, na.rm = TRUE), ...) # add centre line, coloured and dashed if shifts or trends were identified by # the runs analysis lines(x, cl, col = runs.signal + 1, lty = runs.signal + 1) # add control limits lines(x, lcl) lines(x, ucl) # add data line and points, colour freak data points (outside control limits) lines(x, y) points(x, y, pch = 19, col = sigma.signal + 1) } with(cdiff, { spc(month, infections, cl, lcl, ucl) }) Figure 7.2: Improved control chart with visual clues to highlight special cause variation Now it is a lot easier to immediately see if a chart signals special cause variation or not (Figure 7.2). Freak data points are red, and the centre line turns red and dashed if there are any unusually long runs or if the curve crossed the centre line unusually few times. Remember, the chart itself does not tell us what caused the signals. This interpretation of a chart – common or special cause variation – still relies on humans with a deep understanding the process and the data. 7.3 Highlighting special cause variation in short In this chapter we have improved the spc() function to automatically highlight signs of special cause variation using visual clues that signal special cause variation. In the next chapter we will improve the spc() function further to automatically aggregate data and calculate control limits. R function for runs analysis runs.analysis &lt;- function(y, cl) { # trichotomise data according to position relative to CL # -1 = below, 0 = on, 1 = above runs &lt;- sign(y - cl) # remove NAs and data points on the CL runs &lt;- runs[runs != 0 &amp; !is.na(runs)] # find run lengths run.lengths &lt;- rle(runs)$lengths # find number of useful observations (data points not on CL) n.useful &lt;- sum(run.lengths) # find longest run above or below CL longest.run &lt;- max(run.lengths) # find number of times adjacent data points are on opposite sides of CL n.crossings &lt;- length(run.lengths) - 1 # find upper limit for longest run longest.run.max &lt;- round(log2(n.useful)) + 3 # find lower limit for number of crossing n.crossings.min &lt;- qbinom(0.05, n.useful - 1, 0.5) # return result, TRUE if either of the two tests is true, otherwise FALSE longest.run &gt; longest.run.max | n.crossings &lt; n.crossings.min } "],["r-functions.html", "Chapter 8 Core R Functions to Construct SPC Charts 8.1 Examples 8.2 TODO 8.3 Further up, further in R function library", " Chapter 8 Core R Functions to Construct SPC Charts Until now, we have calculated control limits manually before plotting. In this chapter we will introduce a library of functions that work together to automate all the steps involved in constructing SPC charts. We will not go through each of these functions in detail, but we encourage you to study them to get a good grasp of how they work and work together. And we encourage you to improve and adapt them to your own needs. In total there are 17 functions that work together to construct SPC charts. But the user only needs to interact with one of them, spc(). See the R functions library section at the end of this chapter for the source code. The main function, spc() is an improved version of the improved spc() function from Chapter 7. Most importantly, it is no longer necessary to calculate the limits manually. Instead, we provide a chart argument, which should be one of the following: ‘run’, ‘xbar’, ‘s’, ‘i’, ‘mr’, ‘c’, ‘u’, ‘p’. If no chart argument is provided, a run chart will be drawn. Also, we no longer have to use the clumsy $-notation or with() function to access variables inside a data frame. Instead, we may pass the name of the data frame to the data argument. Finally, we do not need to aggregate data for X-bar and S charts in advance. That job is delegated to the spc.aggregate() function, which is also responsible for calling the appropriate functions to calculate the centre line and control limits and perform the runs analysis. After doing its job, spc.aggregate() returns a data frame with all the necessary information needed to construct a plot. This, in turn, is handled by the plot.spc() function. 8.1 Examples Here are examples of a run chart and each of the Magnificent Seven. See Appendix A for documentation of the data sets used in the examples. 8.1.1 Run chart d &lt;- read.csv(&#39;data/blood_pressure.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(date = &#39;Date&#39;)) head(d) ## date systolic diastolic pulse ## 1 2012-06-13 125 77 56 ## 2 2012-06-14 118 76 59 ## 3 2012-06-15 125 75 59 ## 4 2012-06-16 126 73 69 ## 5 2012-06-17 124 77 70 ## 6 2012-06-18 127 83 63 spc(date, systolic, data = d, main = &#39;Systolic blood pressure&#39;, ylab = &#39;mm Hg&#39;, xlab = &#39;Date&#39;) Figure 8.1: Run chart 8.1.2 I and MR charts for individual measurements # Setup plotting area to hold two plots on top of each other and adjust margins op &lt;- par(mfrow = c(2, 1), mar = c(4, 4, 2, 0) + 0.2) spc(date, systolic, data = d, chart = &#39;i&#39;, main = &#39;Systolic blood pressure&#39;, ylab = &#39;mm Hg&#39;, xlab = NA) spc(date, systolic, data = d, chart = &#39;mr&#39;, main = &#39;Moving range&#39;, ylab = &#39;mm Hg&#39;, xlab = &#39;Date&#39;) Figure 8.2: I and MR charts # Reset plotting area to default par(op) 8.1.3 X-bar and S charts for averages and standard deviations of measurements d &lt;- read.csv(&#39;data/renography_doses.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(date = &#39;Date&#39;, week = &#39;Date&#39;)) head(d) ## date week dose ## 1 2014-01-06 2014-01-06 51 ## 2 2014-01-06 2014-01-06 48 ## 3 2014-01-06 2014-01-06 75 ## 4 2014-01-06 2014-01-06 53 ## 5 2014-01-06 2014-01-06 71 ## 6 2014-01-06 2014-01-06 84 op &lt;- par(mfrow = c(2, 1), mar = c(4, 4, 2, 0) + 0.2) spc(week, dose, data = d, chart = &#39;xbar&#39;, main = &#39;Average radiation dose for renography&#39;, ylab = &#39;MBq&#39;, xlab = NA) spc(week, dose, data = d, chart = &#39;s&#39;, main = &#39;Standard deviation&#39;, ylab = &#39;MBq&#39;, xlab = &#39;Week&#39;) Figure 8.3: X-bar and S charts par(op) 8.1.4 C and U charts for counts and rates d &lt;- read.csv(&#39;data/bacteremia.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(month = &#39;Date&#39;)) head(d) ## month ha_infections risk_days deaths patients ## 1 2017-01-01 24 32421 23 100 ## 2 2017-02-01 29 29349 22 105 ## 3 2017-03-01 26 32981 13 99 ## 4 2017-04-01 16 29588 14 85 ## 5 2017-05-01 28 30856 17 98 ## 6 2017-06-01 16 30544 15 85 op &lt;- par(mfrow = c(2, 1), mar = c(4, 4, 2, 0) + 0.2) spc(month, ha_infections, data = d, chart = &#39;c&#39;, main = &#39;Hospital acquired bacteremia&#39;, ylab = &#39;Count&#39;, xlab = NA) spc(month, ha_infections, risk_days, data = d, chart = &#39;u&#39;, multiply = 10000, main = NA, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 8.4: C and U charts par(op) 8.1.5 P chart for percentages spc(month, deaths, patients, data = d, multiply = 100, chart = &#39;p&#39;, main = &#39;30-day mortality after bacteremia&#39;, ylab = &#39;%&#39;, xlab = &#39;Month&#39;) Figure 8.5: P chart 8.2 TODO One obvious shortcoming of this function library is that the functions lack error checking. So if you are going to use them in a production environment or for your own SPC package you will need to build that yourself. At the least, you need to automatically check that inputs are of the expected types and that the x, y, and n arguments have the same lengths. TIP: check the stopifnot() function. 8.3 Further up, further in We now have a functioning library of R functions that automate most of the steps involved in the construction of SPC charts. There is still plenty of room for improvement. But this should get you started and – most importantly – give you a deeper understanding of the considerations involved in plotting SPC charts. In the next chapter we will take a quick look at how to use ggplot2() for plotting rather than the plot() function from base R. R function library # Master SPC function ########################################################## # # Constructs an SPC chart. # # Invisibly returns a data frame of class &#39;spc&#39;. # # x: Numeric or date(time) vector of subgroup values to plot along the x # axis. Or, if y is NULL, x values will be used for y coordinates. # y: Numeric vector of measures or counts to # plot on the y axis (numerator). # n: Numeric vector of subgroup sizes (denominator). # data: Data frame containing the variables used in the plot. # multiply: Number to multiply y axis by, e.g. 100 to get percentages rather # than proportions. # chart: Character value indicating the chart type. Possible values are: # &#39;run&#39; (default), &#39;xbar&#39;, &#39;s&#39;, &#39;i&#39;, &#39;mr&#39;, &#39;c&#39;, &#39;u&#39;, and &#39;p&#39;. # plot: Logical, if TRUE (default), plots an SPC chart. # print: Logical, if TRUE, prints a data frame with coordinates. # ...: Other arguments to the plot() function, e.g. main, ylab, xlab. # spc &lt;- function(x, y = NULL, n = 1, data = NULL, multiply = 1, chart = c(&#39;run&#39;, &#39;xbar&#39;, &#39;s&#39;, &#39;i&#39;, &#39;mr&#39;, &#39;c&#39;, &#39;u&#39;, &#39;p&#39;), plot = TRUE, print = FALSE, ...) { # Get data from data frame if data argument is provided, or else get data # from the parent environment. x &lt;- eval(substitute(x), data, parent.frame()) y &lt;- eval(substitute(y), data, parent.frame()) n &lt;- eval(substitute(n), data, parent.frame()) # Get chart argument. chart &lt;- match.arg(chart) # If y argument is missing, use x instead. if (is.null(y)) { y &lt;- x x &lt;- seq_along(y) } # Make sure that the n vector has same length as y. if (length(n) == 1) { n &lt;- rep(n, length(y)) } # Make sure that numerators and denominators are balanced. If one is missing, # the other should be missing too. xna &lt;- !complete.cases(data.frame(y, n)) y[xna] &lt;- NA n[xna] &lt;- NA # Aggregate data by subgroups. df &lt;- spc.aggregate(x, y, n, chart) # Multiply y coordinates if needed. df$y &lt;- df$y * multiply df$cl &lt;- df$cl * multiply df$lcl &lt;- df$lcl * multiply df$ucl &lt;- df$ucl * multiply # Make plot. if (plot) { plot.spc(df, ...) } # Print data frame. if (print) { print(df) } # Make data frame an &#39;spc&#39; object and return invisibly. class(df) &lt;- c(&#39;spc&#39;, class(df)) invisible(df) } # Aggregate function ########################################################### # # Calculates subgroup lengths, sums, means, and standard deviations. Called # from the spc() function. # # Returns a data frame of x, y, n, and centre line and control limits. # # x: Numerical, numbers or dates for the x axis. # y: Numerical, measure or count to plot. # n: Numerical, denominator (if any). # chart: Character, type of chart. # spc.aggregate &lt;- function(x, y, n, chart) { df &lt;- data.frame(x, y, n) # Get function to calculate centre line and control limits. chart.fun &lt;- get(paste(&#39;spc&#39;, chart, sep = &#39;.&#39;)) # Get function to restore the x variable to its original class after # aggregation. # subgrp.fun &lt;- get(paste0(&#39;as.&#39;, class(x))) # Split data frame by subgroups df &lt;- split(df, df$x) # Calculate subgroup lengths, sums, means, and standard deviations. df &lt;- lapply(df, function(x) { data.frame(x = x$x[1], n = sum(x$n, na.rm = TRUE), sum = sum(x$y, na.rm = TRUE), mean = sum(x$y, na.rm = TRUE) / sum(x$n, na.rm = TRUE), sd = sd(x$y, na.rm = TRUE), chart = chart) }) # Put list elements back together in a data frame. df &lt;- do.call(rbind, c(df, make.row.names = FALSE)) # df &lt;- data.frame(x = rownames(df), df, chart, row.names = NULL) # Replace any zero length subgroups with NA. df$n[df$n == 0] &lt;- NA # Calculate the weighted subgroup mean. df$ybar &lt;- weighted.mean(df$mean, df$n, na.rm = TRUE) # Restore x variable to its original class. # df$x &lt;- subgrp.fun(df$x) # Calculate centre line and control limits. df &lt;- chart.fun(df) # Add runs analysis if (chart == &#39;mr&#39;) { df$runs.signal &lt;- FALSE } else { df$runs.signal &lt;- runs.analysis(df$y, df$cl) } # Find data points outside control limits. df$sigma.signal &lt;- (df$y &lt; df$lcl | df$y &gt; df$ucl) df$sigma.signal[is.na(df$sigma.signal)] &lt;- FALSE # Return data frame. df[c(&#39;x&#39;, &#39;y&#39;, &#39;n&#39;, &#39;lcl&#39;, &#39;cl&#39;, &#39;ucl&#39;, &#39;sigma.signal&#39;, &#39;runs.signal&#39;, &#39;chart&#39;)] } # Plot function ################################################################ # # Draws an SPC chart from data provided by the spc() function. Is usually # called from the spc() function, but may be used as stand-alone for plotting # data frames of class spc created by the spc() function. # # Invisibly returns the data frame # # x: Data frame produced by the spc() function. # ...: Additional arguments for the plot() function, e.g. title and labels. # plot.spc &lt;- function(x, ...) { col1 &lt;- &#39;steelblue&#39; col2 &lt;- &#39;grey30&#39; col3 &lt;- &#39;tomato&#39; # Make room for data and control limits on the x axis. ylim &lt;- range(x$y, x$lcl, x$ucl, na.rm = TRUE) # Draw empty plot. plot(x$x, x$y, type = &#39;n&#39;, bty = &#39;l&#39;, las = 1, ylim = ylim, font.main = 1, ...) # Add lines and points to plot. lines(x$x, x$cl, col = ifelse(x$runs.signal, col3, col2), lty = ifelse(x$runs.signal, &#39;dashed&#39;, &#39;solid&#39;)) lines(x$x, x$lcl, col = col2) lines(x$x, x$ucl, col = col2) lines(x$x, x$y, col = col1, lwd = 2.5) points(x$x, x$y, pch = 19, cex = 0.8, col = ifelse(x$sigma.signal, col3, col1) ) invisible(x) } # Runs analysis function ####################################################### # # Tests time series data for non-random variation in the form of # unusually long runs or unusually few crossings. Called from the # spc.aggregate() function. # # Returns a logical, TRUE if non-random variation is present. # # x: Numeric vector. # cl: Numeric vector of length either one or same length as y. # runs.analysis &lt;- function(y, cl) { # Trichotomise data according to position relative to CL: # -1 = below, 0 = on, 1 = above. runs &lt;- sign(y - cl) # Remove NAs and data points on the centre line. runs &lt;- runs[runs != 0 &amp; !is.na(runs)] # Find run lengths. run.lengths &lt;- rle(runs)$lengths # Find number of useful observations (data points not on centre line). n.useful &lt;- sum(run.lengths) # Find longest run above or below centre line. longest.run &lt;- max(run.lengths) # Find number of crossings. n.crossings &lt;- length(run.lengths) - 1 # Find upper limit for longest run. longest.run.max &lt;- round(log2(n.useful)) + 3 # Find lower limit for number of crossing. n.crossings.min &lt;- qbinom(0.05, n.useful - 1, 0.5) # Return result. longest.run &gt; longest.run.max | n.crossings &lt; n.crossings.min } # Limits functions ############################################################# # # These functions calculate coordinates for the centre line and control limits # of SPC charts. They are not meant to be called directly but are used by the # spc.aggregate() function. # # Return data frames with coordinates for centre line and control limits. # # x: A data frame containing the values to plot. # spc.run &lt;- function(x) { x$y &lt;- x$mean x$cl &lt;- median(x$y, na.rm = TRUE) x$lcl &lt;- NA_real_ x$ucl &lt;- NA_real_ x } spc.i &lt;- function(x) { x$y &lt;- x$mean xbar &lt;- x$ybar amr &lt;- mean(abs(diff(x$y)), na.rm = T) sss &lt;- 2.66 * amr x$cl &lt;- xbar x$lcl &lt;- xbar - sss x$ucl &lt;- xbar + sss x } spc.mr &lt;- function(x) { x$y &lt;- c(NA, abs(diff(x$mean))) amr &lt;- mean(x$y, na.rm = TRUE) x$cl &lt;- amr x$lcl &lt;- NA_real_ x$ucl &lt;- 3.267 * amr x } spc.xbar &lt;- function(x) { x$y &lt;- x$mean a3 &lt;- a3(x$n) xbarbar &lt;- weighted.mean(x$mean, x$n, na.rm = TRUE) sbar &lt;- weighted.mean(x$sd, x$n, na.rm = TRUE) sss &lt;- a3 * sbar x$cl &lt;- xbarbar x$lcl &lt;- xbarbar - sss x$ucl &lt;- xbarbar + sss x } spc.s &lt;- function(x) { x$y &lt;- x$sd sbar &lt;- weighted.mean(x$sd, x$n, na.rm = TRUE) b3 &lt;- b3(x$n) b4 &lt;- b4(x$n) x$cl &lt;- sbar x$lcl &lt;- b3 * sbar x$ucl &lt;- b4 * sbar x } spc.c &lt;- function(x) { x$y &lt;- x$sum cbar &lt;- mean(x$y, na.rm = TRUE) sss &lt;- 3 * sqrt((cbar)) x$cl &lt;- cbar x$lcl &lt;- pmax(0, cbar - sss) x$ucl &lt;- cbar + sss x } spc.u &lt;- function(x) { x$y &lt;- x$mean ubar &lt;- x$ybar sss &lt;- 3 * sqrt((ubar / x$n)) x$cl &lt;- ubar x$lcl &lt;- pmax(0, ubar - sss, na.rm = TRUE) x$ucl &lt;- ubar + sss x } spc.p &lt;- function(x) { x$y &lt;- x$mean pbar &lt;- x$ybar sss &lt;- 3 * sqrt((pbar * (1 - pbar)) / x$n) x$cl &lt;- pbar x$lcl &lt;- pmax(0, pbar - sss) x$ucl &lt;- pmin(1, pbar + sss) x } # Constants functions ########################################################## # # These functions calculate the constants that are used for calculating the # parameters of X-bar and S charts. Called from the spc.xbar() and spc.s() # functions # # Return a number, the constant for that subgroup size # # n: Number of elements in subgroup # a3 &lt;- function(n) { 3 / (c4(n) * sqrt(n)) } b3 &lt;- function(n) { pmax(0, 1 - 3 * c5(n) / c4(n), na.rm = TRUE) } b4 &lt;- function(n) { 1 + 3 * c5(n) / c4(n) } c4 &lt;- function(n) { n[n &lt;= 1] &lt;- NA sqrt(2 / (n - 1)) * exp(lgamma(n / 2) - lgamma((n - 1) / 2)) } c5 &lt;- function(n) { sqrt(1 - c4(n) ^ 2) } "],["ggplot.html", "Chapter 9 SPC Charts with ggplot2 9.1 Creating an SPC object for later plotting 9.2 Making a new plot function based on ggplot2 9.3 Customising the plotting theme 9.4 Preparing for qicharts2", " Chapter 9 SPC Charts with ggplot2 Armed with the battery of functions from Chapter 8 we are able to construct any of the most commonly used SPC charts using functionality from base R. Furthermore, it is easy to add new types of SPC charts to the library. To achieve this, all we have to do is to write an appropriate spc.*() function to handle the calculations of the centre line and limits and to include the function type in thespc() function’s chart argument. Because we have used a modularised approach and made a separate function for plotting spc objects, plot.spc(), it is also a simple task to use any plotting engine other than base R graphics. In this chapter we will build an alternative plot function, which uses ggplot2 as its plotting engine. ggplot2 has some advantages over plotting with base R function. Not because ggplot2 is able to do things that cannot be done with base R, but because it makes some operations a lot easier. For example, with ggplot2 we do not need to worry about scaling the axes to accommodate data that are added to the plot or to make room for axis labels and tick marks. These are all handled gracefully by ggplot2 itself. Also ggplot2 has an extensive theming engine that makes it (relatively) easy to customise the non-data parts of a plot, for example colours, legends, and number formats. 9.1 Creating an SPC object for later plotting With the spc() function we created in the previous chapter we will create an spc object and assign it to a variable, p, for later use: # make spc object p &lt;- spc(month, infections, data = cdiff, chart = &#39;c&#39;, plot = FALSE) Notice that we suppressed the plotting and assigned the (invisible) output, which is a data frame containing the coordinates to plot, to the variable p. We can now continue working with p as with any other R object. # check the class of p class(p) ## [1] &quot;spc&quot; &quot;data.frame&quot; # show the first six rows from p head(p) ## x y n lcl cl ucl sigma.signal runs.signal chart ## 1 2020-01-01 12 1 0 5.041667 11.77776 TRUE TRUE c ## 2 2020-02-01 7 1 0 5.041667 11.77776 FALSE TRUE c ## 3 2020-03-01 1 1 0 5.041667 11.77776 FALSE TRUE c ## 4 2020-04-01 4 1 0 5.041667 11.77776 FALSE TRUE c ## 5 2020-05-01 4 1 0 5.041667 11.77776 FALSE TRUE c ## 6 2020-06-01 5 1 0 5.041667 11.77776 FALSE TRUE c # show the C chart plot(p) # not necessary to call spc.plot(), just call the generic plot() function Figure 9.1: SPC chart Because p is an object of class “spc” we only need to call the generic plot() function, which in turn will pass its first argument to the specialised spc.plot() function. 9.2 Making a new plot function based on ggplot2 We may now create any number of alternative plotting functions for spc objects. In this example we will create a plotting function that uses ggplot2. # Load ggplot2 library(ggplot2) # Function for plotting spc objects with ggplot() ggspc &lt;- function(p) { # Set colours col1 &lt;- &#39;steelblue&#39; col2 &lt;- &#39;tomato&#39; linecol &lt;- &#39;gray50&#39; dotcol &lt;- ifelse(p$sigma.signal, col2, col1) clcol &lt;- ifelse(p$runs.signal[1], col2, linecol) cltyp &lt;- ifelse(p$runs.signal[1], &#39;dashed&#39;, &#39;solid&#39;) # Plot the dots and draw the lines ggplot(p, aes(x, y)) + geom_line(aes(y = lcl), colour = linecol, na.rm = TRUE) + geom_line(aes(y = ucl), colour = linecol, na.rm = TRUE) + geom_line(aes(y = cl), colour = clcol, linetype = cltyp, na.rm = TRUE) + geom_line(colour = col1, na.rm = TRUE) + geom_point(colour = dotcol, na.rm = TRUE) } # Plot an spc object ggspc(p) Figure 9.2: SPC chart using the ggspc() function We may also turn the spc object into a ggplot2 object: # make the spc object into a ggplot2 object p &lt;- ggspc(p) class(p) ## [1] &quot;gg&quot; &quot;ggplot&quot; # plot with modified theme and custom labels p + theme_light() + theme(panel.grid = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = &#39;gray&#39;)) + labs(title = &#39;CDiff infections&#39;, y = &#39;Count&#39;, x = &#39;Month&#39;) Figure 9.3: SPC chart with modified theme Now, if we wished, we could replace the plot.spc() function with this new function. We will leave it to you to decide which of the two you like best. 9.3 Customising the plotting theme The last example in this chapter demonstrates how to create our own custom theme and how to format y axis tick marks as percentages: mytheme &lt;- function() { theme_light() + theme(panel.grid = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = &#39;gray&#39;)) } p &lt;- spc(month, deaths, patients, data = bact, chart = &#39;p&#39;, plot = FALSE) ggspc(p) + mytheme() + scale_y_continuous(labels = scales::label_percent()) + labs(title = &#39;30-day mortality&#39;, y = NULL, x = &#39;Month&#39;) Figure 9.4: SPC chart with labels and custom y-axis In the long run, though, we might get tired of manually designing our own theme, modifying the plot function, and formatting tick mark labels for every plot. Wouldn’t it be nice to have this done automatically for us? This is exactly what qicharts2 does. 9.4 Preparing for qicharts2 qicharts2 is an R package for plotting SPC charts and is the subject of the next chapter. qicharts2 builds on the same principles we have developed so far but has a lot more facilities for customising charts. Most importantly, qicharts2 makes it easy to produce multidimensional plots using ggplot2’s faceting methods. "],["qicharts.html", "Chapter 10 Introducing qicharts2 10.1 A simple run chart 10.2 A simple control chart 10.3 Excluding data points from analysis 10.4 Freezing baseline period 10.5 Splitting chart by period 10.6 Small multiple plots for multivariate data 10.7 qicharts2 in short", " Chapter 10 Introducing qicharts2 qicharts2 (Quality Improvement Charts, Anhøj (2024), Anhøj (2018)) is an R package for SPC aimed at healthcare data analysts. It is based on the same principles that we have developed in the previous chapters of this book. It contains functions to construct run charts and all of the Magnificent Seven plus a number of specialised charts including pareto charts and control charts for rare events data. To learn everything about qicharts2, visit its website: https://anhoej.github.io/qicharts2/. In this chapter we will concentrate on some key facilities that is missing from the function library we have build so far: excluding data points from analysis freezing and splitting charts by periods multivariate plots (small multiples) To get started with qicharts2, install it and load it into your working environment: # install package install.packages(&#39;qicharts2&#39;) # load package library(qicharts2) Remember, you only need to install a package once, but you need to load it every time you want to use it. Next, you may want to read the vignette: vignette('qicharts2') – or you may want to get started right away. 10.1 A simple run chart The main function of qicharts2 is qic(). It takes the same arguments as the spc() function we built previously plus many more. Check the documentation for a complete list of arguments: ?qic. To reproduce our first run chart from Chapter 5, run: qic(systolic) Figure 10.1: Run chart produced with the qic() function from the qicharts2 package There are several things to note in Figure 10.1: Default chart title and axis labels are created automatically. These can be changed using the title, ylab, and xlab arguments. Data points that fall directly on the centre line are greyed out. These do not count as useful observation in the runs analysis. The centre line value is printed on the chart. 10.2 A simple control chart To produce a control chart, we simply add a chart argument (Figure 10.2): qic(systolic, chart = &#39;i&#39;) Figure 10.2: I chart produced with qic() By default qic() uses a grey background area to show the natural process limits. 10.3 Excluding data points from analysis Sometimes it is useful to exclude one or more data points from the calculation of control limits and from the runs analysis. This may be the case when specific data points are known to have been influenced by factors that are not part of the natural process, for example data points that fall outside the control limits. We use the exclude argument to do this: qic(systolic, chart = &#39;i&#39;, exclude = 6) Figure 10.3: I chart with one data point excluded from calculations Notice how the values for the centre line and control limits in Figure 10.3 changed a little. Specifically, the control limits became slightly narrower. Excluding data points should be a deliberate decision and not something that is done automatically just because one or more data points are outside the control limits. Exclusion should be based on a thorough understanding of the process and only when the reason(s) for a special cause has been established. Otherwise, the whole idea of SPC as a way of understanding variation and its sources is lost. 10.4 Freezing baseline period When data have been collected for a long enough period of time to establish the centre line and control limits of a stable and predictable process – that is, a process with only common cause variation – it is often useful to “freeze” the limits and use them for future data. In production industry this technique is referred to as phase one and phase two studies. In healthcare freezing is especially useful when we have historical data from before the start of some type of intervention or improvement programme. When plotting future data with the centre line and control limits from a stable baseline period shifts and trends will show up faster than if the limits were recalculated with every new data point. The cdi dataset comes with qicharts2 and contains monthly counts of infections two years before and one year after the initiation of an improvement programme. Check the documentation for details, ?cdi. qic(month, n, data = cdi, freeze = 24) Figure 10.4: Infections before and after intervention Figure 10.4 shows a run chart of data where the centre line has been established from the baseline period (month 1-24) using the freeze argument. After the intervention, marked by the dotted vertical line, there is a sustained shift in data in the desired direction. 10.5 Splitting chart by period When a sustained shift in data has been discovered and the cause is known it is allowable to split the graph by periods. We use the part argument for this (Figure 10.5). qic(month, n, data = cdi, part = 24) Figure 10.5: Splitting using index The part argument takes either the indices of the data points to split after, or a categorical variable naming the time periods in which case the periods will be labelled (Figure 10.6). qic(month, n, data = cdi, part = period) Figure 10.6: Splitting using a period variable As with excluding data points, splitting should be based on deliberate decisions and thorough understanding of the process. Some SPC applications allow for automatic splitting whenever a shift is detected. We strongly advise against this approach. Splitting may be useful when: there is a sustained shift in data the reason for the shift is known the shift is in the desired direction the shift is expected to continue If any of these conditions is not met we should rather look for the root cause and – if need be – eliminate it. Because we now have data from two very different but stable processes we may choose to add control limits to better detect future changes, especially freaks, in process behaviour (Figure 10.7). qic(month, n, data = cdi, part = period, chart = &#39;c&#39;) Figure 10.7: Splitting using a period variable 10.6 Small multiple plots for multivariate data Process data is all about time. But often data – not the least in healthcare – have more dimensions, which are important to understand in order to interpret data correctly. For example, the hospital_infections dataset, which is also included in the qicharts2 package, contains monthly counts of three types of hospital infections: bacteremia (BAC), C. diff. (CDI), and urinary tract infections (UTI) from six hospitals: AHH, BFH, BOH, HGH, NOH, RGH. # show the first six rows of the hospitals_infections dataset head(hospital_infections) ## hospital infection month n days ## 1 AHH BAC 2015-01-01 17 17233.67 ## 2 AHH BAC 2015-02-01 18 15308.25 ## 3 AHH BAC 2015-03-01 17 16883.67 ## 4 AHH BAC 2015-04-01 10 15463.83 ## 5 AHH BAC 2015-05-01 13 15788.96 ## 6 AHH BAC 2015-06-01 14 15660.04 In addition to the time dimension, these data have two extra dimensions, infection and hospital. Figure 10.8 shows the total (aggregated) monthly counts of hospital associated urinary tract infections from six hospitals. qic(month, n, days, data = subset(hospital_infections, infection == &#39;UTI&#39;), chart = &#39;u&#39;, multiply = 10000, title = &#39;Urinary tract infections&#39;, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 10.8: Aggregated U chart of urinary tract infections from six hospital Figure 10.9 shows the same data as Figure 10.8, but this time data have been stratified into so-called small multiple plots – one plot per hospital. qic(month, n, days, data = subset(hospital_infections, infection == &#39;UTI&#39;), chart = &#39;u&#39;, multiply = 10000, facets = ~hospital, # stratify by hospital ncol = 2, # two-column arrangement of plots title = &#39;Urinary tract infections&#39;, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 10.9: Stratified (small multiple) U charts of urinary tract infections from six hospital In the litterature, small multiples are also known as trellis, lattice, or grid plots. Likewise, we may construct a small multiple plot of different infection types from one hospital (Figure 10.10). qic(month, n, days, data = subset(hospital_infections, hospital == &#39;NOH&#39;), chart = &#39;u&#39;, multiply = 10000, facets = ~infection, # stratify by infection type ncol = 1, title = &#39;Hospital infections&#39;, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 10.10: U charts from one hospital stratified by infection type By default, qic() uses fixed axis scales. This makes it easy to compare both the indicator levels (y-axis) and the patterns of variation over time (x-axis) between facets. However, sometimes it makes little sense to compare levels from very different indicators as in this example where different types of infections occur at very different rates. Because urinary tract infections is much more frequent that the other two types of infection, it is hard to interpret the patterns over time from these. In Figure 10.11 we use individual y-axes. qic(month, n, days, data = subset(hospital_infections, hospital == &#39;NOH&#39;), chart = &#39;u&#39;, multiply = 10000, facets = ~infection, scales = &#39;free_y&#39;, # free y-axes ncol = 1, title = &#39;Hospital infections&#39;, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 10.11: Small multiple plot with individual y-axes The decision about when to use fixed or free axis scales should be taken deliberately depending on the purpose of the plot. Sometimes it may even be useful to display both plots with fixed and free axes side by side. Finally, we may want to display both dimensions, infection and hospital, at the same time as in Figure 10.12. qic(month, n, days, data = hospital_infections, chart = &#39;u&#39;, multiply = 10000, facets = infection ~ hospital, # two-dimensional faceting scales = &#39;free_y&#39;, title = &#39;Hospital infections&#39;, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 10.12: Hospital infections stratified by infection and hospital 10.6.1 To aggregate or not to aggregate When data come from multiple organisational units, for example hospitals or hospital departments, we must decide if we want to aggregate or stratify data. Figures 10.8 and 10.9 demonstrate the difference. Notice how the aggregated data show no signs of special causes while the stratified data show shifts in two hospitals (BOH and NOH). If data, as in this case, move in different directions in two or more units, aggregation has a tendency to mask or cancel out special causes. However, when minor shifts in data, that are too small to produce signals in the small multiple plots, move in the same direction the shifts tend to add up resulting in a better chance of detecting the special cause with aggregated data. As usual, the decision to aggregate or stratify must be taken deliberately by persons with a thorough understanding of the structures and processes that have produced data. And often it may be useful to produce several plots at different levels of aggregation. 10.7 qicharts2 in short qicharts2 is an R package for constructing SPC charts aimed specifically at healthcare but usefull in many other areas. Besides functions for the most commonly used SPC charts, qicharts2 has a number of specialist charts for rare events data and count data with very large denominators. References ———. 2018. “qicharts2: Quality Improvement Charts for R.” JOSS. https://doi.org/10.21105/joss.0069. ———. 2024. Qicharts2: Quality Improvement Charts. https://CRAN.R-project.org/package=qicharts2. "],["case-1.html", "Chapter 11 Case 1:", " Chapter 11 Case 1: "],["screenedmr.html", "Chapter 12 Screened I Chart – eliminating freak moving ranges before calculating limits", " Chapter 12 Screened I Chart – eliminating freak moving ranges before calculating limits As detailed in earlier chapters, control limits are designed to represent the natural, common cause variation and thereby enclose (almost) all data points from a stable process. To estimate the common cause variation we use the within subgroup variation. However, if the subgroups consist of single data elements, as is the case with I charts, there is no within subgroup variation to be calculated. Instead, we use the moving ranges, that is the absolute differences between consecutive data points. Thus, two subgroups is used to define the “within” subgroup variation. Consequently, if a shift occurs between two subgroups, this will affect the moving range at this point and possible produce a signal on the moving range chart. For example, take these 24 “random” numbers: 18 16 8 9 10 11 26 14 15 14 18 19 18 11 28 20 16 17 12 13 24 16 15 11 The average moving range (AMR) is 5. From Table 6.1 we find that the natural upper AMR limit is 3.267 x AMR (= 16.3). Consequently, the range between observations numbers 14 and 15 (|28 – 11| = 17) is unusually large as shown by the moving range chart in Figure 12.1. qic(y, chart = &#39;mr&#39;, title = &#39;Moving range chart&#39;) Figure 12.1: Moving range chart with one range above the control limit Some experts recommend removing extreme moving ranges before calculating the control limits for the corresponding I chart (Nelson 1982), as this can slightly improve the chart’s sensitivity. qicharts2 does this by default as shown in Figure 12.2. # default is to screen moving ranges before calculating control limits qic(y, chart = &#39;i&#39;, title = &#39;I chart with screened MRs&#39;) Figure 12.2: I chart with control limits calculated after removing freak moving ranges To remove extreme moving ranges, first calculate AMR on the original data (= 5), then remove any MRs greater than 3.267 x AMR (= 16.335) and recalculate AMR (= 4.45). Finally, use the screened AMR to calculate the control limits of the I chart (= 15.8 \\(\\pm\\) 2.66 x 4.45). To suppress the screening of moving ranges before calculating control limits for I charts (and prime charts) in qicharts2, we can set the qic.screenedmr option to FALSE before plotting as in Figure 12.3: # suppress screening of moving ranges options(qic.screenedmr = FALSE) qic(y, chart = &#39;i&#39;, title = &#39;I chart without screened MRs&#39;) Figure 12.3: I chart with control limits calculated without removing extreme ranges # reset screening option to default options(qic.screenedmr = TRUE) As expected, the control limits on the unscreened chart is sightly wider than on the screened chart. In this example, just enough to suppress a signal that would otherwise have been discovered. One may argue that screening moving ranges is unnecessary as long as the moving range chart is shown alongside the I chart. However, in our experience, presenting moving range charts to non-technical SPC users rarely adds meaningful insight and can sometimes cause confusion. As a result, we prefer to enhance the sensitivity of I charts by excluding extreme moving ranges before calculating control limits while leaving the use and interpretation of moving range charts to data analyst. References Nelson, Lloyd S. 1982. “Control Charts for Individual Measurements.” Journal of Quality Technology 14 (3): 172–73. https://doi.org/10.1080/00224065.1982.11978811. "],["spc-charts-for-rare-events.html", "Chapter 13 SPC Charts for Rare Events 13.1 Introducing the birth dataset 13.2 G charts for opportunities between cases 13.3 T charts for time between events 13.4 The Bernoulli CUSUM chart for binary data 13.5 Selecting the rigth chart for rare events", " Chapter 13 SPC Charts for Rare Events When dealing with potentially serious or fatal events, the number of occurrences is often (fortunately) very low, which can present challenges for traditional SPC charts designed for count data. The challenge arises because traditional SPC charts for count data – like P and U charts – assume a relatively higher and more consistent frequency of events to function effectively. When counts are low, the data becomes sparse and highly variable, making these charts unreliable. Sparse data can produce lower control limits that are censored at zero, thereby invalidating the 3-sigma test in that direction. Additionally, runs charts become problematic when more than half of the data points are zero, as this causes the median to also be zero. This undermines the validity of the runs analysis – resulting in just one long run above the median. One useful approach to handling rare events is to plot the number of opportunities or the time between events, rather than focusing on event proportions or rates – essentially flipping the indicator to look at the gaps between occurrences instead of the occurrences themselves. Another approach is to look at the cumulated sums (CUSUM) of binary data. In this chapter we introduce the G chart for number of opportunities between events, the T chart for time between events, and the Bernoulli CUSUM chart for binary data. 13.1 Introducing the birth dataset The Robson group 1 births dataset is a data frame with 2193 observations from Robson group 1 deliveries, that is: first time pregnancy, single baby, head first, gestational age at least 37 weeks. # import data births &lt;- read.csv(&#39;data/robson1_births.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(&#39;POSIXct&#39;, &#39;Date&#39;, &#39;logical&#39;, &#39;logical&#39;, &#39;factor&#39;, &#39;integer&#39;, &#39;integer&#39;, &#39;integer&#39;, &#39;double&#39;, &#39;logical&#39;)) # make sure the rows are sorted in time order births &lt;- births[order(births$datetime), ] # add dummy variable, case, for counting the denominator for the proportion charts births$case &lt;- 1 # show data structure str(births) ## &#39;data.frame&#39;: 2193 obs. of 11 variables: ## $ datetime: POSIXct, format: &quot;2016-01-04 06:13:00&quot; &quot;2016-01-04 07:20:00&quot; ... ## $ biweek : Date, format: &quot;2016-01-04&quot; &quot;2016-01-04&quot; ... ## $ csect : logi FALSE FALSE FALSE FALSE FALSE FALSE ... ## $ cup : logi FALSE FALSE FALSE FALSE TRUE TRUE ... ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 2 2 2 2 1 2 2 2 ... ## $ length : int 55 52 50 47 55 50 50 47 50 53 ... ## $ weight : int 3872 3750 3458 3145 4224 2730 3130 2755 3270 3645 ... ## $ apgar : int 10 10 10 10 10 10 10 10 10 10 ... ## $ ph : num 7.1 7.26 7.36 7.31 7.16 7.14 7.23 7.21 7.17 7.2 ... ## $ asphyxia: logi FALSE FALSE FALSE FALSE FALSE FALSE ... ## $ case : num 1 1 1 1 1 1 1 1 1 1 ... For this chapter we are interested in the asphyxia variable, which is a logical vector that is TRUE when the baby had either low apgar score or low umbilical cord pH suggesting lack of oxygen during delivery. Asphyxia is a very serious condition that may result in permanent brain damage or death. In total, there are 16 cases corresponding to 0.7%. Figure 13.1 is a run chart of the biweekly counts. # run chart of counts qic(biweek, asphyxia, data = births, agg.fun = &#39;sum&#39;) # use sum() function to aggregate data by subgroup ## Subgroup size &gt; 1. Data have been aggregated using sum(). Figure 13.1: Run chart of number of deliveries with neonatal asphyxia Notice that because more than half the data points are zero, the centre line (median) is also zero. This invalidates the runs analysis – there is only one very long run, which may lead to the false conclusion that data contains one or more shifts. Figure 13.3 plots proportions rather than counts reaching the same conclusion. # run chart of proportions qic(biweek, asphyxia, case, # use the case variable for denominators data = births) Figure 13.2: Run chart of proportion deliveries with neonatal asphyxia Plotting the data on a P chart provides control limits and allows for a more meaningful runs analysis – as the average, in this case, better represents the process centre (Figure 13.3). # P chart qic(biweek, asphyxia, case, data = births, chart = &#39;p&#39;) Figure 13.3: P chart of percent deliveries with neonatal asphyxia While this P chart remains useful, the lower control limit is zero, making it impossible to detect a signal of improvement using the 3-sigma rule. As a result, we must rely solely on runs analysis to identify improvement. One obvious solution is to increase the subgroup size by aggregating data over longer periods, such as months or quarters. However, this approach results in slower detection of process improvement or deterioration. As an alternative, we introduce at the G chart. 13.2 G charts for opportunities between cases The G chart plots opportunities between cases, for example the number of deliveries between neonatal asphyxia. This type of count data often follows a geometric distribution with a standard deviation given by \\(\\sigma = \\sqrt{\\bar{x}(\\bar{x}+1)}\\). The control limits are then calculated as: \\[\\bar{x}\\pm3\\sqrt{\\bar{x}(\\bar{x}+1)}\\] where \\(\\bar{x}\\) is the average number of opportunities between cases. To obtain the number-between variable, we calculate the differences between the indices of cases (remember to first sort the data in time order). # get indices of asphyxia cases asph_cases &lt;- which(births$asphyxia) # calculate the number of deliveries between cases asph_g &lt;- diff(asph_cases) # plot G chart qic(asph_g, chart = &#39;g&#39;) Figure 13.4: G chart of deliveries between neonatal asphyxia Since the geometric distribution is highly skewed, the average is not ideal for runs analysis, which assumes the data are symmetrically distributed around the centre. Instead, the median may be used – as is done by default in qicharts2 (Figure 13.4). As is the case with the other SPC charts for counts data, negative lower control limits are rounded to 0, as values below this is not possible. Note that process improvement – as in fewer cases – will present itself as the curve going up. To trigger a 3-sigma signal we would – in this case – need at least 518 successive deliveries without asphyxia. Thus, G charts are useful alternatives to P charts when occurrences are rare and the primary interest is in detecting process improvement. However, one chart does not exclude the other, and P and G charts go well together. The P chart may be more familiar to users and is more useful for signalling process deterioration, while the G charts helps trigger signals of improvement. 13.3 T charts for time between events The T chart plots the time between events – a continuous variable. While it is possible to use an I chart to plot such data, this approach may be problematic. If events occur according to a Poisson distribution – which is often the case – the time between events is more appropriately modelled by the exponential distribution, which is highly skewed. One way to address this issue is to transform the data prior to plotting it on an I chart. An appropriate transformation is given by: \\[x = y^{(1 / 3.6)}\\] where \\(x\\) is the transformed variable and \\(y\\) is the original time between events variable. Control limits can then be calculated for the transformed data using the standard I chart procedure. However, the transformed values may be difficult to interpret. A better approach is to plot the original values alongside back-transformed control limits and centre line. The back-transformation is: \\[y=x^{3.6}\\]. # get time between events asph_t &lt;- diff(c(births$datetime[asph_cases])) # plot T chart qic(asph_t, chart = &#39;t&#39;) Figure 13.5: T chart of time (days) between deliveries with neonatal asphyxia Note that T charts do not accommodate zero time between events – a situation that may arise when time is not recorded with sufficiently high resolution. For example, if two events – such as patient falls – occur on the same day and the time of day is not recorded, the time variable is not truly continuous. In such cases, a G chart plotting days between events, a discrete variable, may be more appropriate. In fact, to our eyes, the control limits on the T chart in Figure 13.5 appear unnaturally wide. The upper control limit indicates that at least 190 days (or 27 weeks) must pass without any asphyxia cases before a signal is triggered. This suggests to us that these asphyxia cases (being discrete cases rather than random events) may not be suitable for analysis with a T chart. 13.4 The Bernoulli CUSUM chart for binary data The Bernoulli CUSUM chart (also known as the B chart) is a specialized control chart used to detect small shifts in the proportion of binary outcomes (e.g., pass/fail, success/failure) over time (Neuburger et al. 2017). It operates on a logical vector (TRUE/FALSE), where each observation contributes to a trace statistic, computed as the cumulative sum of deviations from a predefined target proportion. The trace value \\(s_i\\) at time \\(i\\) is updated recursively: \\[s_i=s_{i-1}+ increment\\ based\\ on\\ current\\ value\\] When the current observation \\(x_i\\) is TRUE (i.e., an event of interest occurs), the trace increases; when \\(x_i\\) is FALSE, the trace decreases. The size of each increment is determined by both the target proportion and the magnitude of the shift the chart is designed to detect. This design allows the B chart to accumulate evidence over time, enhancing sensitivity to sustained deviations from the target. If \\(x_i\\) = TRUE: \\[s_i=s_{i-1}+logOR-log(1+p_0(OR-1))\\] If \\(x_i\\) = FALSE: \\[s_i=s_{i-1}-log(1-p_0(OR-1))\\] Here: \\(s_i\\) is the CUSUM statistic at time i \\(p_0\\) is the target (or baseline) proportion \\(OR\\) is the odds ratio representing the smallest shift the chart should detect For example, setting OR = 2 configures the chart to detect a doubling of the target proportion p0. If the trace remains near zero, it means that the process is operating close to target. bchart(births$asphyxia, target = 0.007, or = 2, limit = 3.5) Figure 13.6: B chart of newborns with asphyxia Figure 13.6 places the asphyxia data in a B chart constructed using the bchart() function from the qicharts2 package. The target value corresponds to the known baseline proportion of asphyxia cases with default values for odds ratio (= 2) and limits (= ±3.5). Several key features are worth noting: The chart displays two cumulative traces: the upper trace is configured to detect an increase from the target proportion – specifically, a doubling in odds (OR = 2) – while the lower trace is tuned to detect a decrease (OR = 0.5). The trace values have no intrinsic meaning beyond their directional movement – they increase in response to TRUE values and decrease in response to FALSE values. The magnitude of the trace simply reflects the cumulative deviation from the target, not the severity or frequency of events in absolute terms. Traces reset to zero whenever they cross the horizontal axis or a control limit, allowing the chart to remain responsive to new patterns of deviation. The control limits are user-defined, rather than statistically derived. Their placement represents a compromise between desired sensitivity (the ability to detect true shifts) and specificity (resistance to false alarms). By default, the limits are set at ±3.5. More on how to chose limits later. Figure 13.7 compares our results against a target proportion of 2%. bchart(births$asphyxia, target = 0.02) Figure 13.7: B chart of newborns with asphyxia, target = 0.2% The lower trace signals repeatably suggesting that the current process is not centred around a target of 2% – specifically, it indicates that the process is performing better than expected. And vice versa, comparing to a target of 0.1% indicates that the process is performing worse than expected (Figure 13.8). bchart(births$asphyxia, target = 0.001) Figure 13.8: B chart of newborns with asphyxia, target = 0.01% Control limits for B charts are user-defined and reflect a trade-off between sensitivity and specificity. A common default is ±3.5, suitable for detecting a doubling or halving of the event rate. Tighter limits increase sensitivity but may lead to more false alarms; wider limits reduce false positives but may miss smaller shifts. The best choice depends on context, such as the number of available observations, size of the shift to be detected, and the consequences of missing a signal or triggering a false one. In practice, limits are often chosen based on simulation, historical data, and domain knowledge – particularly considering the cost or impact of missed detections versus false alerts. See Neuburger et al. (2017) for details and guidelines on how to select control limits. Inspecting Figure 13.6, which shows a historically stable process based on 2000+ observations and with most or all data points clustered around the centre line, we might conclude that it would be appropriate to tighten the control limits to ±3 or even ±2.5, as demonstrated in Figure 13.9. bchart(births$asphyxia, target = 0.007, limit = 2.5) Figure 13.9: B chart of newborns with asphyxia, target = 0.01% 13.5 Selecting the rigth chart for rare events After reviewing various alternative charting options for rare events – U and T charts for low event rates, and P, G, and B charts for low case proportions – we may ask: which should we prefer? Well, that depends. No single chart is universally superior – and often, presenting two or more charts together can provide complementary insights. In particular, we always recommend pairing a T or G chart with its corresponding U or P chart, as these pairs may offer a more complete picture of the process by highlighting both improvement and deterioration. The B chart, in particular, is a powerful tool, but it requires careful attention and specialist knowledge to construct and interpret effectively. Its diagnostic performance is highly sensitive to the choice of parameters — target, odds ratio, and control limits – and these should be selected by individuals with a strong understanding of the underlying process. That said, the default settings – an odds ratio of 2 and control limits at ±3.5 – are generally suitable for most processes where the baseline (target) rate is around 1%, and where the goal is to detect a doubling or halving of the event rate relative to that target. References Neuburger, Jenny, Kate Walker, Chris Sherlaw-Johnson, Jan van der Meulen, and David A Cromwell. 2017. “Comparison of Control Charts for Monitoring Clinical Performance Using Binary Data.” BMJ Quality &amp; Safety 26 (11): 919–28. https://doi.org/10.1136/bmjqs-2016-005526. "],["prime-charts-for-count-data-with-very-large-subgroups.html", "Chapter 14 Prime Charts for Count Data with Very Large Subgroups 14.1 Laney’s prime chart 14.2 When to use prime charts Example data for P prime charts", " Chapter 14 Prime Charts for Count Data with Very Large Subgroups With count data involving very large subgroup sizes, SPC charts often produce very tight control limits with many data points outside the limits. Figure 14.1 demonstrates this phenomenon, known as overdispersion, using data from from Mohammed A. Mohammed et al. (2013) included in qicharts2 (data are tabulated at the end of this chapter). Figure 14.1: P chart of percent emergency attendances seen within 4 hours This can suggest that the process is highly unstable, even when such a conclusion may not be warranted. Overdispersion occurs when the natural, common cause variation in the data exceeds what is expected under the assumed theoretical distribution – binomial for proportions and Poisson for rates. To diagnose this issue, we can plot the data on an I chart, which bases its control limits on the natural variation between successive subgroups rather than on theoretical distributional assumptions. Figure 14.2 is an I chart of the data from Figure 14.1 suggesting only common cause variation. Figure 14.2: I chart of percent emergency attendances seen within 4 hours As a general rule of thumb, when the control limits from an I chart differ significantly from those of the P or U chart, this suggests that the observed variation is inconsistent with the assumed binomial or Poisson models underlying the P and U charts, respectively. Several solution to the problem with overdispersion and tight control limits have been proposed. The obvious pragmatic solution is to simply use I charts for count data as well as for (individual) measurements. However, I charts have straight control limits that do not account for varying subgroup sizes. If the subgroup sizes only vary little, this may not be a problem. But sometimes – not the least in healthcare – varying subgroup sizes matter. Laney proposed a solution that adjusts the assumed within subgroup variation in count data by a factor based on the moving ranges of successive standardised data points (\\(\\sigma_z\\)) (Laney 2002). 14.1 Laney’s prime chart As shown earlier in Table 6.1, the control limits for a traditional P chart are calculated as: \\[\\bar{p}\\pm3\\sigma_{pi}\\] where \\(\\bar{p}\\) is the average proportion and \\(\\sigma_{pi}\\) is the within-subgroup standard deviation for the i-th subgroup: \\[\\sigma_{pi}=\\sqrt{\\bar{p}(1-\\bar{p})/{n_{i}}}\\] where \\(n_i\\) is the sample size of the i-th subgroup. The P′ chart (pronounced P prime chart) accounts for both within and between subgroup variation. The control limits are given by: \\[\\bar{p}\\pm3\\sigma_{pi}\\sigma_z\\] where \\(\\sigma_z\\) represents the between-subgroup variation, calculated using the moving ranges of the standardised proportions defined as: \\[z_i=(p_i - \\bar{p})/\\sigma_{pi}\\] The moving ranges are: \\[MR_i=|z_i-z_{i-1}|\\] Then, the estimated between-subgroup variation \\(\\sigma_z\\) is the average moving range devided by the constant 1.128: \\[\\sigma_z=\\overline{MR_z}/1.128\\] Thus, the control limits for the P′ chart are: \\[\\bar{p}\\pm3\\sigma_{pi}\\sigma_z \\] Figure 14.3: P’ chart of percent emergency attendances seen within 4 hours The control limits in Figure 14.3 are very close to the I chart limits from Figure 14.3, but vary slightly due to varying subgroup sizes. Similarly, control limits for the U’ chart are: \\[\\bar{u}\\pm3\\sigma_{ui}\\sigma_z\\] where \\(\\sigma_{ui}=\\sqrt{\\bar{u}/n_i}\\) and \\(\\sigma_{z}=\\overline{MR_z}/1.128\\); and the moving ranges are computed from the standardised rates defined as \\(z_i=(u_i-\\bar{u})/\\sigma_{ui}\\). Note that in qicharts2, the moving ranges of the standardized values are, by default, screened for extreme values – following the same approach used for I charts, as described in Chapter 12. 14.2 When to use prime charts Laney’s prime charts were developed to handle overdispersion (and underdispersion), that is, when data show more (or less) variation than expected under a binomial or Poisson distribution, which is often seen with very large subgroup sizes. But how do we know when to suspect overdispersion? A red flag is when a traditional P or U chart shows unusually tight control limits that seem unnatural. If plotting the same data on an I chart produces significantly wider control limits, it is a strong indication that the assumptions behind the P or U chart may not hold. In such cases, switching to Laney’s P’ or U’ charts is typically the better choice. Note that when the adjustment factor (\\(\\sigma_z\\)) is close to one – indicating little to no overdispersion – the Laney P′ or U′ chart closely resembles the traditional P or U chart. For this reason, Laney recommends using prime charts as a generally safe and robust default. In the next chapter, we will explore a modified I chart – the I’ (I prime) chart – which generates control limits for count data that closely align with Laney’s prime charts, while also accommodating measurement data with varying subgroup sizes. Example data for P prime charts Table 14.1: The number of attendances to major accident and emergency hospital departments in the NHS that were seen within 4 hours of arrival over twenty weeks. Source: (Mohammed A. Mohammed et al. 2013) Week (i) Attendances seen within 4 hours (r) Number of attendances (n) 1 266,501 280,443 2 264,225 276,823 3 276,532 291,681 4 281,461 296,155 5 269,071 282,343 6 261,215 275,888 7 270,409 283,867 8 279,778 295,251 9 270,483 284,468 10 270,320 282,529 11 267,923 279,618 12 271,478 283,932 13 255,353 266,629 14 256,820 268,091 15 261,835 276,803 16 259,144 271,578 17 255,910 266,005 18 260,863 273,520 19 264,465 278,574 20 260,989 273,772 References Laney, David B. 2002. “Improved Control Charts for Attributes.” Quality Engineering 14: 531–37. Mohammed, Mohammed A, Jagdeep S Panesar, David B Laney, and Richard Wilson. 2013. “Statistical Process Control Charts for Attribute Data Involving Very Large Sample Sizes: A Review of Problems and Solutions.” BMJ Quality &amp; Safety 22 (4): 362–68. https://doi.org/10.1136/bmjqs-2012-001373. "],["i-prime-chart-for-measurement-data-with-variable-subgroup-sizes-and-more.html", "Chapter 15 I Prime Chart for Measurement Data With Variable Subgroup Sizes (and more) 15.1 I’ charts for measument data with variable subgroup sizes 15.2 One chart to rule them all?", " Chapter 15 I Prime Chart for Measurement Data With Variable Subgroup Sizes (and more) The I chart is often regarded as the Swiss Army knife of SPC. It is useful in many situations and can frequently serve as a valid – or even superior – alternative to other Shewhart SPC charts. This is partly because the I chart is based on the empirical variation in data, rather than on theoretical distributional assumptions, which may or may not be true. However, the I chart does not account for variable subgroup sizes – that is, when the area of opportunity varies between samples, such as when the number of patients fluctuates from month to month. This produces straight control limits, which in some situations may generate false signals or fail to detect true ones. When the variation is small, this may not pose a problem, but often – not the least in healthcare – size matters. Several solutions have been proposed. Here we present the normalised I chart or, as we prefer to name it, the I prime (I’) chart suggested by Taylor (2018). In summary: The I’ chart accounts for variable subgroup sizes by adjusting the within subgroup standard deviation with a factor that depends on the size of each subgroup producing wavy control limits when subgroup sizes vary. The I’ chart is useful for measurement and count data with or without denominators. With constant subgroup sizes, the I’ chart is an exact match for the original I chart. For rates and proportions, the I’ chart produces control limits that match those of the U' and P' charts. Figure 15.1 shows an I’ and a P’ chart side-by-side demonstrating their similar results. qic(month, deaths, admissions, data = admis, chart = &#39;ip&#39;, y.percent = T, title = &quot;I&#39; chart of hospital mortality&quot;, xlab = &#39;Month&#39;) qic(month, deaths, admissions, data = admis, chart = &#39;pp&#39;, title = &quot;P&#39; chart of hospital mortality&quot;, xlab = &#39;Month&#39;) Figure 15.1: Comparing I’ and P’ charts 15.0.1 Procedure for calculating centre line and control limits We use the following symbols: \\(n\\) = numerators \\(d\\) = denominators \\(o\\) = number of data values (subgroups) \\(i\\) = ith data value Values to plot: \\[ y = \\frac{n}{d} \\] Centre line: \\[ CL = \\frac{\\sum{n}}{\\sum{d}} \\] Standard deviation of ith data point: \\[ s_i = \\sqrt{\\frac{\\pi}{2}}\\frac{\\vert{}y_i-y_{i-1}\\vert{}}{\\sqrt{\\frac{1}{d_i}+\\frac{1}{d_{i-1}}}} \\] Average standard deviation: \\[ \\bar{s} = \\frac{\\sum{s}}{o} \\] Control limits: \\[ \\text{control limits} = CL \\pm 3 \\frac{\\bar{s}}{\\sqrt{d_i}} \\] When subgroup sizes equals 1, the control limits simplify to: \\(CL \\pm 2.66\\overline{MR}\\) as in the original I chart. As with the original I chart, qicharts2 screens the moving ranges of \\(s_i\\), removing ranges greater than the theoretical upper natural limit (= 3.2665) before calculating \\(\\bar{s}\\). 15.1 I’ charts for measument data with variable subgroup sizes Figure 15.1 demonstrates the use of an I’ chart with count data. However, the I’ chart was originally intended for use with measurement data where subgroup sizes vary. For example, due to privacy considerations, we may only have access to averaged patient data rather than individual records. Traditionally, such data would be plotted on an original I chart, but if the number of patients in each subgroup varies significantly, straight control limits may be suboptimal. Figure 15.2 is an I chart of the monthly HbA1c averages from the Diabetes HbA1c dataset. Notice the data point above the upper control limit in April 2020 suggesting a special cause. However, when plotting aggregated measurement data, the I chart does not account for variations in subgroup size. qic(month, avg_hba1c, data = diabetes, chart = &#39;i&#39;, title = NULL, ylab = &#39;mmol / mol&#39;, xlab = &#39;Month&#39;) Figure 15.2: I chart of average HbA1c without denominator The I’ chart in Figure 15.3 takes the subgroup size (number of patients) into account and adjusts the control limits correspondingly. qic(month, avg_hba1c * n, n, data = diabetes, chart = &#39;ip&#39;, title = NULL, ylab = &#39;mmol / mol&#39;, xlab = &#39;Month&#39;) Figure 15.3: I prime chart of average HbA1c with denominator April 2020 was the first month of lockdown during Covid-19 in Denmark, and the number of patients (the denominator) seen during this month was significantly lower than usual, which allowed for larger than usual common cause variation in measurements and consequently wider control limits this month. So, when the subgroup size is taken into account, the apparent special cause in Figure 15.2 is actually within the limits of the expected common cause variation. Also, notice that the centre lines are a bit different (60.6 vs 60.3), because the I prime chart uses the weighted rather than the unweighted mean of the measurements. Note that in order to plot the averages we need to multiply the numerators (avg_hba1c, which are already averaged) by the denominators (n) to get the sum of individual measurements to use as the new numerator. Otherwise, the result would be a plot of averages of averages. 15.2 One chart to rule them all? The I’ chart produces results that match the original I chart for individual measurements and P’ and U’ charts for proportion and count data. If we accept Laney’s claim that prime charts are valid – or even better – substitutes for their non-prime counterparts, it is tempting to conclude that the I’ chart offers a universal solution to most, if not all, of our charting needs. In conclusion, while the I’ chart is a recent development, its versatility and ability to mimic the behaviour of traditional SPC charts make it a compelling alternative, that has the potential to streamline chart selection by serving as a single, robust option across various data types and scenarios. As the methodology continues to gain empirical support, the I’ chart may well become the preferred tool for modern quality control. References Taylor, Wayne. 2018. Normalized Individuals (IN) Control Chart. https://variation.com/normalized-individuals-control-chart/. "],["funnel-plots-for-categorical-subgroups.html", "Chapter 16 Funnel Plots for Categorical Subgroups", " Chapter 16 Funnel Plots for Categorical Subgroups Funnel plots are SPC charts with categorical subgroups, which are often sorted after size to produce funnel shaped control limits. Funnel plots are useful for comparing indicator levels from different categories, for example complication rates from different hospitals. Figure 16.1 compares the levels of some indicator across six organisational units. One unit (E) falls below the lower control limit, indicating that its data may reflect a fundamentally different process compared to the others. Figure 16.1: Funnel plot Because funnel plots do not involve a natural time sequence, data points are not connected by lines, and run analysis is not applicable. To demonstrate the construction of funnel plots we use data on urinary tract infections from the hospital_infections dataset from qicharts2. # get urinary tract infections from hospital infections data uti &lt;- hospital_infections[hospital_infections$infection == &#39;UTI&#39;,] # plot U chart qic(month, n, days, data = uti, chart = &#39;u&#39;, multiply = 10000, facets = ~hospital, ncol = 2, title = &#39;Hospital acquired urinary tract infections in six hospitals&#39;, ylab = &#39;Infections per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 16.2: U chart of urinary tract infections Figure 16.2 is a traditional U chart of infection rates in six hospital. There are signals of special cause variation in two hospitals (BOH, NOH), which makes direct comparison of infection rates between hospitals pointless – it makes no sense to compare levels from data that are moving. It is therefore important to select data from a recent and stable period of time before constructing funnel plots. In Figure 16.3 we have selected data from the most recent quarter and plotted them using hospital (rather than time) as the subgrouping variable. # filter data to latest quarter uti_2016q4 &lt;- uti[uti$month &gt;= &#39;2016-10-01&#39;, ] # plot &quot;funnel&quot; plot qic(hospital, n, days, data = uti_2016q4, chart = &#39;u&#39;, multiply = 10000, title = &#39;Hospital acquired urinary tract infections in six hospitals&#39;, ylab = &#39;Infections per 10,000 risk days&#39;, xlab = &#39;Hospital&#39;) Figure 16.3: Unordered ‘funnel’ plot of urinary tract infections By default the x-axis will be sorted alphabetically. To produce a funnel plot, we need to sort the subgroups by size as is shown in Figure 16.4. # order hospitals by denominator (risk days) to produce funnel qic(reorder(hospital, days), n, days, data = uti_2016q4, chart = &#39;u&#39;, multiply = 10000, title = &#39;Hospital acquired urinary tract infections in six hospitals&#39;, ylab = &#39;Infections per 10,000 risk days&#39;, xlab = &#39;Hospital&#39;) Figure 16.4: Ordered funnel plot of urinary tract infections In summary, funnel plots are SPC charts with categorical subgroups. They are useful for comparing indicator levels across organisational units. To ensure valid comparisons, it is essential to use data from a recent, stable period that reflects only common cause variation before constructing a funnel plot. "],["pareto-charts-for-ranking-problems.html", "Chapter 17 Pareto Charts for Ranking Problems", " Chapter 17 Pareto Charts for Ranking Problems The Pareto chart, named after Vilfred Pareto, was invented by Joseph M. Juran as a tool to identify the most important causes of a problem. For this example, we use the dataset on adverse events causing harm to patients, collected using the Global Trigger Tool method (Plessen, Kodal, and Anhøj 2012). # print structure of ae data str(ae) ## &#39;data.frame&#39;: 131 obs. of 2 variables: ## $ severity: chr &quot;E&quot; &quot;F&quot; &quot;E&quot; &quot;F&quot; ... ## $ category: chr &quot;Pressure ulcer&quot; &quot;Gastrointestinal&quot; &quot;Infection&quot; &quot;Infection&quot; ... The paretochart() function (from qicharts2) takes a categorical vector as argument and plots a Pareto chart as demonstrated in Figure 17.1. paretochart(ae$category) Figure 17.1: Pareto chart of patient harm. The bars show the count in each category, and the curve shows the cumulated percentage over categories. Almost 80% of harms come from 3 categories: gastrointestinal, infection, and procedure. Figure 17.2 is a Pareto chart of harm severity demonstrating that nearly all events resulted in temporary harm (E-F). paretochart(ae$severity) Figure 17.2: Pareto chart of harm severity: E-I, where E-F = temporary harm, G-H = permanent harm, and I = fatal harm. The paretochart() function takes a character or factor vector, but often data have already been aggregated into tabular format: ae.tbl category count 1 Fall 1 2 Gastrointestinal 40 3 Infection 34 4 Medication 18 5 Other 4 6 Pressure ulcer 5 7 Procedure 29 To make a Pareto chart from tabular data, we first need to convert data back into a vector. This can be achieved with the rep() function repeating each category by its count: # make vector from counts ae.cat &lt;- rep(ae.tbl$category, ae.tbl$count) # show first six rows of vector head(ae.cat) ## [1] Fall Gastrointestinal Gastrointestinal Gastrointestinal ## [5] Gastrointestinal Gastrointestinal ## 7 Levels: Fall Gastrointestinal Infection Medication Other ... Procedure # plot Pareto chart paretochart(ae.cat) Figure 17.3: Pareto chart constructed from tabular data. In conclusion, the Pareto chart is useful for identifying the most common causes of a problem. Often most of the problems are caused by relatively few of the causes. In the example above eliminating gastrointestinal harm (most often obstipation) and hospital associated infections would more than half the rate of adverse events. References Plessen, Christian von, Anne Marie Kodal, and Jacob Anhøj. 2012. “Experiences with Global Trigger Tool Reviews in Five Danish Hospitals: An Implementation Study.” BMJ Open 2 (5). https://doi.org/10.1136/bmjopen-2012-001324. "],["tips-for-effective-spc-implementation.html", "Chapter 18 Tips for Effective SPC Implementation", " Chapter 18 Tips for Effective SPC Implementation Automating production of SPC charts Engaging stakeholders Continuous monitoring and improvement. Problems and challenges with SPC "],["common-pitfalls-to-avoid.html", "Chapter 19 Common Pitfalls to Avoid", " Chapter 19 Common Pitfalls to Avoid Data issues, misinterpretation of charts Overreacting to common cause variation (over-sensitive runs rules, too tight control limits) Automating recalculation of control limits One-to-one relation between PDSA cycles and dots on the plot The Control Charts vs Run Charts Debate "],["high-volume-data.html", "Chapter 20 High Volume Data", " Chapter 20 High Volume Data "],["scaling-up-charts.html", "Chapter 21 Scaling Up Charts", " Chapter 21 Scaling Up Charts technical issues tabular charts grids "],["subgrouping.html", "Chapter 22 The Forgotten Art of Rational Subgrouping 22.1 Too large subgroups — masking meaningful signals 22.2 Too small subgroups — revealing unimportant noise 22.3 Striking the balance 22.4 A practical approach for rational subgrouping 22.5 Rational subgrouping “in short”", " Chapter 22 The Forgotten Art of Rational Subgrouping A subgroup consists of the data elements that make up a single data point, for example, the waiting times used to calculate the average waiting time for a particular period. Rational subgrouping is the intentional and intelligent sampling and grouping of data into data points for SPC charts with the aim of maximising the chances of detecting special cause variation while minimising the risk of false alarms. In other words, rational subgrouping is all about maximising the signal-to-noise ratio. A rational subgroup consists of a set of measurements or counts that are: produced under conditions that are as similar as possible, taken close together in time and space, and likely to show only common cause variation. The underlying logic is that when subgroups are rationally formed, variation within subgroups reflects common cause variation, whereas variation between subgroups that exceeds what is expected from within-subgroup variation indicates the presence of special causes. In our experience – particularly in healthcare – rational subgrouping is something of a forgotten art. We often rely on whatever data are readily available, which are frequently pre-aggregated into monthly, quarterly, or even yearly time periods for administrative purposes rather than for quality improvement. This practice often leads to suboptimal use of data for driving improvement. 22.1 Too large subgroups — masking meaningful signals A common mistake is forming subgroups across overly broad spans of time or space (e.g. organisational units), which blends common and special cause variation and effectively obscures the latter. As an example, figures 22.1 and 22.2 display the number of C. diff. infections subgrouped by monthly and two-monthly periods respectively. qic(month, infections, data = cdiff, chart = &#39;c&#39;, title = &#39;C. diff. infections&#39;, ylab = &#39;Count&#39;, xlab = &#39;Months&#39;) Figure 22.1: Monthly C. diff. infections. qic(month, infections, data = cdiff, chart = &#39;c&#39;, x.period = &#39;2 months&#39;, title = &#39;C. diff. infections&#39;, ylab = &#39;Count&#39;, xlab = &#39;Two-months&#39;) Figure 22.2: Two-monthly C. diff. infections. By using larger subgoups, as shown in Figure 22.2, we effectively mask the two signals – a freak value and a sustained shift – that suggest the process is trending downwards. Clearly, if the trend continues, it will eventually become apparent even with two-monthly data, but it will inevitably take longer to detect delaying any potential learning or intervention. To avoid over-aggregating data by using excessively large subgroups, we need to record data at a temporal resolution that, at minimum, matches the expected rate of change we are trying to detect. High-resolution data can always be aggregated to a lower resolution if suitable (or necessary), but low-resolution data cannot be further resolved. Note that the qic() function from qicharts2 includes an argument, x.period, which allows us to aggregate data into larger subgroups as demonstrated in the code producing Figure 22.2. 22.2 Too small subgroups — revealing unimportant noise A less common – but equally important – mistake is to form subgroups that are too small, which fail to capture natural process noise and thus misinterpret it as special cause variation.. Imagine stepping on a scale three times each morning for a couple of weeks and plotting the results on an X-bar chart, using the within-subgroup (within-day) variation as the basis for calculating control limits. Figure 22.3 illustrates this with simulated data. As expected, the variation within each daily subgroup is very low, while the variation between subgroups is noticeably higher suggesting that our body weight is highly unstable from day to day. However, this difference between within- and between-subgroup variation merely reflects natural physiological fluctuations and is irrelevant to our goal of monitoring long-term body weight trends. # lock random number generator for reproducibility set.seed(5) # subgroups, 12 subgroups of three values x &lt;- rep(1:12, each = 3) # random values, each repeated three times y &lt;- rep(rnorm(12, mean = 80, sd = 0.5), each = 3) # add a bit of random noise within subgroups y &lt;- jitter(y, amount = 0.2) # plot Xbar-chart qic(x, y, chart = &#39;xbar&#39;) Figure 22.3: Xbar-chart from too small subgroups. A better strategy would be to plot data using an I-chart of the daily averages. The I-chart uses the moving range between successive subgroups as a basis for calculating control limits, which is – in this case – a much better representation of the day-to-day variation, which is really what we want to monitor. qic(x, y, chart = &#39;i&#39;) ## Subgroup size &gt; 1. Data have been aggregated using mean(). Figure 22.4: I-chart of average daily body weight. Alternatively, we could devise a different sampling plan that produces subgroups better representing the process of interest – for example, using weekly averages of daily measurements as subgroups. Depending on our goal, different subgrouping strategies may be appropriate. If the aim is to monitor and maintain a stable body weight, weekly subgroups may be sufficient. However, if the objective is to support a weight-reduction plan expecting significant weekly decreases, daily measurements could prove more useful. 22.3 Striking the balance As the chapter title suggests, rational subgrouping is as much an art as it is a science. In fact, it remains one of the more complex and unresolved challenges in statistical process control: to understand a process, we need rational subgroups – but to form rational subgroups, we need to understand the process. In practice, we frequently need to try multiple approaches to subgrouping our data – experimenting with different timeframes, organisational units or other dimensions – before finding an approach that meaningfully reflects the underlying process behaviour. That said, in healthcare – in contrast to the production industry – there is often far less flexibility to tailor data collection to the requirements of SPC. In a production setting, where outputs are counted in the thousands and inputs are largely under control, it is possible to design highly specific sampling plans aligned to precise time intervals and structured across machinery, personnel and organisational units. In healthcare, by contrast, the smallest meaningful unit is typically the individual patient or procedure, situated within a specific organisational context or clinical pathway. Patient outcomes are shaped by a complex interplay of factors – including clinical complexity, social determinants, people, and system-level variation. Unlike components in a production process, this variability cannot be standardised or controlled with the same degree of precision. However, that does not mean that we should not care about rational subgrouping. Although we may have limited control over input variation we can still design sampling strategies that aim to minimise the impact of these sources of variation by carefully selecting patient groups, clinical pathways, organisational units and time periods that reliably reflect the processes we aim to understand. Doing so helps preserve an optimal signal-to-noise ratio, enhancing our ability to detect meaningful changes. 22.4 A practical approach for rational subgrouping There is no single ideal procedure for designing rational subgroups. As noted previously, this often requires an iterative process involving trial and error: Plan - Do - Study - Act. Here are a few suggestions for points to consider when designing rational subgroups: Consult individuals with expert knowledge of the process in question – rational subgrouping is a collaborative effort, not merely a statistical exercise. Develop a detailed model of the process – including inputs, outputs, and factors that may influence either. Consider whether your objective is monitoring or improving the process. Consider the level of organisational granularity at which the data should be analysed, and whether aggregation or stratification is appropriate. Consider the rate of change you aim to detect. Choose a timeframe that is shorter than the expected rate of change. For count data, select a timeframe expected to capture at least five events or cases (numerator), and, for proportion data, ensure there are at least five additional opportunities (denominator). Remain flexible and open to revising your sampling strategy as new insights emerge. Note that decisions about temporal and organisational granularity (#4–6) may conflict with the requirement for sufficiently large subgroups (#7) to ensure meaningful analysis. In such cases, it may be necessary to compromise or explore alternative methods to monitor the processes of interest – for example using different indicators or charts better suited for rare events. 22.5 Rational subgrouping “in short” Despite the section header, there is no truly concise way to explain rational subgrouping. It is one of the most challenging aspects of SPC to understand and apply correctly – not least because there is no single recipe for getting it right. Still, there is no excuse – getting rational subgrouping right is what separates meaningful SPC charts from those that mislead or fall short. "],["data-sets.html", "A Data Sets", " A Data Sets Datasets for this book are provided as comma separated values (csv) in text files. For details on how to read data from csv-files, see the Importing data from text files in Appendix D. Adverse Events Patient harm found with the Global Trigger Tool File: adverse_events.csv Variables: severity (character): Harm severity: E = minor transient, I = fatal category (character): Harm category Bacteremia Hospital acquired and all cause bacteremias and 30 days mortality File: bacteremia.csv Variables: month (date): month of infection ha_infections (numeric): number of hospital acquired infections risk_days (numeric): number of patient days without infection deaths (numeric): 30-day mortality after all-cause infection patients (numeric): number of patients with all-cause infection Blood pressure Daily measurements of blood pressure and resting pulse. File: blood_pressure.csv Variables: date (date): date of measurement systolic (numeric): systolic blood pressure (mm Hg) diastolic (numeric): diastolic blood pressure (mm Hg) pulse (numeric): resting pulse (beats per minute) Clostridioides difficile infections Hospital acquired C. diff. infections File: cdiff.csv Variables: month (date): first day of month cases (numeric): number of cases risk_days (numeric): number of patient days without infection Ceasearian section delay Time to grade 2 C-section File: csection_delay.csv Variables: datetime (datetime): date and time of delivery month (date): first day of month delay (numeric): time in minutes between decision and delivery Diabetes HbA1c HbA1c measurements in children with diabetes File: diabetes_hba1c.csv Variables: month (date): month of measurements avg_hba1c (numeric): average of HbA1c measurements n (integer): number of patients who visited the clinic Emergency admission mortality 7-day mortality after emergency admission File: emergency_admission.csv Variables: month (date): first day of month deaths (numeric): number of deaths within 7 days after emergency admission admissions (numeric): number of emergency admissions On-time CT Patients with acute abdomen CT scanned within 3 hours after arrival File: ontime_ct.csv Variables: month (date): first day of month ct_on_time (numeric): number of patients scanned within 3 hours cases (numeric): number of patients with acute abdomen Radiation doses Radiation doses used for renography File: renography_doses.csv Variables: date (date): date of renography week (date): first day of week dose (numeric): radiation dose in megabequerel Robson group 1 births Outcomes and complications of Robson group 1 births: first time pregnancy, single baby, head first, gestational age at least 37 weeks. File: robson1_births.csv Variables: datetime (datetime): data and time of birth biweek (date): first day of biweekly period csect (logical): delivery by C-section cup (logical): delivery by vacuum extraction sex (character): sex of baby length (numeric): baby length in cm weight (numeric): baby weight in kg apgar (numeric): apgar score at 5 minutes ph (numeric): arterial umbilical chord pH asphyxia (logical): ph &lt; 7 or missing ph and apgar &lt; 7 "],["stat-concepts.html", "B Basic Statistical Concepts B.1 Data types B.2 Summarising categorical data B.3 Summarising numerical data B.4 Theoretical distributions B.5 Basic statistical concepts in summary", " B Basic Statistical Concepts Understanding data is the cornerstone of effective decision-making in any quality improvement context. While this chapter is not intended as a comprehensive statistical tutorial, it introduces key concepts related to data types, basic statistical summaries, and visualisation techniques that support meaningful application of appropriate SPC charts and help ensure that valid data-driven conclusions can be drawn. B.1 Data types Data can be classified into several types, with the most common being categorical and numerical data. B.1.1 Categorical data Categorical data, also known as qualitative data, represent characteristics that cannot be meaningfully measured on a numerical scale, for example [red, green, blue], [medicine, surgery, psychiatry] or [low, medium, high]. Categorical data cannot be directly analysed using arithmetic operations – what is the sum of red, green and blue, for example? Categorical data can be divided into: Nominal data: Categories without a natural order, e.g. [red, green, blue] or [medicine, surgery, psychiatry]. Ordinal data: Categories with a meaningful order, but without consistent intervals between them, e.g. [low &lt; medium &lt; high]. If categorical data consist of only two possible values – such as yes/no, true/false or dead/alive – they are referred to as binary or binomial data. Categorical data can be transformed into numerical form by counting the number of observations in each category. In some (rare) cases, it may be appropriate to assign numerical values to ordinal data, such as school grades, thereby enabling the use of arithmetic operations. However, we should be careful not to impose numerical values on any ordinal data unless the intervals are consistent and well-defined. It may be tempting to converts, for instance, cancer stages [I, II, III] into numbers [1, 2, 3]. But this will only make sense, if cancer stage II is exactly twice as severe as stage I, and stage III three times as severe. Note that some categorical data – such as postal codes, insurance numbers and phone numbers – may appear numerical but are actually categorical. To identify such cases, ask whether it makes sense to calculate a sum or an average. If not, the values should be treated as categories rather than numbers. B.1.2 Numerical data Numerical data, also known as quantitative data, consist of values that represent measurable quantities. These data can be meaningfully analysed using arithmetic operations such as addition or subtraction. Numerical data fall in two main subtypes: Discrete data: Distinct, separate values that result from counting and are always expressed as whole numbers (including zero). Examples include number of pregnancies, pressure ulcers and hospital admissions. Continuous data: Values obtained through measurement that can take on any value within a given range, including decimals, fractions and negative numbers. Examples include height, weight, waiting time and blood pressure. Just as categorical data can be converted into numbers through counting, numerical data can be transformed into categories by grouping values into defined ranges — for example, converting exact blood pressure readings into hypertension categories such as normal, elevated, stage 1 hypertension, and stage 2 hypertension. B.2 Summarising categorical data In this section we use the Adverse events dataset assigned to the variable ae. As mentioned, categorical data are most commonly summarised by counting the number of observations in each category, typically presented as frequencies or proportions (or percentages). In R, this can be easily done using the table() function. # count number of adverse events in each category (ae.tbl &lt;- table(ae$category)) ## ## Fall Gastrointestinal Infection Medication ## 1 40 34 18 ## Other Pressure ulcer Procedure ## 4 5 29 A useful visualisation of categorical data is the bar chart displaying either the frequencies or proportions in each category: # plot frequencies barplot(ae.tbl) Figure B.1: Bar chart of adverse event frequencies # plot proportions barplot(prop.table(ae.tbl)) Figure B.2: Bar chart of adverse event proportions. The only difference between figures B.1 and B.2 is the y-axis scale. For binary data, a summary may simply involve calculating the proportion or percentage of one category relative to the total, for example the proportion of adverse events with fatal outcome: # proportion of fatal adverse events (severity = &#39;I&#39;). mean(ae$severity == &#39;I&#39;) ## [1] 0.007633588 B.3 Summarising numerical data For this section we use the Robson group 1 births and the Renography doses datasets assigned to the births and reno variables respectively. Numerical data are commonly summarised using three key characteristics: central tendency, distribution shape and spread (variation). In R, the summary() function provides a quick overview of all three: # summarise the length of newborn babies summary(births$length) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 35.0 50.0 52.0 51.7 53.0 60.0 3 summary() is a generic function that behaves differently depending on the type of input. With numerical input, it returns a table displaying the minimum and maximum values, the three quartiles (1st, Median, 3rd), the mean and the number of NA values (if any). Quartiles are the three values that divide a dataset into four equally sized parts. 25% of the data values fall below the first quartile, 50% fall below the second quartile (median), and 75% fall below the third quartile. A most useful visualisation of the distribution of continuous data is the histogram: hist(births$length) Figure B.3: Histogram of birth lengths. A histogram groups data into intervals, called bins, and shows how many values fall within each interval. It is similar to a bar chart, but the bars are touching to reflect the fact that the data are continuous. Note that there are much more to histograms than meets the eye. For a deeper understanding and additional options, read the documentation (?hist). B.3.1 Centre The central tendency of a dataset refers to the typical or central value around which the data points cluster. It represents the centre of the distribution. Common measures of central tendency include the mean and the median. The mean is perhaps the better-known of the two. It is calculated by summing all the values and dividing by the total number of values. For example, the mean of the values [1, 2, 3] is (1 + 2 + 3) / 3 = 2. The median – often overlooked but equally important – is the middle value when the data are sorted in order. For example, given the values [2, 1, 3], the median is 2 (remember to sort first). If there is an even number of values, the median is the mean of the two central values; for instance, for [1, 2, 3, 4], the median is 2.5. In the previous examples, the mean and the median are identical. This occurs when the data are perfectly symmetrical. However, when the data are skewed – that is, spread unevenly on either side of the centre – the mean and median can differ significantly. For example, consider the values [1, 2, 999]. The mean is 334, heavily influenced by the extreme value, whereas the median remains 2, effectively splitting the dataset in halves. Imagine a playground seesaw with a child and an adult seated at opposite ends. The mean corresponds to the balance point of the seesaw, shifting closer to the heavier adult, reflecting the weighted average of the two positions. In contrast, the median represents the midpoint of the plank itself, simply dividing the seesaw into halves regardless of weight. The choice between using the mean or the median depends largely on the purpose of the analysis as well as the characteristics of the data distribution. The mean is useful when we want to consider every value in the dataset and obtain a measure that reflects the overall average, especially when the data are symmetrically distributed without extreme outliers. On the other hand, the median is often preferred when the data are skewed or contain outliers, as it provides a measure of central tendency that is resistant to extreme values and better represents the “typical” observation in such cases. In SPC, the median is particularly useful for runs analysis with run charts. Because the median reflects the midpoint of the data, there is an equal probability – fifty-fifty – that any individual data point will fall above or below it. This balance is crucial for runs analysis, as it ensures that the number and length of runs (consecutive points above or below the median) can be assessed against expected probabilities under random variation. Consequently, using the median helps accurately detect non-random trends or shifts in the process regardless of the shape of data. In our birth lengths data, the mean and the median are nearly identical: 51.7 vs 52.0. Understanding the shape and spread of the data helps inform which measure will provide the most meaningful summary. B.3.2 Shape The shape of a dataset refers to the overall pattern or distribution of values. Two key features that describe the shape of data are symmetry and modality. Symmetry describes how evenly the values are distributed around the centre. In a perfectly symmetrical distribution the left and right sides are mirror images and the mean and the median are identical. When one side of the distribution extends further than the other, the data are said to be skewed. If the tail extends towards higher values, the distribution is right-skewed (positively skewed), and the mean is greater than the median. If it extends towards lower values, it is left-skewed (negatively skewed), and the mean is less than the median. Examples of data that are often right-skewed include waiting times and income, where most observations cluster around the lower end of the scale, while a few extreme values create a long tail extending towards higher values. Symmetry is also characterised by the mean and median being approximately centred between the minimum and maximum values. Because the mean and median of birth length are very close, we may assume that the data are approximately symmetrical. However, neither the mean nor the median is well centred between the minimum and maximum values, suggesting that the distribution may still be slightly skewed or influenced by outliers at one end. The histogram in Figure B.3 provides a much clearer and more detailed picture of the shape of the data. The majority of values are symmetrically centred, but a few data points have unusually low values (birth length = 35 cm) suggesting a left-skew. However, these outliers appear unlikely for full-term babies and should be investigated further before proceeding with analysis. Modality refers to the number of peaks or modes in a distribution. A unimodal distribution has one clear peak, bimodal has two peaks, and multimodal has more than two. Bi- or multimodal distributions indicate the presence of important subgroups in data that need to be taken into account when analysing data. hist(reno$dose) Figure B.4: Histogram of radiation doses used for renography. Figure B.4 shows an example of bimodal data, suggesting the presence of two distinct groups of renography procedures – each likely driven by a different underlying cause that is unknown to us. Before plotting these data – as we did in Chapter 6 – we should first seek an explanation for the observed pattern and consider stratifying the data according to the underlying procedural strategy. B.3.3 Spread The concept of spread in data is fundamental to SPC, as we have discussed numerous times throughout this book – although the term “spread” itself has not been explicitly introduced until now. Spread refers to the variability or diversity within the data, indicating how much the values differ from each other. When constructing control limits, we rely on the standard deviation (SD or sigma) of common cause variation as a primary measure of spread. However, standard deviation is not the only useful spread indicator. As demonstrated above, the summary() function provides additional measures that reflect the spread of data. The range represents the distance between the highest and lowest values in a dataset, while the interquartile range (IQR) captures the spread of the middle 50% of the data — calculated as the difference between the third and first quartiles. The range is easy to understand but has limited usefulness on its own, as it tends to increase with sample size. As the number of observations grows, so does the likelihood of including rare – though not necessarily unusual – values. The interquartile range is a more robust measure of spread and can also offer some insight into the shape of the distribution through the position of the centre relative to the quartiles. However, it becomes unreliable with very small sample sizes. When fewer than five values are present – at the very least – calculating quartiles is effectively meaningless. A simple, useful and compact alternative to histograms is the box plot, which provides a visual summary of the central tendency and spread of a dataset. boxplot(births$length) Figure B.5: Boxplot of birth lengths. The box in a box plot represents the interquartile range (IQR), while the line inside the box indicates the median. The whiskers extend from either end of the box to the smallest and largest values that lie within 1.5 times the IQR from the quartiles. Any dots beyond the whiskers represent more extreme values – often referred to as outliers, though there is often nothing truly outlandish about them. As long as data have a unimodal shape, the box plot is a very effective visualisation of both the centre, shape and spread of a distribution. Box plots are especially useful with grouped data as in Figure B.6, which compares the birth length of boys and girls, suggesting that, on average, boys are slightly longer than girls. boxplot(length ~ sex, births) Figure B.6: Stratified boxplot. The standard deviation is perhaps the most commonly used measure of spread in a dataset. It tells, on average, how far from the mean each data value lies. To calculate SD we use \\[ SD = \\sqrt{\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n-1}} \\] That is, the square root of the sum of squared deviations from the mean divided by one less than the number of values. SD can always be calculated, but its usefulness depends on the underlying distribution of the data. This is why we first introduced the range and interquartile range, which are reliable measures of spread regardless of the distribution. When data follow a Gaussian (or normal) distribution – which we will talk more about in the next section – the standard deviation has some particularly useful properties: Approximately 68% of data values fall within ±1 SD of the mean, 95% fall within ±2 SD, and 99.7% fall within ±3 SD. The first two rules depend heavily on data’s underlying distribution. However, the third rule – that “most” data points fall within ±3 SD – holds true for many common distributions. Without delving into technical details, it can be shown that for any unimodal distribution, at least 95% of the data lie within three standard deviations of the mean. For many common unimodal distributions, especially those that are roughly symmetric, this proportion can rise to more than 98%. This fact supports the use of three-sigma limits in SPC charts regardless of the distribution of data and cautions against adopting tighter limits solely to increase sensitivity. B.4 Theoretical distributions So far we have mainly concerned ourselves with empirical distributions – examining the centre, shape and spread of real-world datasets. In this section we will take a look at some important theoretical distributions. A theoretical distribution is a mathematical model that describes the probabilities of different outcomes in a given situation. For instance, consider tossing a fair coin. While we cannot predict the outcome of any single toss, we know that the set of possible outcomes is [heads, tails], each with a probability of 1/2. Similarly, when rolling a fair six-sided die, the possible outcomes are [1, 2, 3, 4, 5, 6], each occurring with a probability of 1/6. Given this type of information, we are able – through the use of probability theory – to predict the probability of any future outcome or combination of outcomes. Numerous theoretical distributions have been described, but for our purposes in SPC, we are primarily concerned with three: the Poisson, the binomial, and the Gaussian (or normal) distribution. The Poisson and binomial distributions are used for count data, while the Gaussian distribution is applied to measurement data. B.4.1 Poisson distribution – predicting the number of events The Poisson distribution – named after the French mathematician Siméon Poisson – describes the probability of a given number of events occurring within a fixed time interval, assuming that the events happen independently of one another and at a constant average rate, commonly denoted by lambda (λ). It is used to estimate the control limits for C- and U-charts. Based on the birth data, we estimate the expected birth rate to be approximately 2,200 births per year, averaging to about 6 births per day. I R, we can use the dpois() function to calculate the probability (or density) of any given number of births in a day. For example, the probability of having exactly 9 births in one days is dpois(9, lambda = 6) = 0.0688385. The standard deviation of a Poisson distribution conveniently equals the square root of lambda (\\(SD = \\sqrt{\\lambda}\\)), in this case, approximately 2.45. To visualise discrete probability distributions, we use bar (or stick) charts as demonstrated in Figure B.7. # plot Poisson probability x &lt;- 0:16 # x-axis values plot(x, dpois(x, lambda = 6), type = &#39;h&#39;, lwd = 2, ylab = &#39;Probability&#39;, xlab = &#39;Number of births&#39;) Figure B.7: Poisson probability plot of the number of births in a day (mean = 6). Note that the Poisson distribution is censored at zero – it cannot produce negative counts – but in principle, it extends towards infinity. As with all probability distributions, the sum of all probabilities is equal to 1. For low values of lambda, the Poisson distribution is right-skewed; however, as lambda increases, the distribution becomes increasingly symmetric and begins to resemble the normal distribution. B.4.2 Binomial distribution – predicting the number of cases of “success” or “failure” The binomial distribution describes the probability of obtaining a given number of cases – often referred to as successes or failures – in a fixed number of independent trials (or opportunities), each with two possible outcomes (such as yes/no or pass/fail), and a constant probability of success. The standard deviation of a binomial distribution is \\(SD = \\sqrt{np(1-p)}\\), where n is the sample size and p the success proportion. Often, we prefer to work with the proportion of cases rather than the count (as in P-charts). In this case, the standard deviation of the proportion is calculated as \\(SD = \\sqrt{p(1-p)/n}\\) For example, if we consider each birth as a trial (opportunity) and define a case as a Caesarean section (C-section), the binomial distribution can be used to model the probability of observing a specific number of C-sections within a set number of births. In R, the dbinom() function is used to calculate binomial probabilities. In addition to the number of cases of interest, the function requires the total number of opportunites (sample size) and the average probability of a case. Based on the birth data, we estimate there are approximately 42 births per week, with about 9% resulting in a C-section. To calculate the probability of observing exactly 6 C-sections in a given week, we use the following command: dbinom(6, size = 42, prob = 0.09) = 0.093488. # plot binomial probability x &lt;- 0:12 plot(x, dbinom(x, size = 42, prob = 0.09), type = &#39;h&#39;, lwd = 2, ylab = &#39;Probability&#39;, xlab = &#39;Number of C-sections&#39;) Figure B.8: Binomial probability plot of the number of C-sections in a week (size = 42, prob = 0.09). As with the Poisson distribution, the binomial distribution is censored at zero. However, unlike the Poisson, its upper limit is fixed and equal to the sample size, since it models a finite number of opportunities The shape of the binomial distribution is perfectly symmetric when the success probability is close to 50% and grows increasingly skewed when this approaches 0% (right-skew) or 100% (left-skew). The degree of skewness depends largely on the sample size – bigger samples, less skew and more symmetry. These considerations are important when designing a sampling plan. To quickly gather enough data points for a control chart, smaller samples are preferable; however, to maintain symmetry – which is important for the reliability of the P-chart – larger samples are needed. B.4.3 Gaussian distribution – predicting the probability of continuous outcomes The Gaussian distribution, named after the German mathematician Carl Gauss and often referred to as the normal distribution – though there is nothing inherently “normal” about it – is a continuous probability distribution widely used to model many real-world phenomena. Figure B.9 shows a histogram of birth weights, where each bin represents the number of data points that fall within a specific range. hist(births$weight, breaks = 20) Figure B.9: Histogram of birth weights Now, imagine gradually making the bins narrower and more numerous. As they become smaller, the tops of the bars would begin to blend together, eventually forming a smooth, continuous curve. In Figure B.10, we have overlaid a curve representing the theoretical Gaussian distribution, using the empirical mean and standard deviation of the birth weights. avg_w &lt;- mean(births$weight) std_w &lt;- sd(births$weight) hist(births$weight, breaks = 20, freq = F) curve(dnorm(x, mean = avg_w, sd = std_w), add = TRUE) Figure B.10: Histogram of birth weights with overlayed Gaussian density curve. Note that the y-axis now represents density rather than frequency. In a histogram, density reflects the likelihood of values falling within a bin, with the total area summing to 1. The density curve, however, doesn’t assign probabilities to individual points – it represents the overall shape of the distribution, and probabilities are found by calculating the area under the curve over an interval. The total area under the curve – which, in theory ranges from minus infinity to plus infinity – also equals 1. The Gaussian distribution has an associated density function in R, dnorm(), which returns the height of the density curve at a given value. For example, dnorm(3500, mean = avg_w, sd = std_w returns 0.000912. As mentioned earlier, this value is not directly meaningful on its own – it represents the curve’s height at a point, not a probability. To find the probability of a value being less than or equal to a given threshold, we use pnorm(), which returns the area under the curve up to that value. For instance, pnorm(3500, mean = avg_w, sd = std_w) = 0.5157967 indicates that approximately 51.6% of birth weights are expected to be below 3500 grams. Using pnorm(), we can calculate the probability of outcomes within any interval. To find the probability of data falling within ±3 SD from the mean, we calculate the area under the curve like this: pnorm(avg_w + 3 * std_w, # area below mean + 3 SD mean = avg_w, sd = std_w) - pnorm(avg_w - 3 * std_w, # aread below mean - 3 SD mean = avg_w, sd = std_w) ## [1] 0.9973002 B.5 Basic statistical concepts in summary In this chapter, we have explored several fundamental concepts essential for understanding data in general, and for applying SPC methods in particular. We began by examining the two primary types of data: categorical and numerical. Understanding these distinctions is crucial, as they determine the appropriate methods for summarising and analysing information. We then discussed how to generate meaningful summaries of data using both numerical measures (such as the mean, median, interquartile range, and standard deviation) and graphical techniques (including bar charts, histograms and boxplots). Before undertaking any detailed data analysis, it is good practice to create initial plots that illustrate key characteristics of the dataset – specifically its centre, shape and spread. These visualisations can reveal important features such as skewness, the presence of outliers, or potential data quality issues, all of which may influence subsequent analysis and interpretation. "],["diagnostics.html", "C Two types of errors when using SPC C.1 Quantifying the diagnostic error of SPC charts C.2 Conclusion: Keeping the balance", " C Two types of errors when using SPC Classifying variation into common cause or special cause is the primary focus of statistical process control methodology. In practice, this classification is subject to two types of error which can be compared to an imperfect screening test that sometimes shows a patient has disease when in fact the patient is free from disease (false positive), or the patient is free from disease when in fact the patient has disease (false negative). False positive (type 1 error): Treating an outcome resulting from a common cause as if it were a special cause and (wrongly) seeking to find a special cause, when in fact the cause is the underlying process. False negative (type 2 eroor): Treating an outcome resulting from a special cause as if it were a common cause and so (wrongly) overlooking the special cause. Either mistake can cause losses. Treating all data as special cause variation maximises the losses from false positives; and treating all data as common cause variation maximises the losses from false negatives. Unfortunately, in practice it is impossible to reduce both mistakes to zero. Shewhart sought a strategy to make either mistake only rarely and concluded that this depended largely upon the costs of looking unnecessarily for special cause variation. Using mathematical theory, empirical evidence, and pragmatism, he argued that setting control limits to three standard deviations below and above the mean provides a reasonable balance between making the two types of mistakes. C.1 Quantifying the diagnostic error of SPC charts C.1.1 Average run length Traditionally, the performance characteristics of SPC charts have been evaluated through the so-called average run length (ARL), that is, the average number of data points until a special cause is signalled (Montgomery 2020, 186): \\[ ARL_0=\\frac{1}{\\alpha} \\] for the in-control ARL, when no special cause is present, and \\[ ARL_1=\\frac{1}{1-\\beta} \\] for the out-of-control ARL, when a special cause is present, where \\[ \\alpha=P\\{\\text{signal | common cause variation}\\}=P\\{\\text{false positive}\\}=P\\{\\text{type 1 error}\\} \\] \\[ \\beta=P\\{\\text{no signal | special cause variation}\\}=P\\{\\text{false negative}\\}=P\\{\\text{type 2 error}\\} \\] For example, in a common cause process with normal data the chance (\\(\\alpha\\)) of a data point falling outside the 3-sigma limits is 0.0027 and \\(ARL_0=1/0.0027=370\\), meaning that we should expect to wait on average 370 data points between false alarms. The out-of-control ARL depends on the false negative risk, \\(\\beta\\), which in turn depends on the size of the shift (signal) relative to the size of the common cause variation (noise). The ideal control charts would have \\(ARL_0=\\infty\\) and \\(ARL_1=1\\). In practice, this is not possible because ARLs are linked – if one goes up, the other goes up too. ARLs are related to sensitivity and specificity, which may be more familiar to healthcare workers. In general, sensitivity and specificity tell how well a test is able to identify the presence or absence of a certain condition. Specifically, regarding SPC charts: \\[ specificity=P\\{\\text{no signal | common cause variation}\\}=P\\{\\text{true negative}\\}=1-\\alpha \\] \\[ sensitivity=P\\{\\text{signal | special cause variation}\\}=P\\{\\text{true positive}\\}=1-\\beta \\] C.1.2 Likelihood ratios Sensitivity and specificity are, however, not that useful on their own – they describe how a special cause predicts a signal, not how a signal predicts a special cause, which is what we really want to know. Likelihood ratios are diagnostic measures designed to answer such questions. Assume that an SPC chart signals special cause variation. A perfect test would mean that the chart would certainly come from an unstable process (true positive, TP). However, some charts with only common cause variation also signals (false positive, FP). We therefore correct the true positive rate by the false positive rate by dividing one with the other. Likewise, if a chart does not signal it could be a false negative (FN) rather than a true negative (TN). \\[ LR+=TP/FP=sensitivity/(1-specificity) \\] \\[ LR-=FN/TN=(1-sensitivity)/specificity \\] A likelihood ratio greater than 1 speaks in favour of the condition being tested for, which in our case is special cause variation, while a likelihood ratio less than 1 speaks against special cause variation. The further a likelihood ratio is from 1, the more or less likely is the presence of special cause variation. As a rule of thumb, a positive likelihood ratio greater than 10 is considered strong evidence that the condition being tested for is present. A negative likelihood ratio smaller than 0.1 is considered strong evidence against the condition (Deeks and Altman 2004). Thus, likelihood ratios allow us to quantify the probability of special causes in data and are useful quality characteristics of SPC rules (Anhøj 2015). All else being equal, a “good” rule (or combination of rules) is one with a high positive likelihood ratio and a low negative likelihood ratio. A worked example is presented in the table below: Results from runs analyses of 2000 simulated run charts with 24 data points. In half the simulations a shift of 2 SD was introduced in the last 12 subgroups. Shift +/– indicates the presence or absence of true shifts in process mean. Signal +/– indicates the result from the run chart analysis using the two runs analysis rules (Anhøj 2015). Shift– Shift+ Likelihood ratio Signal– 927 115 LR– = 115 / 927 = 0.12 Signal+ 73 885 LR+ = 885 / 73 = 12 Studies comparing different combination of rules using likelihood ratios (Anhøj 2015; Anhøj and Wentzel-Larsen 2018) found that: The 3-sigma rule is effective (high LR+, low LR–) in signalling moderate to large possibly transient shifts in data. The 3-sigma rule looses specificity (more false positive signals) with increasing number of data points. Runs analysis using the two rules proposed in Chapter 3 is effective in signalling minor to moderate sustained shifts in data regardless of the number of data points. Combining the 3-sigma rule with runs analysis and keeping the number of data points between 20 and 30 strikes a good balance between false positive and false negative signals. C.2 Conclusion: Keeping the balance SPC charts, like any statistical or medical tests, can sometimes suggest a problem where none exists or fail to detect a real issue. This can result in losses – either from wasted resources chasing false alarms or from harm caused by overlooked special causes. However, carefully selecting which rules to apply to SPC charts can help minimize losses in both cases. Since Shewhart first introduced the control chart in 1924 – using only the 3-sigma rule – many additional rules and rule sets have been proposed to improve the sensitivity of SPC charts to special cause variation. However, increased sensitivity comes at the cost of reduced specificity, and applying too many or overly sensitive rules inevitably leads to wasted resources chasing false alarms. Our goal is to strike the right balance between sensitivity and specificity. Quantifying diagnostic errors using likelihood ratios is a valuable tool in achieving this. The rules proposed in this book – the two runs rules and the 3-sigma rule – have been validated through careful studies and years of practical experience, demonstrating a useful balance between sensitivity and specificity. References Anhøj, Jacob. 2015. “Diagnostic Value of Run Chart Analysis: Using Likelihood Ratios to Compare Run Chart Rules on Simulated Data Series.” PLoS ONE. https://doi.org/10.1371/journal.pone.0121349. Anhøj, Jacob, and Tore Wentzel-Larsen. 2018. “Sense and Sensibility: On the Diagnostic Value of Control Chart Rules for Detection of Shifts in Time Series Data.” BMC Medical Research Methodology. https://doi.org/10.1186/s12874-018-0564-0. Deeks, Jonathan J, and Douglas G Altman. 2004. “Diagnostic Tests 4: Likelihood Ratios.” BMJ 329: 168–69. https://doi.org/10.1136/bmj.329.7458.168. Montgomery, Douglas C. 2020. Introduction to Statistical Quality Control, Eighths Ed. Wiley. "],["r-notes.html", "D R Notes D.1 Data structures and classes D.2 Plot-ready data frames D.3 Importing data from text files D.4 Manipulating data frames D.5 Tips and tricks", " D R Notes This is not an R tutorial. Rather, this appendix aims to explain and clarify some of the tools and techniques we use in this book to import and prepare data for plotting using only base R functions. We are very well aware of new and modern approaches to data manipulation from the tidyverse and data.table packages – we use these tool ourselves every day – but we find it valuable to be able to handle data in base R. Especially when sharing code or building R packages it is generally a good strategy to avoid unnecessary dependencies on external packages. First, we will look at some data structures and types that are essential to this book. Next, we will discuss some principles for importing data from text files into data frames and how to manipulate these to make data ready for plotting. Finally, we give some useful tips and tricks D.1 Data structures and classes The simplest data structure in R is the vector: zero or more data elements of the same type. Data come in several basic types (classes). We are mainly concerned with logical, numeric and character values. Date and datetime values, which are especially important in SPC, are basically just numeric values representing the number of days (dates) or seconds (datetimes) since the beginning of the year 1970. The data frame is (for our purpose) probably the most important data structure in R. Data frames are collections of vectors that may be of different types but are all of the same length. Think matrix or table with rows and columns where each row represents an observation, each column represents a variable, and each cell represents a data value. All rows and all columns have the same length, and all cells have values (including NA for missing data). D.2 Plot-ready data frames When plotting time series data including spc data, R usually expects two vectors, one for the x axis representing the subgroups, which in its simplest form may be a sequence of numbers or dates and one for the y axis representing the indicator values to be plotted. To correctly calculate the control limits in spc charts, we often need a third variable representing the denominator of the count data in the y variable. Thus, a generic plot-ready data set for making an spc chart may look like this. # A tibble: 12 × 3 x y n &lt;date&gt; &lt;int&gt; &lt;int&gt; 1 2025-05-31 13 32 2 2025-06-01 14 29 3 2025-06-02 16 33 4 2025-06-03 19 30 5 2025-06-04 13 32 6 2025-06-05 18 35 7 2025-06-06 19 29 8 2025-06-07 16 33 9 2025-06-08 16 34 10 2025-06-09 11 27 11 2025-06-10 13 32 12 2025-06-11 12 26 To plot a P chart from these data with the qic() function from the qicharts2 package, we may do this, where dta is the name of the data frame containing the three variables x, y, and n: qic(x, y, n, data = d, chart = &#39;p&#39;) Notice that to correctly plot dates or datetimes on the x axis, it is important that the x variable is of the correct class (Date for dates or POSIXct for datetimes). D.3 Importing data from text files When importing data from a text file into R using one of the base R read.*() functions, data are returned as a data frame. For this book, we provide all data sets as comma separated values (csv) in text files that can be read using the read.csv() function. Each data file begins with a number of commented lines that explains the content and the variables in data. For example, the first 18 lines of the “bacteremia.csv” file looks like this: # Bacteremia # # Hospital acquired and all cause bacteremias and 30 days mortality # # Variables: # month (date): month of infection # ha_infections (numeric): number of hospital acquired infections # risk_days (numeric): number of patient days without infection # deaths (numeric): 30-day mortality after all-cause infection # patients (numeric): number of patients with all-cause infection month,ha_infections,risk_days,deaths,patients 2017-01-01,24,32421,23,100 2017-02-01,29,29349,22,105 2017-03-01,26,32981,13,99 2017-04-01,16,29588,14,85 2017-05-01,28,30856,17,98 2017-06-01,16,30544,15,85 ... Lines beginning with a hash symbol (#) are comments. The first non-blank line after the comments holds the variable names, and the the rest of the file contains the data values separated by commas (,). Note how the dates in the first column are formatted using the only unmistakeable way of writing dates: year-month-day (yyyy-mm-dd). We highly recommend to always store dates in this format, which also happens to be the international ISO standard for writing dates. Also, ISO dates, when used in file names, sort correctly and also have the advantage of being easily recognised as dates by R (and other statistical software). If dates are stored in any other format (e.g. dd-mm-yyyy), we may need to import them as character values and later convert them to dates using the as.Date() function. When reading data in R programmes for use in production environments, we recommend that you specify the data type (class) of each column using the colClasses argument. # read data from file and assign to variable named d d &lt;- read.csv(&#39;data/bacteremia.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(month = &#39;Date&#39;, ha_infections = &#39;integer&#39;, risk_days = &#39;integer&#39;, deaths = &#39;integer&#39;, patients = &#39;integer&#39;)) # print the first six lines of data head(d) month ha_infections risk_days deaths patients 1 2017-01-01 24 32421 23 100 2 2017-02-01 29 29349 22 105 3 2017-03-01 26 32981 13 99 4 2017-04-01 16 29588 14 85 5 2017-05-01 28 30856 17 98 6 2017-06-01 16 30544 15 85 # print the data structure str(d) &#39;data.frame&#39;: 24 obs. of 5 variables: $ month : Date, format: &quot;2017-01-01&quot; &quot;2017-02-01&quot; ... $ ha_infections: int 24 29 26 16 28 16 14 18 27 30 ... $ risk_days : int 32421 29349 32981 29588 30856 30544 26482 27637 30495 30600 ... $ deaths : int 23 22 13 14 17 15 15 25 21 24 ... $ patients : int 100 105 99 85 98 85 89 99 103 86 ... D.4 Manipulating data frames We will import the C-section data set to demonstrate adding variables and aggregating data. d &lt;- read.csv(&#39;data/csection_delay.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(datetime = &#39;POSIXct&#39;, month = &#39;Date&#39;, delay = &#39;integer&#39;)) head(d) datetime month delay 1 2016-01-06 03:55:40 2016-01-01 22 2 2016-01-06 20:52:34 2016-01-01 22 3 2016-01-07 02:50:43 2016-01-01 29 4 2016-01-07 22:32:27 2016-01-01 28 5 2016-01-09 14:56:09 2016-01-01 22 6 2016-01-09 21:21:24 2016-01-01 20 The C-section data contains 208 rows representing individual C-sections. Our aim for this exercise is to reduce data to a plot ready data frame with one row per month and the number of C-section that were on target and the total number of C-sections. D.4.1 Adding variables to data frames The delay variable is the number of minutes from decision to perform a C-section to delivery of the baby. The standard target value for grade 2 C-sections is less than 30 minutes. If we want to plot the proportion of C-sections that are on time (i.e. less than 30 min.), we first need to dichotomise the delay variable into a logical variable, ontime, that is TRUE when delay is less than 30. We add this new variable to the data frame using the $-notation. d$ontime &lt;- d$delay &lt; 30 # Dichotomise delays. head(d) datetime month delay ontime 1 2016-01-06 03:55:40 2016-01-01 22 TRUE 2 2016-01-06 20:52:34 2016-01-01 22 TRUE 3 2016-01-07 02:50:43 2016-01-01 29 TRUE 4 2016-01-07 22:32:27 2016-01-01 28 TRUE 5 2016-01-09 14:56:09 2016-01-01 22 TRUE 6 2016-01-09 21:21:24 2016-01-01 20 TRUE D.4.2 Aggregating data frames Then we aggregate data to one row per month. For this, we use the split-apply-combine strategy by first splitting the data frame into a list of data frames, one per month. Next, we apply the same summary function to all elements (months) of this list collapsing into a one-row data frame. Finally, we combine the elements back into a data frame again. d2 &lt;- split(d, d$month) # Split data frame by month. d2 &lt;- lapply(d2, function(x) { # Apply summaries to each group. data.frame(month = x$month[1], avg_delay = mean(x$delay), n = nrow(x), n_ontime = sum(x$ontime)) }) d2 &lt;- do.call(rbind, # Combine groups into data frame. c(d2, make.row.names = FALSE)) head(d2) month avg_delay n n_ontime 1 2016-01-01 23.85714 7 7 2 2016-02-01 24.45455 11 9 3 2016-03-01 22.45455 11 10 4 2016-04-01 22.66667 9 9 5 2016-05-01 22.50000 8 8 6 2016-06-01 22.00000 5 4 str(d2) &#39;data.frame&#39;: 24 obs. of 4 variables: $ month : Date, format: &quot;2016-01-01&quot; &quot;2016-02-01&quot; ... $ avg_delay: num 23.9 24.5 22.5 22.7 22.5 ... $ n : int 7 11 11 9 8 5 7 12 7 12 ... $ n_ontime : int 7 9 10 9 8 4 5 12 6 11 ... The three functions split(), lapply(), and do.call() may be unfamiliar to many R users, but it pays to get to know them – read the documentation. The split-apply-combine strategy may be performed a lot easier with functions from the tidyverse or table.table packages. But, as mentioned, we find it useful to know the base R ways of doing things, not the least to maintain independence from external packages when creating our own functions. D.5 Tips and tricks D.5.1 Cutting dates and datetimes In the C-section data set the month variable represents the time period of each delivery used for subgrouping data, that is counting events and cases per month. The month variable was created by “cutting” the datetime variable into monthly chunks. Converting dates and datetimes into time period – for example weeks, months or quarters – is a common task, not the least in SPC. It is easily done using the cut() function, which is a generic function with many uses. However, the syntax for cutting dates is poorly documented. To cut dates we use two arguments: first, the vector of date(time)s to be cut; second, the interval we want. # R&#39;s date of birth (using parentheses to print the result) (x &lt;- as.Date(&#39;2000-02-29&#39;)) [1] &quot;2000-02-29&quot; # The first day of the month of R&#39;s date of birth cut(x, breaks = &#39;month&#39;) [1] 2000-02-01 Levels: 2000-02-01 Notice that cut() returns a factor. We need to convert it back to a date: as.Date(cut(x, breaks = &#39;month&#39;)) [1] &quot;2000-02-01&quot; The breaks argument accepts a character string that qualifies for a time period, for example: # Cutting to the first day of a week (monday) as.Date(cut(x, breaks = &#39;week&#39;)) [1] &quot;2000-02-28&quot; # Quarter as.Date(cut(x, breaks = &#39;quarter&#39;)) [1] &quot;2000-01-01&quot; We can even specify multiples of time periods in the breaks argument: # The first day of biweekly periods as.Date(cut(x, breaks = &#39;2 weeks&#39;)) [1] &quot;2000-02-28&quot; Cutting dates is such a common task that we may want to make our own function for the purpose: cutdate &lt;- function(x, breaks = &#39;month&#39;) { as.Date(cut(x, breaks = breaks)) } cutdate(x) [1] &quot;2000-02-01&quot; cutdate(x, &#39;week&#39;) [1] &quot;2000-02-28&quot; cutdate(x, &#39;quarter&#39;) [1] &quot;2000-01-01&quot; D.5.2 Getting age from date of birth In healthcare we often need to know the patient’s age on a certain date. By “age” we usually mean a whole number of years since the patient’s date of birth. However, year is not a well defined unit of time, and age is really a continuous variable. Therefore, we are usually better off knowing the patient’s age in days, which in turn can always be converted to decimal or integer years if necessary. How old is R today? today &lt;- as.Date(&#39;2025-04-24&#39;) r_dob &lt;- as.Date(&#39;2000-02-29&#39;) # calculate age in days (age_in_days &lt;- today - r_dob) Time difference of 9186 days When subtracting dates we get back a difftime object. Usually we want to convert this to an integer: # convert from difftime object to integer: (age_in_days &lt;- as.integer(age_in_days)) [1] 9186 A calendar year is on average a little less than 365.25 days. We can converts age in days to age in years: (age_in_years &lt;- age_in_days / 365.25) [1] 25.1499 Putting everything together: (age_in_years &lt;- as.integer(today - r_dob) / 365.25) [1] 25.1499 Notice that this calculation may be off by up to one day depending on the number and position of leap years. However, this is far better than relying on age expressed in whole years. D.5.3 Naming files and variables Book have been written about how to and how not to name variables and files. Here is our take on a minimal list of dos and don’ts. Feel free to make your own naming style – and stick to it. Mixing styles is a source of confusion not only for others but also for your future self. Always: use lower case ascii letters (a-z) and integers (0-9), e.g. “myvariable”, “myfile.R”; separate words with “-”, “_“, or”.”, e.g.: “my_variable”, “my-variable”, “my.variable”; use ISO format (yyyy-mm-dd) for dates, e.g.: “2001-02-03”; when numbering files, use use a suitable number of leading zeros, e.g. “myfile_01”, “myfile_02”, … “myfile_10”, “myfile_11”. Newer: use spaces, e.g.: “my variable”, “my file.R”; versionize files using words like “final”, “finalfinal”, “new”, “draft”, etc. Instead, use ISO dates, e.g.: “my_file_2001-02-03.R”. "],["runs-limits.html", "E Critical Values for Longest Runs and Number of Crossings", " E Critical Values for Longest Runs and Number of Crossings Number of useful observations Upper limit for longest run Lower limit for number of crossings 10 6 2 11 6 2 12 7 3 13 7 3 14 7 4 15 7 4 16 7 4 17 7 5 18 7 5 19 7 6 20 7 6 21 7 6 22 7 7 23 8 7 24 8 8 25 8 8 26 8 8 27 8 9 28 8 9 29 8 10 30 8 10 31 8 11 32 8 11 33 8 11 34 8 12 35 8 12 36 8 13 37 8 13 38 8 14 39 8 14 40 8 14 41 8 15 42 8 15 43 8 16 44 8 16 45 8 17 46 9 17 47 9 17 48 9 18 49 9 18 50 9 19 51 9 19 52 9 20 53 9 20 54 9 21 55 9 21 56 9 21 57 9 22 58 9 22 59 9 23 60 9 23 61 9 24 62 9 24 63 9 25 64 9 25 65 9 25 66 9 26 67 9 26 68 9 27 69 9 27 70 9 28 71 9 28 72 9 29 73 9 29 74 9 29 75 9 30 76 9 30 77 9 31 78 9 31 79 9 32 80 9 32 81 9 33 82 9 33 83 9 34 84 9 34 85 9 34 86 9 35 87 9 35 88 9 36 89 9 36 90 9 37 91 10 37 92 10 38 93 10 38 94 10 39 95 10 39 96 10 39 97 10 40 98 10 40 99 10 41 100 10 41 "],["resources.html", "F Resources and Further Readings", " F Resources and Further Readings books websites communities R packages "],["references.html", "References", " References Anhøj, Jacob. 2015. “Diagnostic Value of Run Chart Analysis: Using Likelihood Ratios to Compare Run Chart Rules on Simulated Data Series.” PLoS ONE. https://doi.org/10.1371/journal.pone.0121349. ———. 2018. “qicharts2: Quality Improvement Charts for R.” JOSS. https://doi.org/10.21105/joss.0069. ———. 2024. Qicharts2: Quality Improvement Charts. https://CRAN.R-project.org/package=qicharts2. Anhøj, Jacob, and Anne Vingaard Olesen. 2014. “Run Charts Revisited: A Simulation Study of Run Chart Rules for Detection of Non-Random Variation in Health Care Processes.” PLoS ONE. https://doi.org/10.1371/journal.pone.0113825. Anhøj, Jacob, and Tore Wentzel-Larsen. 2018. “Sense and Sensibility: On the Diagnostic Value of Control Chart Rules for Detection of Shifts in Time Series Data.” BMC Medical Research Methodology. https://doi.org/10.1186/s12874-018-0564-0. Chen, Zhenmin. 2010. “A Note on the Runs Test.” Model Assisted Statistics and Applications 5: 73–77. https://doi.org/10.3233/MAS-2010-0142. Deeks, Jonathan J, and Douglas G Altman. 2004. “Diagnostic Tests 4: Likelihood Ratios.” BMJ 329: 168–69. https://doi.org/10.1136/bmj.329.7458.168. Goldratt, Eliyahu M., and Jeff Cox. 2022. The Goal: A Process of Ongoing Improvement, 3rd Edition. Routledge. Jeppegaard, Maria, Steen C. Rasmussen, Jacob Anhøj, and Lone Krebs. 2023. “Winter, Spring, Summer or Fall: Temporal Patterns in Placenta-Mediated Pregnancy Complications—an Exploratory Analysis.” Gynecol Obstet 309: 1991–98. https://doi.org/https://doi.org/10.1007/s00404-023-07094-6. Koetsier, A., S. N. van der Veer, K. J. Jager, N. Peek, and N. F. de Keizer. 2012. “Control Charts in Healthcare Quality Improvement.” Methods of Information in Medicine. https://doi.org/10.3414/ME11-01-0055. Laney, David B. 2002. “Improved Control Charts for Attributes.” Quality Engineering 14: 531–37. Langley, Gerald J, Ronald D Moen, Kevin M Nolan, Thomas W Nolan, Clifford L Norman, and Lloyd P Provost. 2009. The Improvement Guide. San Fracisco, CA: Jossey-bass. Lilford, Richard, Mohammed A Mohammed, David Spiegelhalter, and Richard Thomson. 2004. “Use and Misuse of Process and Outcome Data in Managing Performance of Acute Medical Care: Avoiding Institutional Stigma.” The Lancet 363: 1147–54. https://doi.org/https://doi.org/10.1016/S0140-6736(04)15901-1. Mohammed, M A. 2024. Statistical Process Control. Elements of Improving Quality and Safety in Healthcare. Cambridge University Press. https://www.cambridge.org/core/elements/statistical-process-control/60B6025BF62017A9A203960A9E223C10. Mohammed, M A, Rouse Cheng KK, and T Marshall. 2001. “Bristol, Shipman, and Clinical Governance: Shewhart’s Forgotten Lessons.” Lancet 357. https://doi.org/10.1016/s0140-6736(00)04019-8. Mohammed, M A, Anthony Rathbone, Paulette Myers, Divya Patel, Helen Onions, and Andrew Stevens. 2004. “An Investigation into General Practitioners Associated with High Patient Mortality Flagged up Through the Shipman Inquiry: Retrospective Analysis of Routine Data.” BMJ 328 (7454): 1474–77. https://doi.org/10.1136/bmj.328.7454.1474. Mohammed, M A, P Worthington, and W H Woodall. 2008. “Plotting Basic Control Charts: Tutorial Notes for Healthcare Practitioners.” BMJ Qual Saf 17 (2): 137–45. https://doi.org/10.1136/qshc.2004.012047. Mohammed, Mohammed A, Jagdeep S Panesar, David B Laney, and Richard Wilson. 2013. “Statistical Process Control Charts for Attribute Data Involving Very Large Sample Sizes: A Review of Problems and Solutions.” BMJ Quality &amp; Safety 22 (4): 362–68. https://doi.org/10.1136/bmjqs-2012-001373. Montgomery, Douglas C. 2020. Introduction to Statistical Quality Control, Eighths Ed. Wiley. Nelson, Lloyd S. 1982. “Control Charts for Individual Measurements.” Journal of Quality Technology 14 (3): 172–73. https://doi.org/10.1080/00224065.1982.11978811. Neuburger, Jenny, Kate Walker, Chris Sherlaw-Johnson, Jan van der Meulen, and David A Cromwell. 2017. “Comparison of Control Charts for Monitoring Clinical Performance Using Binary Data.” BMJ Quality &amp; Safety 26 (11): 919–28. https://doi.org/10.1136/bmjqs-2016-005526. Plessen, Christian von, Anne Marie Kodal, and Jacob Anhøj. 2012. “Experiences with Global Trigger Tool Reviews in Five Danish Hospitals: An Implementation Study.” BMJ Open 2 (5). https://doi.org/10.1136/bmjopen-2012-001324. Rogers, Chris A., Barnaby C. Reeves, Massimo Caputo, J. Saravana Ganesh, Robert S. Bonser, and Gianni D. Angelini. 2004. “Control Chart Methods for Monitoring Cardiac Surgical Performance and Their Interpretation.” The Journal of Thoracic and Cardiovascular Surgery 128: 811–19. https://doi.org/https://doi.org/10.1016/j.jtcvs.2004.03.011. Schilling, Mark F. 2012. “The Surprising Predictability of Long Runs.” Mathematics Magazine 85: 141–49. https://doi.org/10.4169/math.mag.85.2.141. Shewhart, Walther A. 1931. Economic Control of Quality of Manufactured Product. New York: D. Van Nostrand Company. Taylor, Wayne. 2018. Normalized Individuals (IN) Control Chart. https://variation.com/normalized-individuals-control-chart/. Thor, Johan, Jonas Lundberg, Jakob Ask, Jesper Olsson, Cheryl Carli, Karin Pukk Härenstam, and Mats Brommels. 2007. “Application of Statistical Process Control in Healthcare Improvement: Systematic Review.” BMJ Qual Saf 16: 387–99. https://doi.org/10.1136/qshc.2006.022194. Western Electric Company. 1956. Statistical Quality Control Handbook. New York: Western Electric Company inc. Wheeler, Donald J. 2000. Understanding Variation – the Key to Managing Chaos. Knoxville, Tennessee: SPC Press. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
