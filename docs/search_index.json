[["index.html", "Mastering Statistical Process Control Charts in Healthcare A practical, hands-on, step-by-step guide for data scientists using R What is Statistical Process Control?", " Mastering Statistical Process Control Charts in Healthcare A practical, hands-on, step-by-step guide for data scientists using R Jacob Anhøj &amp; Mohammed Amin Mohammed 2024-11-19 What is Statistical Process Control? This is the online version of Mastering Statistical Process Control Charts in Healthcare, a book currently under early development. The ultimate purpose of collecting and analysing data is to support better decision-making and actions that will lead to improvement. Statistical Process Control (SPC) is a proven methodology for doing just that. SPC methodology provides a philosophy and framework for continually learning about the behaviour of processes for analytical purposes – where the aim is to act on the underlying causes of variation to maintain or improve the performance of a process. SPC was initially developed by Walter A. Shewhart in the 1920s to improve the quality of manufactured products and has since been successfully used in many settings including healthcare. At is core, SPC methodology involves the plotting of data over time to detect unusual patterns or variations that might indicate a change or problem with a process. This simple graphical device is underpinned by an intuitive theory of variation, the hypothesis-generating testing-cycle of the scientific method, and statistical theory. To master SPC, it’s essential to first understand the underlying theory of variation, which we explore in Part 1 of this book. Next, proficiency in using software to construct SPC charts is key, and this is covered in Part 2. In the later sections, we delve into specialized topics for more advanced SPC practitioners, offering deeper insights and expertise. "],["preface.html", "Preface What Sets This Book Apart? Prerequisites How to Use This Book About the Authors", " Preface This book is about the practical application of Statistical Process Control (SPC) methodology in healthcare. At its core, SPC is founded on a powerful, intuitive insight: processes are subject to two sources of variation – common cause and special cause. This distinction enables us to understand, monitor, and improve a wide range of processes. With this insight comes a suite of visual tools – run charts and control charts – that help differentiate between common and special cause variation with ease. However, while SPC tools are conceptually simple to use, applying them correctly can be a challenge. As noted in a systematic review of SPC in healthcare: … although SPC charts may be easy to use even for patients, clinicians, or managers without extensive SPC training, they may not be equally simple to construct correctly. To apply SPC is, paradoxically, both simple and difficult at the same time. – Thor et al. (2007) This book seeks to address this paradox by providing a straightforward, practical guide to the correct construction of SPC charts in healthcare using modern software. What Sets This Book Apart? This book is a step-by-step guide to easily and correctly producing SPC charts. Since this involves statistics, computing, and visualization, our software of choice is R – often referred to as the lingua franca of statistical computing and visualization. What makes this book unique is its specialized, practical, and modern approach, specifically tailored for data scientists and practitioners in the healthcare sector. Here’s what you can expect: Target Audience This book is for anyone looking to produce SPC charts using modern tools. While it is specifically geared toward data scientists, we recognize that our readers may include analysts, practitioners, managers, educators, students, researchers, clinicians, or even patients. Regardless of your role, if you work with healthcare data and want to master SPC, then this book is for you. Why R? We’ve chosen R as our primary tool because it is popular, free, and open-source. While we are pro-R, we are not anti-other software; readers can adapt the concepts in this book to their preferred tools. R has several key advantages: Transparency &amp; Reproducibility: R’s programming capabilities ensure every step of data analysis and SPC chart construction is documented, making your work both readable and reproducible – something rarely achieved with “point-and-click” software. Automation: R allows for automating repetitive tasks such as generating monthly reports, slide decks, and SPC dashboards with customizable, high-quality graphics. Healthcare-Focused Unlike general SPC books, this one focuses on healthcare-specific applications, addressing challenges like patient safety, clinical outcomes, and operational efficiency. It complements the foundational concepts in our companion book, Statistical Process Control: Elements of Improving Quality and Safety in Healthcare (Mohammed 2024). Practical and Hands-On The book takes a hands-on approach, providing real-world examples and case studies to help readers produce and use SPC charts confidently. This practical emphasis bridges the gap between theory and application. Comprehensive Coverage From foundational principles to advanced SPC techniques, this book covers it all. It’s designed to cater to both beginners and experienced data scientists, ensuring everyone finds value. Additional Resources Readers will gain access to supplemental materials, including: R scripts Datasets A dedicated GitHub repository for continued learning and collaboration. Prerequisites No prior knowledge of SPC is assumed. However, basic familiarity with R is necessary to follow the steps and algorithms for constructing SPC charts. For those new to R, we recommend excellent (and free) resources such as the NHS-R Community. How to Use This Book New to SPC?: Start with Chapter 1 to learn about variation. Eager to start plotting?: Jump straight to Chapters 5 and 6. Want to go deeper?: Advanced chart types and topics are covered in later chapters for both beginners and experts. Need more resources?: Visit our GitHub repository for datasets, code, and updates. We hope this book proves valuable, and we welcome your feedback for ongoing improvement. About the Authors Jacob Anhøj: Jacob is a medical doctor with over 30 years of experience and a diploma in Information Technology. With 45+ published papers, two books, and extensive teaching expertise, he is deeply passionate about patient safety and quality improvement in healthcare. Jacob is an experienced R user and the creator of several R packages, including qicharts2, widely used for SPC chart construction and analysis. Contact: jacob@anhoej.net Mohammed Amin Mohammed: Emeritus Professor of Healthcare Quality and Effectiveness at the University of Bradford, Mohammed has over 100 peer-reviewed publications. His landmark paper introducing SPC to healthcare (Mohammed, Cheng, and Marshall 2001) and his book Statistical Process Control: Elements of Improving Quality and Safety in Healthcare (Mohammed 2024) are seminal works in the field. He is also the founder of the NHS-R Community, promoting the use of R in healthcare. Contact: profmaminm@gmail.com; m.a.mohammed5@bradford.ac.uk References Mohammed, M A. 2024. Statistical Process Control. Elements of Improving Quality and Safety in Healthcare. Cambridge University Press. https://www.cambridge.org/core/elements/statistical-process-control/60B6025BF62017A9A203960A9E223C10. Mohammed, M A, Rouse Cheng KK, and T Marshall. 2001. “Bristol, Shipman, and Clinical Governance: Shewhart’s Forgotten Lessons.” Lancet 357. https://doi.org/10.1016/s0140-6736(00)04019-8. Thor, Johan, Jonas Lundberg, Jakob Ask, Jesper Olsson, Cheryl Carli, Karin Pukk Härenstam, and Mats Brommels. 2007. “Application of Statistical Process Control in Healthcare Improvement: Systematic Review.” BMJ Qual Saf 16: 387–99. https://doi.org/10.1136/qshc.2006.022194. "],["synopsis.html", "Synopsis Introduction Part 1: Understanding Variation Part 2: Constructing SPC Charts with R Part 3: Case Studies and Worked Examples Part 4: Advanced SPC Techniques Part 5: Best Practices and Tips Part 6: Conclusion and Final Thoughts Appendices", " Synopsis Introduction What is SPC? Preface Synopsis Part 1: Understanding Variation Understanding Variation Understanding SPC Charts Looking for Signals Charts Without Borders – using runs analysis as stand-alone rules with run charts Using SPC in Healthcare Part 2: Constructing SPC Charts with R Your First SPC Charts with Base R Calculating Control Limits Highlighting Freaks, Shifts, and Trends Core R Functions to Construct SPC Charts SPC Charts with ggplot2 Introducing qicharts2 Part 3: Case Studies and Worked Examples Case 1 Case 2 Case 3 Part 4: Advanced SPC Techniques Funnel Plots for Categorical Subgroups Pareto Charts for Ranking Problems SPC Charts for Rare Events T Charts for Time Between Events G Charts for Opportunities Between Cases Bernoulli CUSUM charts for binary data Prime Charts for Count Data with Very Large Sample Sizes Screened I Chart (eliminating freak moving ranges before calculating limits) Improved (normalised) I chart Improved Runs Analysis Using the Bestbox and Cutbox approaches CUSUM and EWMA Charts Dual charting When to Transform Data Before Plotting High Volume Data Scaling Up Charts (technical issues, tabular charts, grids) Multivariate charts Part 5: Best Practices and Tips Tips for Effective SPC Implementation Automating production of SPC charts Engaging stakeholders Continuous monitoring and improvement. Problems with SPC (challenges) Common Pitfalls to Avoid Data issues, misinterpretation of charts Overreacting to common cause variation (over-sensitive runs rules, too tight control limits) Automating recalculation of control limits One-to-one relation between PDSA cycles and dots on the plot A Note on Rational Subgrouping and Sampling Part 6: Conclusion and Final Thoughts Summary of Key Points The Control Charts vs Run Charts Debate Emerging trends in SPC and healthcare analytics Encouragement for Continuous Learning and Application Final Thoughts Appendices Included Data Sets Basic Statistical Concepts Diagnostic Properties of SPC Charts (Two Types of Errors When Using SPC) Introducing R Table of Critical Values for Longest Runs and Number of Crossings Resources and Further Readings Glossary of Terms Ideas for papers: RAGs to RICHes (two voices) Big data issues – CUSUM vs 3000 SPC charts Improved I chart The problem with SPC "],["variation.html", "Chapter 1 Understanding Variation 1.1 SPC and the nature of variation", " Chapter 1 Understanding Variation Imagine writing the letter a by hand using pen and paper. Figure 1.1 shows eight instances of this letter written by one of the authors. The first seven letters were produced with the dominant (right) hand, while the last one was written with the non-dominant hand. Figure 1.1: Hanwritten a’s Consider the seven leftmost a’s. Although these a’s were produced under identical conditions – same hand, date, time, place, pen, paper, temperature, lighting, and other factors – they are not identical. Instead, they exhibit controlled variation. This illustrates that a stable process, where the underlying conditions are the same, produces some degree of variation or “noise”. This controlled variation is known as common cause variation because it is caused by a stable process. When examining common cause variation, one might be tempted to rank the letters, identifying some as “better” or “worse” and attempting to emulate the best while avoiding the worst. However, this approach is misguided. Because all seven letters were produced under the same conditions, no single letter is inherently superior or inferior. From the process perspective, these seven letters are equivalent, and their differences are attributable to common cause variation – variation intrinsic to the process itself. So how can we improve these a’s? To improve the quality of the a’s we should focus on modifying the process rather than trying to draw lessons from the differences between individual a’s. To reduce variation and improve the quality of the letter a, we might consider changes such as using a different pen, paper, or training, or switching to a computer. Of these options, it is intuitive that using a computer will yield the most significant improvement. This insight is supported by the theory of constraints, which views a process as a chain of interconnected links. The strength of the entire chain is limited by its weakest link. Improving this weakest link will enhance the overall performance, while changes to other, non-constraint links, offer minimal benefit. In the context of handwriting, the weakest link is the manual use of the hand. The pen, paper, and lighting are not constraints in this process; altering them will not substantially impact the quality of the ‘a’. Switching to a computer addresses the key constraint, handwriting, resulting in a marked improvement in the quality of the letter. Now consider the rightmost letter in Figure 1.1, produced with the non-dominant hand. Its marked difference from the others suggests a special cause. Special cause variation arises from factors external to the usual process and requires investigation. When encountering special cause variation, the response involves detective work to identify the underlying cause. If the special cause undermines the quality of the process, efforts should focus on eliminating it. If the special cause enhances the quality of the process, then efforts should focus on trying to understand it and integrate it into the process where possible. The handwritten letters exemplify the two types of variation: Common Cause Variation: Intrinsic to the process, this variation is stable and predictable within a range. Addressing it requires systemic changes to the process as a whole. Special Cause Variation: Arising from external factors, this variation is unpredictable and requires investigation. The response depends on whether the variation is beneficial or harmful. In summary then, the handwritten a’s demonstrate that a process exhibits two types of variation –- common cause and special cause – and the action required to address each type of cause is fundamentally different. To address common cause variation, we must take action on a major portion of the process. To address special cause variation, we must first do some detective work to find the cause and then we can decide to eradicate that cause (if it is unfavourable) or keep it (if it is favourable). The originator of this theory was Walter A. Shewhart, who, in the 1920s, sought to improve industrial product quality. Shewhart recognized that quality involves more than meeting specifications; it requires understanding and managing variation. He distinguished between common cause variation, inherent to a stable process, and special cause variation, which results from specific, external factors (Shewhart 1931). There are various characteristics and descriptions of common and special cause variation which are highlighted below. Characteristics of common versus special cause variation Common Cause Variation Special Cause Variation Is caused by a stable process (like writing a signature) and is intrinsic to the process. Is caused by an assignable cause that it extrinsic to the process. Is neither good or bad, it just is. Can be favourable or unfavourable and premediated (as part of an improvement project) or incidental (not part of an improvement project) Can be reduced (but not eliminated) by changing the underlying process. Such changes may be informed by special cause variation. Unfavourable special cause can be eliminated. Favourable special cause can be adopted and adapted into a new process. Is sometimes referred to as random variation, chance variation, or noise. Is sometimes referred to as non-random variation, systematic variation, or signal. Reflects the voice or behaviour of a stable process and affects all those who are part of the process. Is a distinct signal which differs from the usual voice or behaviour of the process and requires further detective work to identify the assignable cause. 1.1 SPC and the nature of variation Statistical Process Control (SPC) revolves around understanding variation and identifying its causes – whether common or special – in order to drive meaningful improvement. Contrary to common misconceptions, SPC is not merely a method for spotting outliers; it’s a framework for enhancing processes and outcomes. Statistical Process Control is not about statistics, it is not about ‘process-hyphen-control’, and it is not about conformance to specifications. […] It is about the continual improvement of processes and outcomes. And it is, first and foremost, a way of thinking with some tools attached. – Wheeler (2000), p. 152 With this foundation in mind, the rest of this book focuses on the tools of SPC, particularly the SPC chart. In the next chapter, we delve into the “anatomy and physiology” of SPC charts, exploring their structure, function, and practical applications. References Shewhart, Walther A. 1931. Economic Control of Quality of Manufactured Product. New York: D. Van Nostrand Company. Wheeler, Donald J. 2000. Understanding Variation – the Key to Managing Chaos. Knoxville, Tennessee: SPC Press. "],["charts-intro.html", "Chapter 2 Understanding SPC Charts 2.1 Anatomy and physiology of SPC charts 2.2 Some common types of control charts – The Magnificent Seven 2.3 Summary of common SPC charts", " Chapter 2 Understanding SPC Charts Now that we’ve explored the concepts of common and special cause variation through the example of handwritten letters, the next step is understanding how to apply these ideas to healthcare processes. This application involves creating charts that represent the “voice” or behavior of a process (usually) over time. By leveraging statistical theory, these charts help determine whether a process is exhibiting common or special cause variation. Such visualisations are known as SPC charts, control charts, or process behavior charts. SPC charts are point-and-line plots of data collected over time. They serve as operational definitions for identifying common and special cause variation. An operational definition is one that is designed to be practical, useful, and ensures consistency in interpretation across different individuals. Figure 2.1: Control chart of systolic blood pressure Figure 2.1 illustrates a control chart showing daily blood pressure measurements. One data point (#6), marked with a red dot, stands out from the others. This deviation triggers a signal, indicating that the data point is likely due to a special cause. Special causes are signalled by unusual patterns in data. By “unusual” we mean something that is unlikely to have happened purely by chance, like a freak data point. Common cause variation is simply noise. The absence of signals of special cause variation is evidence that the behaviour of the process is consistent with common cause variation. The presence of signals is consistent with special cause variation. There are many different types of control charts and the chart to be used is determined mostly by the type of data to be plotted. But regardless of the type of data, (most) SPC charts look the same and are interpreted the same way, by employing a set of statistical tests (or rules) to help identify unusual patterns. In this chapter, we introduce seven of of the most common types of control charts (the magnificent seven) used in healthcare and their practical applications. In the following chapter (3), we delve into the rules and statistical tests for identifying unusual patterns in data. Later, in Part 2 of this book, we provide a detailed guide on performing the calculations necessary to construct and analyze control charts. 2.1 Anatomy and physiology of SPC charts Shewhart’s groundbreaking innovation was the introduction of control limits, which define the boundaries of common cause variation in data. Data points falling within these limits (without unsuual patterns) indicate common cause variation, while those outside indicate special cause variation. Figure 2.2: Standardised control chart. SD = standard deviation; CL = centre line; LCL = lower control limit; UCL = upper control limit Figure 2.2 demonstrates a standardized Shewhart control chart, created using random numbers from a normal distribution with a mean of 0 and a standard deviation of 1. The x-axis represents time or sequence order, while the y-axis displays the indicator values. Each dot, connected by a line, represents a data point sampled sequentially. The chart features: A Center Line (CL), which represents the mean of the data values. Lower Control Limit (LCL) and Upper Control Limit (UCL), defining the range of common cause variation, often referred to as 3-sigma limits. The data points cluster symmetrically around the center line, with most near the mean. As the distance from the center line increases, data points become increasingly sparse. The control limits are positioned to encompass nearly all data points arising from common cause variation. Conversely, points outside the limits are likely to represent special causes. Why 3-Sigma Limits? Shewhart’s choice of 3-sigma limits was based on empirical observations from real-world experiments. For data following a normal distribution, like in Figure 2.2, these limits contain about 99.7% of all data points, meaning the likelihood of a point falling outside the limits purely by chance is approximately 3 in 1000 (0.3%). In a control chart with a total of 20 data points the chance of all data points being within the control limits is about 95% (1 - 0.99720) But before we go down that rabbit hole we note that these theoretical considerations were rejected by Shewhart who found that most real-life data are not normally distributed. Shewhart argued that the choice of 3-sigma limits was made simply because they “work” (Shewhart (1931), p. 18), because this practical choice balances sensitivity (detecting special causes) with specificity (avoiding false alarms), regardless of the data type or distribution. More on this will be discussed in later chapters (??can we give specific chapter??). 2.2 Some common types of control charts – The Magnificent Seven As described above, the control limits are positioned three at three standard deviations (SDs) above and below the centre line. Thus, all types of control charts follow this general formula for control lines: \\[CL \\pm 3SD\\] To construct a control chart, the essential components are the process mean and the process standard deviation. However, it’s important to use the right standard deviation. Rather than using the overall SD of all data—which could include variation from special causes and artificially inflate the control limits—we rely on a pooled average of the within-subgroup SDs. This approach ensures that the calculated control limits reflect only the common cause variation inherent to the process. The exact method for determining the within-subgroup SD depends on the type of data being analyzed. For readers eager to dive into the specifics, the formulas for constructing control limits can be found in Table 6.1 later in the book. Generally, data come in two flavours: count data and measurement data. 2.2.1 Counts Counts are positive integers representing the number of events or cases. While the distinction between events and cases may seem subtle, it is crucial for accurate analysis: Events are occurrences that happen in time and space, such as patient falls. Cases refer to individual units possessing (or lacking) a particular attribute, such as patients who have fallen 2.2.1.1 Events vs. Cases When counting events, every occurrence is recorded. For example, if a patient falls multiple times, each fall is counted as a separate event. In contrast, when counting cases, each unit (e.g., patient) is counted only once, regardless of how many times the event (e.g. the fall) occurred for that individual. Both events and cases can be expressed as ratios, which are counts divided by a relevant denominator, also known as the area of opportunity. However, the way these ratios are constructed depends on whether we are analyzing events or cases: Rates: Events are often expressed as rates, calculated as the number of events per unit of time. For instance, the rate of falls might be expressed as the number of falls per 1,000 patient-days. The denominator is a continuous variable (e.g., time) and is inherently different from the numerator, which counts discrete events. Proportions: Cases are expressed as proportions or percentages, calculated as the number of cases divided by the total number of cases and non-cases. For example, the proportion of patients who fell might represent the percentage of patients who experienced one or more falls. The numerator and denominator represent the same category of count (e.g., patients). The numerator is always a subset of the denominator, meaning it cannot exceed the denominator. The most common chart types for count data are: C chart: count of events, e.g. number of patient falls. U chart: event rates, e.g. number of patient falls per unit of time. P chart: case proportions, e.g. proportion of patients who fell. 2.2.2 Measurements Measurements refer to data collected on continuous scales, often including decimals. Examples include blood pressure, height, weight, or waiting times. As an example, consider waiting or “door-to-needle” times. These may be plotted as either individual times where each data point represents one patient or as an average time for all patients in a certain period of time, for example an hour, day, week, or month. When prodcing SPC charts for measurement data, the choice of control chart depends on how the measurement data are grouped. For individual measurements, we use an I chart (also called an X chart) when each subgroup represents one individual measurement often in combination with a Moving Range (MR) chart to plot the variability between consecutive individual measurements. For subgroup averages, we use an X-bar chart when subgroups consist of multiple measurements, such as the average of several patients’ waiting times within a given period, often in combination with a S chart to plot the within-subgroup standard deviations, which helps visualize the variability within each subgroup. I and MR charts: individual measurement, subgroup size = 1. X-bar and S charts: multiple measurements, subgroup size &gt; 1. 2.3 Summary of common SPC charts A Shewhart control chart is a point-and-line plot of data over time, augmented by three horizontal lines: Centre Line (CL): Represents the overall mean of the data. Lower Control Limit (LCL) and Upper Control Limit (UCL): Define the boundaries of natural process variation. 2.3.1 The Magnificent Seven: Common Types of SPC Charts While there are various types of SPC charts tailored to different types of data, all share a consistent structure and behavior. When choosing the right chart we must first decide what type of data we have - count data or measurement data. For Count Data: ** C Charts: For event counts. ** U Charts: For event rates (events per unit of time or opportunity). ** P Charts: For proportions (cases as a subset of the total). For Measurement Data: ** I Charts with MR charts: For individual measurements. * X-bar Charts with S charts: For subgroup averages. In the next chapter, we will explore the rules and techniques used to detect signals of special causes. We will present a validated set of rules that achieve a high sensitivity to special cause variation while maintaining a reasonable false alarm rate. References Shewhart, Walther A. 1931. Economic Control of Quality of Manufactured Product. New York: D. Van Nostrand Company. "],["testing.html", "Chapter 3 Looking for Signals on SPC charts – beyond the 3-Sigma Rule 3.1 Patterns of non-random variation in time series data 3.2 SPC rules 3.3 SPC charts without borders – using run charts 3.4 A practical approach to SPC analysis 3.5 SPC rules in summary", " Chapter 3 Looking for Signals on SPC charts – beyond the 3-Sigma Rule Until now, we have primarily focused on Shewhart’s 3-sigma rule, which identifies special cause variation when one or more data points fall outside the control limits. The 3-sigma rule is highly effective at detecting large shifts in data. To illustrate: Large shifts (3 SDs): Imagine a process with data following a normal distribution that suddenly shifts upward by three standard deviations (SDs). In this case, the old upper control limit (UCL) would effectively become the new centre line (CL). Consequently, about 50% of subsequent data points would fall above the old UCL, providing a clear signal of the shift. Smaller shifts (1 SD): For a smaller shift of one standard deviation, the old UCL would align with the new 2-sigma limit. As a result, about 2.5% of future data points would exceed this line, signaling the shift but with less frequency. The 3-sigma rule’s sensitivity makes it an invaluable guide for identifying material, easily detectable changes in the behavior of a process. However, for smaller, subtler shifts, additional rules or techniques are often necessary to ensure reliable detection whilst balancing the number of false alarms (Figure 3.1). Figure 3.1: Control chart with progressive shifts in data The performance of the 3-sigma rule has been studied extensively (see, for instance, Montgomery (2020) or Anhøj and Wentzel-Larsen (2018)). To summarize, the 3-sigma rule is most effective when detecting shifts in data of at least 1.5 to 2 standard deviations (SDs). Minor to moderate shifts may go undetected for significant periods. To increase the sensitivity of SPC charts to smaller shifts, a variety of additional rules have been proposed. However, before diving into these rules, it’s important to first explore the different patterns in data that often signal the presence of special causes. 3.1 Patterns of non-random variation in time series data In the iconic Western Electric Handbook (Western Electric Company 1956) a variety of control chart patterns are described to assist engineers in interpreting control charts based on the notion that certain patterns often reflect specific causes. In our experience, the most common special cause patterns found in healthcare data are freaks, shifts, and trends. 3.1.1 Freaks A freak is one or few data points that are distinctly different from the rest (Figure 3.2). Freaks are by definition transient in nature – they appear and then go away. Figure 3.2: Control chart with a large (2 SD) transient shift in data A freak is a data point or a small number of data points that are distinctly different from the rest, as shown in Figure 3.2). By definition, freaks are transient — they appear suddenly and then disappear. Freaks are often caused by data or sampling errors, but they can also result from temporary external factors influencing the process, such as shifts in patient case mix during a holiday season. In some cases, freaks may simply be a false alarm. 3.1.2 Shifts A trend is a gradual change in the process center, as shown in Figure 3.3. While some texts define a trend more specifically as a series of data points moving consistently up or down, in this book we use the term in a broader sense to refer to any gradual shift in one direction. Trends occur when external forces are consistently influencing the data in one direction, particularly when this influence is continuous and cumulative. Trends are commonly observed when improvements are implemented incrementally, such as in large organizations. In such cases, sequential shifts in data at the department level may accumulate into a broader trend at the organizational level. Figure 3.3: Control chart with a minor (1 SD) sustained shift in data Shifts are caused by sudden changes in process behaviour. In fact, in healthcare improvement we strive to induce shifts in the desired direction by improving the structures and procedures that are behind data. 3.1.3 Trends A trend is a gradual change in process centre (Figure 3.4). Note that in some texts a trend is more specifically a series of data points that are all going up or down. In this book, we use the term “trend” in the more general sense as a gradual change in one direction. Figure 3.4: Control chart with a trend in data Trends are seen when forces outside the usual process are pushing data consistently in one direction, and specifically when the push is continuous and the effect cumulative. Trends are commonly seen when improvements are implemented in a stepwise fashion, for example by being introduced incrementally in a large organisation. In such cases we may observe sequential shifts in data at the department level that sum up to a trend at the organisational level. 3.1.4 Other unusual patterns There are numerous other types of “unusual” or mixed patterns that may appear in data. However, based on our experience in healthcare, process improvement or deterioration is most commonly associated with freaks, shifts, or trends. Learning to recognize these patterns is essential for uncovering the underlying causes of change. That being said, depending on the context and the purpose of using SPC, it may be valuable to look for other types of patterns in the data. This is particularly true for cyclic or seasonal data, where specific patterns repeat based on time of day, week, month, or year (Jeppegaard et al. 2023). For example, excess mortality linked to weekend admissions might not present itself as a freak, shift, or trend, but it is still an important pattern to recognize in order to address the issue effectively. 3.2 SPC rules If patterns of special cause variation were always as clear as in the figures 3.2, 3.3, and 3.4 there would be no need for SPC. However, in practice, special causes often manifest in more subtle ways and so we use additonal statistical tests or SPC rules that are designed to signal the presence, or rather the likelihood, of special cause variation. We’ve already seen Shewhart’s original 3-sigma rule in action, but many additional rules have been developed to identify minor shifts, trends, and other specific patterns in data. While it may seem tempting to apply all known rules to the data, it’s important to remember that the more tests we apply, the more signals we generate and this increases the risk of false alarms - where common cause variation is mistakenly identified as special cause variation. Therefore, it’s crucial to strike a balance: we must select as few rules as necessary to minimize false alarms while ensuring the detection of true special cause signals. This topic will be discussed in greater detail in the chapter on Diagnostic Errors later in this book. For this book, we will concentrate on two sets of rules that have been thoroughly studied and validated for their effectiveness. 3.2.1 Tests based on sigma limits The best known tests for special cause variation are probably the Western Electric Rules (WE) described in the Statistical Quality Control Handbook (Western Electric Company 1956). The WE rules consist of four simple tests that can be applied to control charts by visual inspection and are based on the identification of unusual patterns in the distribution of data points relative to the center lines and the control limits. One or more points outside of the 3-sigma limits (Shewhart’s original 3-sigma rule). Two out of three successive points beyond a 2-sigma limit (two thirds of the distance between the centre line and the control line). Four out of five successive points beyond a 1-sigma limit. A run of eight successive points on one side of the centre line. We leave it to the reader to apply WE rules #2-#4 to figures 3.3 and 3.4. The WE rules have proven their worth during most of a century. One thing to notice though is that the WE rules are most effective with control charts that have between 20 and 30 data points. With fewer data points, they lose sensitivity (more false negatives), and with more data points they lose specificity (more false positives). WE rule #4 is independent of the sigma limits. It is based on assumptions regarding the length of runs on either side of the centre line. A run is defined as one or more successive data points on the same side of the centre line. Rules based on runs analysis are further discussed below. 3.2.2 Runs analysis – tests based on the distribution of data points around the centre line If we assume that the center line divides the data into two halves, the probability of any data point falling above or below the center is fifty-fifty. Similarly, the probability that two neighboring points fall on the same or opposite side of the center line is also fifty-fifty. By dichotomizing the data into runs of points either above or below a certain value—such as the center line—we enter the realm of runs analysis. The fundamental idea behind runs analysis is that the length and number of runs in a random process are governed by natural laws, making them predictable within certain limits. In essence, when a process shifts or trends, runs tend to become longer and fewer. Therefore, we can design runs tests to detect unusually long or unusually few runs. The key question is: what constitutes “unusually” long or “unusually” few runs? To illustrate, imagine flipping a coin ten times. Would you be surprised to get three or four heads in a row? Probably not. But what if you got ten heads in a row? That would definitely be surprising. Now, imagine tossing the coin 100 times. Would a sequence of ten heads be surprising then? Probably not, because as the number of trials increases, the likelihood of observing a run of ten heads also increases. This intuitive understanding highlights that what constitutes an “unusually” long run depends on the total number of observations or subgroups. The more subgroups we have in our SPC chart, the longer the longest runs are likely to be. From practical experiments, some theoretical considerations, and years of experience (Anhøj and Olesen 2014; Anhøj 2015) we suggest these two runs tests: Unusually long runs: A run is one or more consecutive data points on the same side of the centre line. Data points that fall directly on the centre line neither break nor contribute to the run. The upper 95% prediction limit for longest run in a random process is approximately \\(log_2(n)+3\\) (rounded to the nearest integer), where \\(n\\) is the number of useful data points (data points not on the centre line). For example, in a run chart with 24 useful data points a run of more than round(log2(24) + 3) = 8 would suggest a shift in the process (Schilling 2012). Unusually few crossings: Rather than counting the number of runs, we count the number of crossings, which by definition is one less than the number of runs. A crossing is when two consecutive data points are on opposite sides of the centre line. In a random process, the number of crossings follows a binomial distribution. The lower 5% prediction limit for number of crossings is found using the cumulative probability distribution, qbinom(p = 0.05, size = n - 1, prob = 0.5). Thus, in a run chart with 24 useful data points, fewer than qbinom(0.05, 24 - 1, 0.5) = 8 crossings would suggest that the process is shifting (Chen 2010). The two runs rules are two sides of the same coin – when runs get longer, crossings get fewer and vice versa – and either of them may signal special cause variation. Figure 3.3 has 24 data points, the longest run consists of 12 data points (#13 - #24), and the line crosses the centre line 9 times. Since the longest run is longer than expected, we may conclude that there is reason to believe that the process is shifting. In Figure 3.3 there are two long runs with 9 data points and only 5 crossings also suggesting that data are shifting. It’s important to note that the tests themselves do not identify the specific types of patterns in the data, nor do they reveal the underlying causes of shifts or trends. The responsibility for interpreting the results lies with the data analyst and the individuals involved in the process. Critical values for longest runs and number of crossings for 10-100 data points are tabulated in Appendix E. Apart from being comparable in sensitivity and specificity to WE rules #2-#4 with 20-30 data points (Anhøj and Wentzel-Larsen 2018), these runs rules have some advantages: They do not depend on sigma limits and thus are useful as stand-alone rules with run charts (more on run charts in the next section). They adapt dynamically to the number of available data points, and can be applied to charts with as few as 10 and up to indefinitely many data points without losing sensitivity or specificity. In practice these runs rules may be used as alternatives to WE rules #2-#4 to help identify shifts and trends alongside the WE rule #1 for freaks. 3.3 SPC charts without borders – using run charts As discussed in the previous section, some rules rely solely on a single line representing the center of the data. We assumed that the center line divides the data into two equal halves. While the process average typically serves as a good representation of this center, this assumption may not hold if the data are skewed. However, if we use the median instead of the mean, the assumption always holds true, because the median is by definition the middle value. So, what happens if we remove the sigma lines and use the median as the center line? We get a run chart, which is one of the most valuable tools in quality improvement and control. Figure 3.5: Run chart Figure 3.5 is a run chart of the data from Figure 2.2. We notice that the centre line is a little different from the control chart because we have used the empirical median rather than the theoretical mean. Consequently, data are now evenly distributed around the centre line with 12 data points on each side. The longest run have 3 data points (#13-#15 and #22-#24), and the data line crosses the centre line 13 times. Since there are no unusually long runs and not unusually few crossing we conclude that this process shows no signs of persistent shifts in data. Figure 3.6 is a run chart with data from Figure 3.4 containing a trend. The runs analysis confirms our “analysis-by-eye” by finding two unusually long runs with 9 data points and unusually few crossings (4). Figure 3.6: Run chart with a trend Run charts are a lot easier to construct than are control charts. They do not make assumptions about the distribution of data. And they have better sensitivity to minor and moderate persistent shifts and trends than control charts based on only the 3-sigma rule. So why do we bother making control charts at all? In fact, we can only think of two reasons: 1) control charts quickly pick up large, possibly transient, shifts (for example freaks) that may go unnoticed by run charts, and 2) the control limits reflect the common cause variability of the process and hence define its capability. Foruntatley, we do not need to choose between run and control charts. In fact, they are good companions for use at different stages of quality improvement and control. 3.4 A practical approach to SPC analysis Before we move on, let’s take a moment to clarify the purpose of SPC charts. As we will explore in detail in the next chapter (see (ref?)(using)), SPC charts support two distinct purposes: process improvement and process monitoring. When we are focused on process improvement, our goal is to create sustained shifts in the desired direction. Shifts are expected in this context, as improvements often happen gradually. Since we aim for lasting changes, runs analysis is our primary tool to detect these shifts. In process monitoring, the objective is to maintain process stability, with no expected shifts in the data. Here, our focus is on detecting any signs of process deterioration as quickly as possible. For this, the 3-sigma rule is highly effective. To improve sensitivity to minor or moderate shifts, we may combine the 3-sigma rule with either the rest of the Western Electric (WE) rules or the two runs rules. However, we must be mindful that adding more tests increases the risk of false alarms. Regardless of the task, we recommend starting any SPC analysis with an “assumption-free” run chart, using the median as the center line. If runs analysis indicates non-random variation, calculating sigma limits becomes meaningless, as these values are irrelevant when shifts are already evident. In such cases, the focus should shift to identifying special causes, rather than calculating control limits. If the goal is process improvement, we continue with the run chart until we observe significant and sustained improvement, leading to a new and better process. Once this new process stabilizes and appears set to continue, we may transition to monitoring mode by adding control limits and using the mean as the center line. Process monitoring is appropriate when the process is stable (common cause variation only) and the outcome is satisfactory. If either condition is not met, we should return to improvement mode. 3.5 SPC rules in summary SPC rules are statistical tests designed to detect special cause variation in time series data. Given the variety of patterns that can indicate special causes, many rules have been developed. However, applying too many rules increases the risk of false alarms. Therefore, it is important to choose a small set of rules that strike a balance: maximizing the ability to detect true alarms (special causes) while minimizing false alarms. We recommend starting any SPC analysis with a median-based run chart and using the two runs rules to test for unusually long runs or an unusually small number of crossings. If, and only if, the runs analysis indicates random variation (no special cause), and the process outcome is stable and satisfactory, we may proceed to use the mean as the center line and add control limits to help identify large shifts and freak data points more easily. References Anhøj, Jacob. 2015. “Diagnostic Value of Run Chart Analysis: Using Likelihood Ratios to Compare Run Chart Rules on Simulated Data Series.” PLoS ONE. https://doi.org/10.1371/journal.pone.0121349. Anhøj, Jacob, and Anne Vingaard Olesen. 2014. “Run Charts Revisited: A Simulation Study of Run Chart Rules for Detection of Non-Random Variation in Health Care Processes.” PLoS ONE. https://doi.org/10.1371/journal.pone.0113825. Anhøj, Jacob, and Tore Wentzel-Larsen. 2018. “Sense and Sensibility: On the Diagnostic Value of Control Chart Rules for Detection of Shifts in Time Series Data.” BMC Medical Research Methodology. https://doi.org/10.1186/s12874-018-0564-0. Chen, Zhenmin. 2010. “A Note on the Runs Test.” Model Assisted Statistics and Applications 5: 73–77. https://doi.org/10.3233/MAS-2010-0142. Jeppegaard, Maria, Steen C. Rasmussen, Jacob Anhøj, and Lone Krebs. 2023. “Winter, Spring, Summer or Fall: Temporal Patterns in Placenta-Mediated Pregnancy Complications—an Exploratory Analysis.” Gynecol Obstet 309: 1991–98. https://doi.org/https://doi.org/10.1007/s00404-023-07094-6. Montgomery, Douglas C. 2020. Introduction to Statistical Quality Control, Eighths Ed. Wiley. Schilling, Mark F. 2012. “The Surprising Predictability of Long Runs.” Mathematics Magazine 85: 141–49. https://doi.org/10.4169/math.mag.85.2.141. Western Electric Company. 1956. Statistical Quality Control Handbook. New York: Western Electric Company inc. "],["using.html", "Chapter 4 Using SPC in healthcare 4.1 Using SPC to monitor a process 4.2 Using SPC to improve a process 4.3 Successful use of SPC in healthcare", " Chapter 4 Using SPC in healthcare As briefly discussed in the previous chapter, in healthcare, we use SPC methodology in two main ways: Monitoring the behaviour or performance of an existing process (e.g. complications following surgery), or Improving an existing process (e.g. redesigning the pathway for patients with fractured hips). 4.1 Using SPC to monitor a process In the monitoring mode, the primary aim is to determine if a process is deteriorating which is usually indicated by signals of special cause variation where detective work is needed to find the cause and then eliminate it. Such detective work can be undertaken by using the Pyramid Model of Investigation described below. The key aim of using statistical process control charts to monitor healthcare processes is to ensure that quality and safety of care are adequate and not deteriorating. So when a signal of special cause variation is seen on a control chart monitoring a given outcome, investigation is necessary. However, the chosen method must recognise that the link between recorded outcomes and quality of care is complex, ambiguous and subject to multiple explanations (Lilford et al. 2004). Failure to do so may inadvertently contribute to premature conclusions and a blame culture that undermines the engagement of clinical staff and the credibility of statistical process control. As Rogers note: If monitoring schemes are to be accepted by those whose outcomes are being assessed, an atmosphere of constructive evaluation, not ‘blaming’ or ‘naming and shaming’, is essential as apparent poor performance could arise for a number of reasons that should be explored systematically. – Rogers et al. (2004) To address this need, Mohammed et al. (2004) proposed the Pyramid Model for Investigation of Special Cause Variation in healthcare – a systematic approach of hypothesis generation and testing based on five a priori candidate explanations for special cause variation: data, patient case-mix, structure/resources, process of care, and carer(s) (Figure 4.1). Figure 4.1: Pyramid Model for Investigation These broad categories of candidate explanations are arranged from most likely (data) to least likely (carers), so offering a road map for the investigation that begins at the base of the pyramid and stops at the level that provides a credible, evidence-based explanation for the special cause. The first two layers of the model (data and casemix factors) provide a check on the validity of the data and casemix-adjusted analyses, whereas the remaining upper layers focus more on quality of care related issues. A proper investigation requires a team of people with expertise in each of the layers. Such a team is also likely to include those staff whose outcomes or data are being investigated, so that their insights and expertise can inform the investigation while also ensuring their buy-in to the investigation process. Basic steps for using the model are shown below. Form a multidisciplinary team that has expertise in each layer of the pyramid, with a decision-making process that allows them to judge the extent to which a credible cause or explanation has been found, based on hypothesis generation and testing. Guided by what type(s) of non-random pattern(s) exist in data (freaks, shifts, trends, mixed, or cyclic patterns) candidate hypotheses are generated and tested starting from the lowest level of the Pyramid Model and proceeding to upper levels only if the preceding levels provide no adequate explanation for the special cause. A credible cause requires quantitative and qualitative evidence, which is used by the team to test hypotheses and reach closure. If no credible explanation can be found, then the only plausible conclusion is that the signal itself was a false signal. The types of questions that can be asked when undertaking the detective work are highlighted below. Data: Data quality issues, e.g. coding accuracy, reliability of charts, definitions, and completeness. Are the data coded correctly? Has there been a change in data coding practices (e.g. are there less experienced coders)? Is clinical documentation clear, complete, and consistent? Case mix: Although differences in case mix are accounted for in the calculation, it is possible that some residual confounding may remain. Are factors peculiar to this hospital not taken into account in the risk adjustment? Has the pattern of referrals to this hospital changed in a way not considered in risk adjustment? Structure or resource: Availability of beds, staff, and medical equipment; institutional processes. Has there been a change in the distribution of patients in the hospital, with more patients in this speciality spread throughout the hospital rather than concentrated in a particular unit? Has the physical environment or organisational structures changed? Process of care: Medical treatments, clinical pathways, patient admission and discharge policies. Has there been a change in the care being provided? Have new treatment guidelines been introduced? Professional staff/carers: Practice and treatment methods etc. Has there been a change in staffing for treatment of patients? Has a key staff member gained additional training and introduced a new method that has led to improved outcomes? 4.2 Using SPC to improve a process SPC is also used to support efforts to improve a process. In healthcare, this usually involves making small scale changes and measuring their impact on an SPC chart. In the improving mode, the primary aim is to determine if changes made to a process have been successful (or not). For example, in the handwriting process considered earlier, do we get better a’s after switching to a computer? This is determined by looking to see the impact of the change in the form of signals of special cause variation on an SPC chart (provided we have a creditable measure of “letter quality”). The degree of alignment between changes to the process and subsequent signals of special cause variation provide a story which qualitatively and quantitatively describes the impact of changes. Common cause variation can only be addressed by changing a major portion of the process. What do we mean by a major portion? The Theory of Constraints (Goldratt and Cox 2022) offers the analogy of a chain to demonstrate that the strength of the chain is determined by the weakest link. If we increase the strength of the weakest link the whole chain is strengthened. If we increase the strength of other links but not the weakest link, then the chain does not get stronger. The weakest link is the constraint on the performance of the system, and it is argued that in real systems there are usually only a few, perhaps one or two, constraining factors, all other factors are non-constraints. The Model for Improvement, proposed by Langley et al. (2009), is a widely used framework in healthcare to guide improvement efforts. It consists of three fundamental questions and the Plan-Do-Study-Act (PDSA) cycle. What are we trying to accomplish? This question defines the aim of the improvement effort, which should be specific, measurable, and time-bound along with a rationale for why this is important. How will we know that a change is an improvement? This question focuses on measurement. The team identifies key performance indicators and other metrics to assess whether the change has led to improvement. This includes balancing measures designed to capture unintended negative consequences from changing a system or process. What changes can we make that will result in improvement? This question explores potential change ideas or interventions that could lead to the desired improvement. These ideas are undertaken according to the PDSA Cycle, which is a method for iterative small-scale testing of changes: Plan: Develop a plan to test the change, including who, what, when, and where. Do: Implement the change on a small scale. Study: Analyze the results, focusing on the impact of the change. Act: Decide whether to adopt, modify, or abandon the change based on the results. There are other approaches to improvement in healthcare, such as Lean, Six Sigma, and Systems Engineering. The SPC chart can support each of these approaches because it offers a robust and insightful way to test the success of change ideas. 4.3 Successful use of SPC in healthcare The successful use of SPC in healthcare requires a number of factors which is more than the production of an SPC chart especially in complex adaptive systems like healthcare. These factors include: engaging the stakeholders; forming a team; defining the aim; selecting the process of interest; defining the metrics of interest; ensuring that data can be reliably measured, collected and fed back; and establishing baseline performance – all in a culture of continual learning and improvement that is supported by the leadership team. To see examples of SPC in action in healthcare, please see Mohammed (2024). Nevertheless, it is important to note that SPC charts are not necessarily easy to construct. After examining 64 statistical process control charts, Koetsier et al. (2012) found that that almost half the charts had technical problems which suggests a need for more training for those constructing charts – which is the primary motivation for this book. This is the end of Part 1. In Part 2, beginning with Chapter 5, we show you how to produce SPC charts using R. References Goldratt, Eliyahu M., and Jeff Cox. 2022. The Goal: A Process of Ongoing Improvement, 3rd Edition. Routledge. Koetsier, A., S. N. van der Veer, K. J. Jager, N. Peek, and N. F. de Keizer. 2012. “Control Charts in Healthcare Quality Improvement.” Methods of Information in Medicine. https://doi.org/10.3414/ME11-01-0055. Langley, Gerald J, Ronald D Moen, Kevin M Nolan, Thomas W Nolan, Clifford L Norman, and Lloyd P Provost. 2009. The Improvement Guide. San Fracisco, CA: Jossey-bass. Lilford, Richard, Mohammed A Mohammed, David Spiegelhalter, and Richard Thomson. 2004. “Use and Misuse of Process and Outcome Data in Managing Performance of Acute Medical Care: Avoiding Institutional Stigma.” The Lancet 363: 1147–54. https://doi.org/https://doi.org/10.1016/S0140-6736(04)15901-1. Mohammed, M A. 2024. Statistical Process Control. Elements of Improving Quality and Safety in Healthcare. Cambridge University Press. https://www.cambridge.org/core/elements/statistical-process-control/60B6025BF62017A9A203960A9E223C10. Mohammed, M A, Anthony Rathbone, Paulette Myers, Divya Patel, Helen Onions, and Andrew Stevens. 2004. “An Investigation into General Practitioners Associated with High Patient Mortality Flagged up Through the Shipman Inquiry: Retrospective Analysis of Routine Data.” BMJ 328 (7454): 1474–77. https://doi.org/10.1136/bmj.328.7454.1474. Rogers, Chris A., Barnaby C. Reeves, Massimo Caputo, J. Saravana Ganesh, Robert S. Bonser, and Gianni D. Angelini. 2004. “Control Chart Methods for Monitoring Cardiac Surgical Performance and Their Interpretation.” The Journal of Thoracic and Cardiovascular Surgery 128: 811–19. https://doi.org/https://doi.org/10.1016/j.jtcvs.2004.03.011. "],["first-chart.html", "Chapter 5 Your First SPC Charts With Base R 5.1 A run chart of blood pressure data 5.2 Adding control limits to produce a control chart 5.3 That’s all, Folks!", " Chapter 5 Your First SPC Charts With Base R From Part 1 of this book we have a good grasp of what SPC is and how SPC charts work. In this chapter we will start constructing SPC charts using functions from base R. In later chapters we will include functions from ggplot2 and qicharts2 (an R package developed by JA). In essence, an SPC charts is a (point-and-)line plot of data over time with a horizontal line to represent the data centre and – in case of a control chart – two lines to represent the estimated upper and lower boundaries of the natural variation in data. 5.1 A run chart of blood pressure data Consider the data from Figure 2.1, which show systolic blood pressure measurements (mm Hg) for a patient taken in the morning over 26 consecutive days (Mohammed, Worthington, and Woodall 2008). systolic &lt;- c(169, 172, 175, 174, 161, 142, 174, 171, 168, 174, 180, 194, 161, 181, 175, 176, 186, 166, 157, 183, 177, 171, 185, 176, 181, 174) First we plot a simple point-and-line chart without any additional lines (Figure 5.1): # Make point-and-line plot plot(systolic, type = &#39;o&#39;) Figure 5.1: Simple run chart (As a side note, this reminds me (JA) of a manager, who once said to me: “You make such beautiful graphs, but can’t you stop them from going up and down all the time.” 😁) To guide the runs analysis we will add a horizontal centre line, which in run charts is usually the median of the data points (Figure 5.2): # Create systolic-coordinates for the centre line cl &lt;- median(systolic) # calculate median cl &lt;- rep(cl, length(systolic)) # repeat to match the length of y # Plot data and add centre line plot(systolic, type = &#39;o&#39;) lines(cl) Figure 5.2: Run chart with centre line We find that the longest run has 4 data points (#14-#17) and that the curve crosses the centre line 9 times. Four data points (#4, #7, #10, #26) lie directly on the centre line, so we have 22 useful observations. With 22 useful observations and using the two runs rules proposed in Chapter 3, the upper limit for longest run is 7 as is (coincidentally) the lower limit for number of crossings. Consequently, there are no signs of persistent shifts or trends in data over time. 5.2 Adding control limits to produce a control chart We use the same technique to add the lower and upper control limits. Remember that the control limits are usually set to \\(CL \\pm 3 SD\\), where CL is the centre line, usually the mean, and SD is the estimated standard deviation – that is, the standard deviation of the natural variation in data, not the pooled standard deviation that would include both random and any non-random variation. For data consisting of single measurements, we choose the I chart. To estimate the common cause standard deviation we use the average moving range divided by a constant, 1.128. The moving ranges are the absolute pairwise differences between consecutive data points. We will talk much more about control limits in Chapter 6. # Calulate the centre line (mean) cl &lt;- rep(mean(systolic), length(systolic)) # Calculate the moving ranges of data mr &lt;- abs(diff(systolic)) # Print the moving ranges for our viewing pleasure mr ## [1] 3 3 1 13 19 32 3 3 6 6 14 33 20 6 1 10 20 9 26 6 6 14 9 5 7 # Calculate the average moving range amr &lt;- mean(mr) # Calculate the process standard deviation s &lt;- amr / 1.128 # Create y-coordinates for the control limits lcl &lt;- cl - 3 * s ucl &lt;- cl + 3 * s When plotting data, we need to expand the y-axis limits to make room not only for the data points but also the control limits (Figure 5.3): # Plot data while expanding the y-axis to make room for all data and lines plot(systolic, type = &#39;o&#39;, ylim = range(systolic, lcl, ucl)) # Add lines lines(ucl) lines(cl) lines(lcl) Figure 5.3: Standardised control chart One (freak) data point is below the lower control limit suggesting that this reading has most likely been influenced by something outside the natural process. The control chart itself does not tell what caused the special cause, but it tells us that this data point should be investigated with the purpose of learning and improvement. 5.3 That’s all, Folks! So constructing an SPC chart using R may be done using a few lines of code. In fact, most of the code in this chapter went to prepare the data to be plotted. The charts themselves are rather simple and plotting is the same every time: 1. plot the dots; 2. add the lines. Later we will wrap all the steps in a function that automates the calculation of centre and control lines, highlights signals of non-random variation in data, and makes plots that are a lot nicer to look at than the rather crude ones we have produces so far. In the next chapter we will produce SPC charts that are most commonly used in healthcare, “The Magnificent Seven”. References Mohammed, M A, P Worthington, and W H Woodall. 2008. “Plotting Basic Control Charts: Tutorial Notes for Healthcare Practitioners.” BMJ Qual Saf 17 (2): 137–45. https://doi.org/10.1136/qshc.2004.012047. "],["limits.html", "Chapter 6 Calculating Control Limits 6.1 Introducing the spc() function 6.2 Formulas for calculation of control limits 6.3 Count data 6.4 Measurement data 6.5 Control limits in short Control chart constants", " Chapter 6 Calculating Control Limits In the previous chapter we established the basis for constructing SPC charts with R using the I chart as an example. In this chapter we continue with the rest of The Magnificent Seven control charts and how to construct their control limits. 6.1 Introducing the spc() function To avoid repeating ourselves, let’s begin by creating a function to automate the plotting for us. spc &lt;- function( x, # x axis values y = NULL, # data values cl = NA, # centre line lcl = NA, # lower control limit ucl = NA, # upper control limit ... # other parameters passed to the plot() function ) { # if y is missing, set y to x and make a sequence for x if (is.null(y)) { y &lt;- x x &lt;- seq_along(y) } # repeat line values to match the length of y if (length(cl) == 1) cl &lt;- rep(cl, length(y)) if (length(lcl) == 1) lcl &lt;- rep(lcl, length(y)) if (length(ucl) == 1) ucl &lt;- rep(ucl, length(y)) # plot the dots and draw the lines plot(x, y, type = &#39;o&#39;, ylim = range(y, lcl, ucl, na.rm = TRUE), ...) lines(x, cl) lines(x, lcl) lines(x, ucl) } The spc() function takes five arguments of which only the first, x, is mandatory. If only x is provided, a simple point-and-line chart will be drawn from the x values. If y is also provided, x values will be used for the x axis. The line arguments (cl, lcl, ucl) are used (if provided) for the centre line and control limits respectively. Line arguments may be given as either single values or vectors of the same length as x. In addition, we may provide additional arguments for the plot() function, e.g. main, xlab, and ylab for title and axis labels. Let us test it with the blood pressure data from Chapter 5 (Figure 6.1). # create an x variable, not that is it necessary in this case, just because we can day &lt;- seq_along(systolic) # plot data spc(day, systolic, cl, lcl, ucl) Figure 6.1: Control chart of systolic blood pressure With this function we are now able to construct all kinds of control charts. All we need to know is how to calculate the centre line and the control limits. 6.2 Formulas for calculation of control limits The formulas for calculation control limits for The Magnificent Seven introduced in Chapter 2 are provided in Table 6.1. Don’t be alarmed by the number of strange symbols, we will translate the formulas to R code one by one as we move along. Table 6.1: Formulas for calculating control limits Subgroups Chart type Control limits Assumed distribution Count data Counts C \\(\\bar{c}\\pm3\\sqrt{\\bar{c}}\\) Poisson Rates U \\(\\bar{u}\\pm3\\sqrt{\\frac{\\bar{u}}{n_{i}}}\\) Poisson Proportions P \\(\\bar{p}\\pm3\\sqrt{\\frac{\\bar{p}(1-\\bar{p})}{n_{i}}}\\) Binomial Measurement data Individual measurements I \\(\\bar{x}\\pm2.66\\overline{MR}\\) Normal Moving ranges of individual measurements MR \\(3.267\\overline{MR}\\) Normal Averrages of 2 or more measurements X-bar \\(\\bar{\\bar{x}}\\pm A_{3}\\bar{s}\\) Normal Standard deviations of 2 or more measurements S \\(B_{3}\\bar{s};\\ B_{4}\\bar{s}\\) Normal As discussed in Chapter 2, data come in two flavours: count data and measurement data. Counts are positive integers that represent counts of events or cases, for example patient falls, surgical complications, or healthy babies. Measurements are data that are measured on continuous scales and may have decimals, for example blood pressure, height and weight, or waiting times. 6.3 Count data For count charts in this chapter we will use the bacteremia data set: # read data from file bact &lt;- read.csv(&#39;data/bacteremia.csv&#39;, # path to data file comment.char = &#39;#&#39;, # ignore lines that start with &quot;#&quot; colClasses = c( # specify variable types &#39;Date&#39;, &#39;integer&#39;, &#39;integer&#39;, &#39;integer&#39;, &#39;integer&#39; )) # print the first six rows head(bact) ## month ha_infections risk_days deaths patients ## 1 2017-01-01 24 32421 23 100 ## 2 2017-02-01 29 29349 22 105 ## 3 2017-03-01 26 32981 13 99 ## 4 2017-04-01 16 29588 14 85 ## 5 2017-05-01 28 30856 17 98 ## 6 2017-06-01 16 30544 15 85 The variables are: month (date): month of infection ha_infections (numeric): number of hospital acquired infections risk_days (numeric): number of patient days without infection deaths (numeric): number of patients who died within 30-day after a hospital or community acquired (all-cause) infection patients (numeric): number of patients with all-cause infection We use C charts for event counts and U chart for event rates. For case proportions we use the P chart. 6.3.1 C chart The C charts (C for counts) is the simplest of all control charts and the easiest to produce. The process standard deviation is simply estimated as the square root of the process mean. C charts are appropriate when counting events from (nearly) equally big chunks of time or space. Figure 6.2 shows a C chart of the monthly number of hospital acquired bacteremias. with(bact, { cl &lt;- mean(ha_infections) lcl &lt;- cl - 3 * sqrt(cl) ucl &lt;- cl + 3 * sqrt(cl) # print the limits cat(&#39;UCL =&#39;, ucl, &#39;\\n&#39;) cat(&#39;CL =&#39;, cl, &#39;\\n&#39;) cat(&#39;LCL = &#39;, lcl, &#39;\\n&#39;) # plot the chart spc(month, ha_infections, cl, lcl, ucl, ylab = &#39;Infections&#39;, # y-axis label xlab = &#39;Month&#39;) # x-axis label }) ## UCL = 36.94952 ## CL = 22.66667 ## LCL = 8.38381 Figure 6.2: C control chart of monthly numbers of hospital acquired bacteremias The average monthly number of cases is 22.7, and all data points are within the control limits ranging from 8.4 to 36.9. So if nothing changes, we should expect future infection counts to be around 23, and we should not be surprised if once in a while, we observe as little as 9 or as many as 36 infections in a single month. 6.3.2 U chart U charts are useful when events are counted over chunks of time or space that are not equally sized resulting in “unequal area of opportunity” (hence the U). In our case we might want to adjust for for the number of patient days that may vary depending on the time of year or between organisational units. The U chart adjust for this by presenting rates rather than raw counts. Events are often rare in comparison to their areas of opportunity. So to avoid very small numbers on the y-axis it may be useful to multiply the y-axis by some factor before plotting. In Figure 6.3 we multiply by 10,000 to display infections per 10,000 risk days rather than per day. with(bact, { y &lt;- ha_infections / risk_days # rates to plot cl &lt;- sum(ha_infections) / sum(risk_days) # overall mean rate, centre line s &lt;- sqrt(cl / risk_days) # standard deviation lcl &lt;- cl - 3 * s # lower control limit ucl &lt;- cl + 3 * s # upper control limit # multiply y axis to present infections per 10,000 risk days multiply &lt;- 10000 y &lt;- y * multiply cl &lt;- cl * multiply lcl &lt;- lcl * multiply ucl &lt;- ucl * multiply spc(month, y, cl, lcl, ucl, ylab = &#39;Infections per 10,000 risk days&#39;, xlab = &#39;Month&#39;) }) Figure 6.3: U chart of monthly number of infections per 10,000 risk days The U chart shows that on average we have 7.5 infections per 10,000 risk days, and that all data points are between the control limits ranging from about 3.5 to 12. We see that the control limits vary depending on the denominator (risk days), for each data point. Large denominator \\(\\rightarrow\\) narrow limits; small denominator \\(\\rightarrow\\) wide limits. In cases like this where the denominator – the area of opportunity – only varies little between subgroups, the U charts adds little compared to the C chart. For pedagogical reasons we may prefer the C chart, because it is a lot easier to relate to 23 infections per month than to 7.5 infections per 10,000 risk days. 6.3.3 P chart P charts are for proportions (or percentages). Figure 6.4 shows the monthly percentage of patients with bacteremia who died within 30 days. with(bact, { y &lt;- deaths / patients cl &lt;- sum(deaths) / sum(patients) # process mean, centre line s &lt;- sqrt((cl * (1 - cl) / patients)) # process standard deviation lcl &lt;- cl - 3 * s # lower control limit ucl &lt;- cl + 3 * s # upper control limit # multiply by 100 to get percentages rather than proportions multiply &lt;- 100 y &lt;- y * multiply cl &lt;- cl * multiply lcl &lt;- lcl * multiply ucl &lt;- ucl * multiply spc(month, y, cl, lcl, ucl, ylab = &#39;%&#39;, xlab = &#39;Month&#39;) }) Figure 6.4: P chart of monthly 30-day mortality rates On average the mortality is 21%, and all data points are within the control limits. As with U charts, the control limits vary depending on the size of the denominator. 6.4 Measurement data For this section we will use a data set on response times for grade 2 caesarean sections, that is, the time (in minutes) it took from the decision to perform a C-section to the baby was delivered. The goal is to keep the response times below 30 minutes. The csect data frame contains the date and time, the month, and the number of minutes from decision to delivery for 208 grade 2 section over a two-year period. # read raw data csect &lt;- read.csv(&#39;data/csection_delay.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(&#39;POSIXct&#39;, &#39;Date&#39;, &#39;integer&#39;)) csect &lt;- csect[order(csect$datetime), ] # show the first 6 rows head(csect) ## datetime month delay ## 1 2016-01-06 03:55:40 2016-01-01 22 ## 2 2016-01-06 20:52:34 2016-01-01 22 ## 3 2016-01-07 02:50:43 2016-01-01 29 ## 4 2016-01-07 22:32:27 2016-01-01 28 ## 5 2016-01-09 14:56:09 2016-01-01 22 ## 6 2016-01-09 21:21:24 2016-01-01 20 6.4.1 I chart (aka X chart) The “I” in I chart stand for “individuals” because it plots individual values from subgroups of size 1. I charts are also often referred to as X charts. I charts are useful when measurements come from individual units, for example waiting times or blood pressure measurements for individual patients. As we will see later, I charts are in fact useful for all kinds of data because they base their estimations on the actual variation that is present in data rather than theoretical parameters from assumed distributions. For this reason, the I chart is considered the Swiss army knife of SPC. When subgroups consist of single values we use the average absolute difference between neighbouring data points, the average moving range (\\(\\overline{MR}\\)), as an estimate of the within subgroup variation. By dividing this value with 1.128 we get an estimate of the process standard deviation. Alternatively, we may multiply \\(\\overline{MR}\\) by 3 / 1.128 = 2.66 to get 3 \\(SD\\)s. Let’s have a look at individual delay times for the latest 60 C-sections (Figure 6.5). with(tail(csect, 60), { xbar &lt;- mean(delay) # mean value, centre line mr &lt;- abs(diff(delay)) # moving ranges amr &lt;- mean(mr) # average moving range s &lt;- amr / 1.128 # process standard deviation spc(delay, cl = xbar, lcl = xbar - 3 * s, ucl = xbar + 3 * s) }) Figure 6.5: I-chart On average, the delay time for these cases is 24 minutes. Three data points are outside the control limits (#1, #4 and #31) suggesting that these cases were special and that it might be useful to have a closer look to find out what went well with case #1 and not so well with cases #4 and #31. 6.4.2 MR chart The MR chart plots the moving ranges of individual values. It is a companion to the I chart. Since moving ranges can always be zero but never negative, the MR chart has no lower control limit. with(tail(csect, 60), { mr &lt;- c(NA, abs(diff(delay))) # add NA in front to match the length of the I-chart amr &lt;- mean(mr, na.rm = TRUE) spc(mr, cl = amr, ucl = 3.267 * amr) }) Figure 6.6: MR-chart Note that there is one less moving range than individual values. To align the charts, we insert an NA value at the beginning of the MR-chart. We may plot the two charts together (Figure 6.7): with(tail(csect, 60), { xbar &lt;- mean(delay) mr &lt;- c(NA, abs(diff(delay))) amr &lt;- mean(mr, na.rm = TRUE) op &lt;- par(mfrow = c(2, 1), # setting up plotting area mar = c(5, 5, 2, 1)) spc(delay, cl = xbar, lcl = xbar - 2.66 * amr, ucl = xbar + 2.66 * amr, main = &#39;I-chart&#39;, ylab = &#39;Delay (minutes)&#39;, xlab = &#39;&#39;) spc(mr, cl = amr, ucl = 3.267 * amr, main = &#39;MR-chart&#39;, ylab = &#39;Moving range (minutes)&#39;, xlab = &#39;C-section #&#39;) par(op) # restoring plotting area }) Figure 6.7: I- and MR-charts The MR-chart also finds three data points outside the limits. These coincide with two of the special causes found by the I chart and support our conclusion that these deliveries were special. Note that each data point on the I chart (except the first and last ones) produces two moving ranges on the MR chart. 6.4.3 X-bar chart The X-bar chart is appropriate when the subgroups consist of samples of two or more measurements. To plot a control chart of the monthly average delays, we must first aggregate data to find the mean and the standard deviation of delay times and the number of sections per month. # aggregate data by month csect.agg &lt;- aggregate(delay ~ month, csect, function(x) c(mean = mean(x), sd = sd(x), n = length(x))) # make data into a nice data frame csect.agg &lt;- do.call(data.frame, csect.agg) # print the first 6 rows head(csect.agg) ## month delay.mean delay.sd delay.n ## 1 2016-01-01 23.85714 3.387653 7 ## 2 2016-02-01 24.45455 6.137811 11 ## 3 2016-03-01 22.45455 6.638729 11 ## 4 2016-04-01 22.66667 3.041381 9 ## 5 2016-05-01 22.50000 3.891382 8 ## 6 2016-06-01 22.00000 6.204837 5 Next, we calculate the centre line and the control limits using the formula in Table 6.1 where \\(\\bar{\\bar{x}}\\) (pronounced x bar bar) is the weighted mean of the subgroup means, \\(\\bar{s}\\) (s bar) is the weighted mean of the subgroup standard deviations, and \\(A_3\\) is a constant that depends on the subgroup size. See the section on chart constants at the end of this chapter for the R code involved in calculating \\(A_3\\) and other constants for control chart construction. With the aggregated data we are now able to construct the X-bar chart (Figure 6.8). with(csect.agg, { xbarbar &lt;- weighted.mean(delay.mean, delay.n) # centre line sbar &lt;- weighted.mean(delay.sd, delay.n) # process standard deviation a3 &lt;- a3(delay.n) # A3 constant spc(x = month, y = delay.mean, cl = xbarbar, lcl = xbarbar - a3 * sbar, ucl = xbarbar + a3 * sbar) }) Figure 6.8: X bar chart Figure 6.8 shows the average delay time per month. On average the delay time is 23 minutes (= centre line) and all data points fall between the control limits suggesting that the process is stable and predictable. As with U and P charts the control limits vary from month to month reflecting the varying subgroup sizes – small subgroups \\(\\rightarrow\\) wide limits; large subgroups \\(\\rightarrow\\) narrow limits. Be careful not to fall for the temptation to conclude that just because no months are above the target of 30 minutes all is well. The 30-minute target applies to the delay time of individual sections, not the averages. Even if the averages are well below the target, individuals may be above, which we already noticed from the I chart above. 6.4.4 S chart The S chart is usually plotted alongside the X-bar chart and shows the within subgroup variation. It is useful for detecting changes in the spread of data over time. To calculate the centre and control limits for the S chart we need to know the process standard deviation, \\(\\bar{S}\\) (same as for the X-bar chart), and the two constants \\(B_3\\) and \\(B_4\\) From Table 6.1. with(csect.agg, { sbar &lt;- weighted.mean(delay.sd, delay.n) # pooled SD, centre line b3 &lt;- b3(delay.n) # B3 constant b4 &lt;- b4(delay.n) # B4 constant spc(x = month, y = delay.sd, cl = sbar, lcl = b3 * sbar, ucl = b4 * sbar) }) Figure 6.9: S chart Figure 6.9 shows the average standard deviation of delay times per month. On average the standard deviation is 4.7 minutes and all data points fall between the control limits. We may plot the X-bar and S charts together (Figure 6.10): with(csect.agg, { xbarbar &lt;- weighted.mean(delay.mean, delay.n) # pooled average sbar &lt;- weighted.mean(delay.sd, delay.n) # pooled standard deviation a3 &lt;- a3(delay.n) # A3 constant b3 &lt;- b3(delay.n) # B3 constant b4 &lt;- b4(delay.n) # B4 constant op &lt;- par(mfrow = c(2, 1), mar = c(3, 5, 2, 1)) spc(month, delay.mean, cl = xbarbar, lcl = xbarbar - a3 * sbar, ucl = xbarbar + a3 * sbar, main = &#39;X-bar Chart&#39;, xlab = &#39;&#39;) spc(month, delay.sd, cl = sbar, lcl = b3 * sbar, ucl = b4 * sbar, main = &#39;S chart&#39;, xlab = &#39;&#39;) par(op) }) Figure 6.10: X-bar and S charts 6.5 Control limits in short Control limits attempt to estimate the boundaries of the natural common cause process variation. They are placed 3 standard deviations above and below the centre line, which is the (weighted) mean of the subgroup means. The procedure for calculating control limits depends on the type of data involved, but the interpretation of charts are the same regardless of data type. In the next chapter we will improve our plots by adding visual clues to highlight signs of non-random variation. Control chart constants a3 &lt;- function(n) { 3 / (c4(n) * sqrt(n)) } b3 &lt;- function(n) { pmax(0, 1 - 3 * c5(n) / c4(n)) } b4 &lt;- function(n) { 1 + 3 * c5(n) / c4(n) } c4 &lt;- function(n) { n[n &lt;= 1] &lt;- NA sqrt(2 / (n - 1)) * exp(lgamma(n / 2) - lgamma((n - 1) / 2)) } c5 &lt;- function(n) { sqrt(1 - c4(n)^2) } "],["highlighting.html", "Chapter 7 Highlighting Freaks, Shifts, and Trends 7.1 Introducing the cdiff data set 7.2 Improved spc() function 7.3 Highlighting special cause variation in short R function for runs analysis", " Chapter 7 Highlighting Freaks, Shifts, and Trends In the previous chapter we calculated control limits for commonly used control charts. Control limits show the boundaries of the natural common cause process variation. Thus, data points outside the control limits (freaks) are signals of special cause variation in data – that is unexpected change caused by something outside the usual system. Control limits are designed to signal rather large (&gt; 2SD), possibly transient, changes in the system. However, as discussed in detail in Chapter 3, minor to moderate changes in the form of shifts or trends in data may go unnoticed by the control limits for long periods of time. For this purpose, many supplementary tests (rules) have been suggested. To balance the need to quickly detect special causes while keeping the false alarm rate as low as possible we recommend using the 3-sigma rule to signal freaks and the two runs rules for unusually long runs and unusually few crossings to signal shifts and trends. In this chapter we will improve the spc() function to automatically visualise special cause variation in the form of freaks, shifts, and trends. 7.1 Introducing the cdiff data set The cdiff data set contains 24 observations of monthly numbers of hospital acquired Clostridioides difficile infections from an acute care hospital. # read data from file cdiff &lt;- read.csv(&#39;data/cdiff.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(&#39;Date&#39;, &#39;integer&#39;, &#39;integer&#39;)) # calculate centre line and control limits cdiff &lt;- within(cdiff, { cl &lt;- mean(infections) lcl &lt;- pmax(0, cl - 3 * sqrt(cl)) # censor lcl at zero ucl &lt;- cl + 3 * sqrt(cl) }) # print the first six rows of data head(cdiff) ## month infections risk_days ucl lcl cl ## 1 2020-01-01 12 19801 11.77776 0 5.041667 ## 2 2020-02-01 7 18674 11.77776 0 5.041667 ## 3 2020-03-01 1 15077 11.77776 0 5.041667 ## 4 2020-04-01 4 12062 11.77776 0 5.041667 ## 5 2020-05-01 4 14005 11.77776 0 5.041667 ## 6 2020-06-01 5 14840 11.77776 0 5.041667 Figure 7.1 shows data plotted with spc() function. We see that there is one data point (#1) above the upper control limit. If we look carefully we also find an unusually long run of 11 data points below the centre line (#14-#24) and that the curve crosses the centre line only 7 times. Thus, in addition to the freak, there is also a shift in data, which is not large enough to break the limits but sustained enough to trigger the runs rules. with(cdiff, { spc(month, infections, cl, lcl, ucl) }) Figure 7.1: C control chart of CDiff infections To help us signal special cause variation we will improve the spc() function. 7.2 Improved spc() function The new, improved spc() function has a few changes: Line 10: Import a function, runs.analysis(), from a separate R script to test for unusually long runs and unusually few crossings. See this function in the R function for runs analysis section at the end of this chapter. Lines 19-20: If no cl argument is given, use the median for centre line. Lines 33-34: Create a logical vector identifying data points that lie outside the control limits. Line 37: Test for unusually long runs and unusually few crossings. Line 40: Start with an empty plot. Line 47-49: Format the centre line according to the result of runs analysis. Lines 56-49: Add the data line and points and colour data points outside control limits. spc &lt;- function( x, # x axis values y = NULL, # data values cl = NULL, # centre line lcl = NA, # lower control limit ucl = NA, # upper control limit ... # other parameters passed to the plot() function ) { # load runs analysis function from R script source(&#39;R/runs.analysis.R&#39;) # if y is missing, set y to x and make a sequence for x if (is.null(y)) { y &lt;- x x &lt;- seq_along(y) } # if cl is missing use median of y if (is.null(cl)) cl &lt;- median(y, na.rm = TRUE) # repeat line values to match the length of y if (length(cl) == 1) cl &lt;- rep(cl, length(y)) if (length(lcl) == 1) lcl &lt;- rep(lcl, length(y)) if (length(ucl) == 1) ucl &lt;- rep(ucl, length(y)) # find data points outside control limits (freaks) sigma.signal &lt;- y &lt; lcl | y &gt; ucl sigma.signal[is.na(sigma.signal)] &lt;- FALSE # check for sustained shifts and trends using runs analysis runs.signal &lt;- runs.analysis(y, cl) # make empty plot plot(x, y, type = &#39;n&#39;, ylim = range(y, cl, lcl, ucl, na.rm = TRUE), ...) # add centre line, coloured and dashed if shifts or trends were identified by # the runs analysis lines(x, cl, col = runs.signal + 1, lty = runs.signal + 1) # add control limits lines(x, lcl) lines(x, ucl) # add data line and points, colour freak data points (outside control limits) lines(x, y) points(x, y, pch = 19, col = sigma.signal + 1) } with(cdiff, { spc(month, infections, cl, lcl, ucl) }) Figure 7.2: Improved control chart with visual clues to highlight special cause variation Now it is a lot easier to immediately see if a chart contains special cause variation or not (Figure 7.2). Freak data points are red, and the centre line turns red and dashed if there are any unusually long runs or if the curve crossed the centre line unusually few times. Remember, the chart itself does not tell us what caused the signals. This interpretation of a chart – common or special cause variation – still relies on humans with a deep understanding the process and the data. 7.3 Highlighting special cause variation in short In this chapter we have improved the spc() function to automatically highlight signs of special cause variation using visual clues that help us quickly decide if a process is stable or not. In the next chapter we will improve the spc() function further to automatically aggregate data and calculate control limits. R function for runs analysis runs.analysis &lt;- function(y, cl) { # trichotomise data according to position relative to CL # -1 = below, 0 = on, 1 = above runs &lt;- sign(y - cl) # remove NAs and data points on the CL runs &lt;- runs[runs != 0 &amp; !is.na(runs)] # find run lengths run.lengths &lt;- rle(runs)$lengths # find number of useful observations (data points not on CL) n.useful &lt;- sum(run.lengths) # find longest run above or below CL longest.run &lt;- max(run.lengths) # find number of times adjacent data points are on opposite sides of CL n.crossings &lt;- length(run.lengths) - 1 # find upper limit for longest run longest.run.max &lt;- round(log2(n.useful)) + 3 # find lower limit for number of crossing n.crossings.min &lt;- qbinom(0.05, n.useful - 1, 0.5) # return result, TRUE if either of the two tests is true, otherwise FALSE longest.run &gt; longest.run.max | n.crossings &lt; n.crossings.min } "],["r-functions.html", "Chapter 8 Core R Functions to Construct SPC Charts 8.1 Examples 8.2 TODO 8.3 Further up, further in R function library", " Chapter 8 Core R Functions to Construct SPC Charts Until now, we have calculated control limits manually before plotting. In this chapter we will introduce a library of functions that work together to automate all the steps involved in constructing SPC charts. We will not go through each of these functions in detail, but we encourage you to study them to get a good grasp of how they work and work together. And we encourage you to improve and adapt them to your own needs. In total there are 17 functions that work together to construct SPC charts. But the user only needs to interact with one of them, spc(). See the R functions library section at the end of this chapter for the source code. The main function, spc() is an improved version of the improved spc() function from Chapter 7. Most importantly, it is no longer necessary to calculate the limits manually. Instead, we provide a chart argument, which should be one of the following: ‘run’, ‘xbar’, ‘s’, ‘i’, ‘mr’, ‘c’, ‘u’, ‘p’. If no chart argument is provided, a run chart will be drawn. Also, we no longer have to use the clumsy $-notation or with() function to access variables inside a data frame. Instead, we may pass the name of the data frame to the data argument. Finally, we do not need to aggregate data for X-bar and S charts in advance. That job is delegated to the spc.aggregate() function, which is also responsible for calling the appropriate functions to calculate the centre line and control limits and perform the runs analysis. After doing its job, spc.aggregate() returns a data frame with all the necessary information needed to construct a plot. This, in turn, is handled by the plot.spc() function. 8.1 Examples Here are examples of a run chart and each of the Magnificent Seven. See Appendix A for documentation of the data sets used in the examples. 8.1.1 Run chart d &lt;- read.csv(&#39;data/blood_pressure.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(date = &#39;Date&#39;)) head(d) ## date systolic diastolic pulse ## 1 2012-06-13 125 77 56 ## 2 2012-06-14 118 76 59 ## 3 2012-06-15 125 75 59 ## 4 2012-06-16 126 73 69 ## 5 2012-06-17 124 77 70 ## 6 2012-06-18 127 83 63 spc(date, systolic, data = d, main = &#39;Systolic blood pressure&#39;, ylab = &#39;mm Hg&#39;, xlab = &#39;Date&#39;) Figure 8.1: Run chart 8.1.2 I and MR charts for individual measurements # Setup plotting area to hold two plots on top of each other and adjust margins op &lt;- par(mfrow = c(2, 1), mar = c(4, 4, 2, 0) + 0.2) spc(date, systolic, data = d, chart = &#39;i&#39;, main = &#39;Systolic blood pressure&#39;, ylab = &#39;mm Hg&#39;, xlab = NA) spc(date, systolic, data = d, chart = &#39;mr&#39;, main = &#39;Moving range&#39;, ylab = &#39;mm Hg&#39;, xlab = &#39;Date&#39;) Figure 8.2: I and MR charts # Reset plotting area to default par(op) 8.1.3 X-bar and S charts for averages and standard deviations of measurements d &lt;- read.csv(&#39;data/renography_doses.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(date = &#39;Date&#39;, week = &#39;Date&#39;)) head(d) ## date week dose ## 1 2014-01-06 2014-01-06 51 ## 2 2014-01-06 2014-01-06 48 ## 3 2014-01-06 2014-01-06 75 ## 4 2014-01-06 2014-01-06 53 ## 5 2014-01-06 2014-01-06 71 ## 6 2014-01-06 2014-01-06 84 op &lt;- par(mfrow = c(2, 1), mar = c(4, 4, 2, 0) + 0.2) spc(week, dose, data = d, chart = &#39;xbar&#39;, main = &#39;Average radiation dose for renography&#39;, ylab = &#39;MBq&#39;, xlab = NA) spc(week, dose, data = d, chart = &#39;s&#39;, main = &#39;Standard deviation&#39;, ylab = &#39;MBq&#39;, xlab = &#39;Week&#39;) Figure 8.3: X-bar and S charts par(op) 8.1.4 C and U charts for counts and rates d &lt;- read.csv(&#39;data/bacteremia.csv&#39;, comment.char = &#39;#&#39;, colClasses = c(month = &#39;Date&#39;)) head(d) ## month ha_infections risk_days deaths patients ## 1 2017-01-01 24 32421 23 100 ## 2 2017-02-01 29 29349 22 105 ## 3 2017-03-01 26 32981 13 99 ## 4 2017-04-01 16 29588 14 85 ## 5 2017-05-01 28 30856 17 98 ## 6 2017-06-01 16 30544 15 85 op &lt;- par(mfrow = c(2, 1), mar = c(4, 4, 2, 0) + 0.2) spc(month, ha_infections, data = d, chart = &#39;c&#39;, main = &#39;Hospital acquired bacteremia&#39;, ylab = &#39;Count&#39;, xlab = NA) spc(month, ha_infections, risk_days, data = d, chart = &#39;u&#39;, multiply = 10000, main = NA, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 8.4: C and U charts par(op) 8.1.5 P chart for percentages spc(month, deaths, patients, data = d, multiply = 100, chart = &#39;p&#39;, main = &#39;30-day mortality after bacteremia&#39;, ylab = &#39;%&#39;, xlab = &#39;Month&#39;) Figure 8.5: P chart 8.2 TODO One obvious shortcoming of this function library is that the functions lack error checking. So if you are going to use them in a production environment or for your own SPC package you will need to build that yourself. At the least, you need to automatically check that inputs are of the expected types and that the x, y, and n arguments have the same lengths. TIP: check the stopifnot() function. 8.3 Further up, further in We now have a functioning library of R functions that automate most of the steps involved in the construction of SPC charts. There is still plenty of room for improvement. But this should get you started and – most importantly – give you a deeper understanding of the considerations involved in plotting SPC charts. In the next chapter we will take a quick look at how to use ggplot2() for plotting rather than the plot() function from base R. R function library # Master SPC function ########################################################## # # Constructs an SPC chart. # # Invisibly returns a data frame of class &#39;spc&#39;. # # x: Numeric or date(time) vector of subgroup values to plot along the x # axis. Or, if y is NULL, x values will be used for y coordinates. # y: Numeric vector of measures or counts to # plot on the y axis (numerator). # n: Numeric vector of subgroup sizes (denominator). # data: Data frame containing the variables used in the plot. # multiply: Number to multiply y axis by, e.g. 100 to get percentages rather # than proportions. # chart: Character value indicating the chart type. Possible values are: # &#39;run&#39; (default), &#39;xbar&#39;, &#39;s&#39;, &#39;i&#39;, &#39;mr&#39;, &#39;c&#39;, &#39;u&#39;, and &#39;p&#39;. # plot: Logical, if TRUE (default), plots an SPC chart. # print: Logical, if TRUE, prints a data frame with coordinates. # ...: Other arguments to the plot() function, e.g. main, ylab, xlab. # spc &lt;- function(x, y = NULL, n = 1, data = NULL, multiply = 1, chart = c(&#39;run&#39;, &#39;xbar&#39;, &#39;s&#39;, &#39;i&#39;, &#39;mr&#39;, &#39;c&#39;, &#39;u&#39;, &#39;p&#39;), plot = TRUE, print = FALSE, ...) { # Get data from data frame if data argument is provided, or else get data # from the parent environment. x &lt;- eval(substitute(x), data, parent.frame()) y &lt;- eval(substitute(y), data, parent.frame()) n &lt;- eval(substitute(n), data, parent.frame()) # Get chart argument. chart &lt;- match.arg(chart) # If y argument is missing, use x instead. if (is.null(y)) { y &lt;- x x &lt;- seq_along(y) } # Make sure that the n vector has same length as y. if (length(n) == 1) { n &lt;- rep(n, length(y)) } # Make sure that numerators and denominators are balanced. If one is missing, # the other should be missing too. xna &lt;- !complete.cases(data.frame(y, n)) y[xna] &lt;- NA n[xna] &lt;- NA # Aggregate data by subgroups. df &lt;- spc.aggregate(x, y, n, chart) # Multiply y coordinates if needed. df$y &lt;- df$y * multiply df$cl &lt;- df$cl * multiply df$lcl &lt;- df$lcl * multiply df$ucl &lt;- df$ucl * multiply # Make plot. if (plot) { plot.spc(df, ...) } # Print data frame. if (print) { print(df) } # Make data frame an &#39;spc&#39; object and return invisibly. class(df) &lt;- c(&#39;spc&#39;, class(df)) invisible(df) } # Aggregate function ########################################################### # # Calculates subgroup lengths, sums, means, and standard deviations. Called # from the spc() function. # # Returns a data frame of x, y, n, and centre line and control limits. # # x: Numerical, numbers or dates for the x axis. # y: Numerical, measure or count to plot. # n: Numerical, denominator (if any). # chart: Character, type of chart. # spc.aggregate &lt;- function(x, y, n, chart) { # Get function to calculate centre line and control limits. chart.fun &lt;- get(paste(&#39;spc&#39;, chart, sep = &#39;.&#39;)) # Get function to restore the x variable to its original class after # aggregation. subgrp.fun &lt;- get(paste0(&#39;as.&#39;, class(x))) # Calculate subgroup lengths, sums, means, and standard deviations. df &lt;- data.frame(y, n) df &lt;- split(df, x) df &lt;- lapply(df, function(i) { data.frame(n = sum(i$n, na.rm = TRUE), sum = sum(i$y, na.rm = TRUE), mean = sum(i$y, na.rm = TRUE) / sum(i$n, na.rm = TRUE), sd = sd(i$y, na.rm = TRUE)) }) df &lt;- do.call(rbind, df) df &lt;- data.frame(x = rownames(df), df, chart, row.names = NULL) # Replace any zero length subgroups with NA. df$n[df$n == 0] &lt;- NA # Calculate the weighted subgroup mean. df$ybar &lt;- weighted.mean(df$mean, df$n, na.rm = TRUE) # Restore x variable to its original class. df$x &lt;- subgrp.fun(df$x) # Calculate centre line and control limits. df &lt;- chart.fun(df) # Add runs analysis if (chart == &#39;mr&#39;) { df$runs.signal &lt;- FALSE } else { df$runs.signal &lt;- runs.analysis(df$y, df$cl) } # Find data points outside control limits. df$sigma.signal &lt;- (df$y &lt; df$lcl | df$y &gt; df$ucl) df$sigma.signal[is.na(df$sigma.signal)] &lt;- FALSE # Return data frame. df[c(&#39;x&#39;, &#39;y&#39;, &#39;n&#39;, &#39;lcl&#39;, &#39;cl&#39;, &#39;ucl&#39;, &#39;sigma.signal&#39;, &#39;runs.signal&#39;, &#39;chart&#39;)] } # Plot function ################################################################ # # Draws an SPC chart from data provided by the spc() function. Is usually # called from the spc() function, but may be used as stand-alone for plotting # data frames of class spc created by the spc() function. # # Invisibly returns the data frame # # x: Data frame produced by the spc() function. # ...: Additional arguments for the plot() function, e.g. title and labels. # plot.spc &lt;- function(x, ...) { col1 &lt;- &#39;steelblue&#39; col2 &lt;- &#39;grey30&#39; col3 &lt;- &#39;tomato&#39; # Make room for data and control limits on the x axis. ylim &lt;- range(x$y, x$lcl, x$ucl, na.rm = TRUE) # Draw empty plot. plot(x$x, x$y, type = &#39;n&#39;, bty = &#39;l&#39;, las = 1, ylim = ylim, font.main = 1, ...) # Add lines and points to plot. lines(x$x, x$cl, col = ifelse(x$runs.signal, col3, col2), lty = ifelse(x$runs.signal, &#39;dashed&#39;, &#39;solid&#39;)) lines(x$x, x$lcl, col = col2) lines(x$x, x$ucl, col = col2) lines(x$x, x$y, col = col1, lwd = 2.5) points(x$x, x$y, pch = 19, cex = 0.8, col = ifelse(x$sigma.signal, col3, col1) ) invisible(x) } # Runs analysis function ####################################################### # # Tests time series data for non-random variation in the form of # unusually long runs or unusually few crossings. Called from the # spc.aggregate() function. # # Returns a logical, TRUE if non-random variation is present. # # x: Numeric vector. # cl: Numeric vector of length either one or same length as y. # runs.analysis &lt;- function(y, cl) { # Trichotomise data according to position relative to CL: # -1 = below, 0 = on, 1 = above. runs &lt;- sign(y - cl) # Remove NAs and data points on the centre line. runs &lt;- runs[runs != 0 &amp; !is.na(runs)] # Find run lengths. run.lengths &lt;- rle(runs)$lengths # Find number of useful observations (data points not on centre line). n.useful &lt;- sum(run.lengths) # Find longest run above or below centre line. longest.run &lt;- max(run.lengths) # Find number of crossings. n.crossings &lt;- length(run.lengths) - 1 # Find upper limit for longest run. longest.run.max &lt;- round(log2(n.useful)) + 3 # Find lower limit for number of crossing. n.crossings.min &lt;- qbinom(0.05, n.useful - 1, 0.5) # Return result. longest.run &gt; longest.run.max | n.crossings &lt; n.crossings.min } # Limits functions ############################################################# # # These functions calculate coordinates for the centre line and control limits # of SPC charts. They are not meant to be called directly but are used by the # spc.aggregate() function. # # Return data frames with coordinates for centre line and control limits. # # x: A data frame containing the values to plot. # spc.run &lt;- function(x) { x$y &lt;- x$mean x$cl &lt;- median(x$y, na.rm = TRUE) x$lcl &lt;- NA_real_ x$ucl &lt;- NA_real_ x } spc.i &lt;- function(x) { x$y &lt;- x$mean xbar &lt;- x$ybar amr &lt;- mean(abs(diff(x$y)), na.rm = T) sss &lt;- 2.66 * amr x$cl &lt;- xbar x$lcl &lt;- xbar - sss x$ucl &lt;- xbar + sss x } spc.mr &lt;- function(x) { x$y &lt;- c(NA, abs(diff(x$mean))) amr &lt;- mean(x$y, na.rm = TRUE) x$cl &lt;- amr x$lcl &lt;- NA_real_ x$ucl &lt;- 3.267 * amr x } spc.xbar &lt;- function(x) { x$y &lt;- x$mean a3 &lt;- a3(x$n) xbarbar &lt;- weighted.mean(x$mean, x$n, na.rm = TRUE) sbar &lt;- weighted.mean(x$sd, x$n, na.rm = TRUE) sss &lt;- a3 * sbar x$cl &lt;- xbarbar x$lcl &lt;- xbarbar - sss x$ucl &lt;- xbarbar + sss x } spc.s &lt;- function(x) { x$y &lt;- x$sd sbar &lt;- weighted.mean(x$sd, x$n, na.rm = TRUE) b3 &lt;- b3(x$n) b4 &lt;- b4(x$n) x$cl &lt;- sbar x$lcl &lt;- b3 * sbar x$ucl &lt;- b4 * sbar x } spc.c &lt;- function(x) { x$y &lt;- x$sum cbar &lt;- mean(x$y, na.rm = TRUE) sss &lt;- 3 * sqrt((cbar)) x$cl &lt;- cbar x$lcl &lt;- pmax(0, cbar - sss) x$ucl &lt;- cbar + sss x } spc.u &lt;- function(x) { x$y &lt;- x$mean ubar &lt;- x$ybar sss &lt;- 3 * sqrt((ubar / x$n)) x$cl &lt;- ubar x$lcl &lt;- pmax(0, ubar - sss, na.rm = TRUE) x$ucl &lt;- ubar + sss x } spc.p &lt;- function(x) { x$y &lt;- x$mean pbar &lt;- x$ybar sss &lt;- 3 * sqrt((pbar * (1 - pbar)) / x$n) x$cl &lt;- pbar x$lcl &lt;- pmax(0, pbar - sss) x$ucl &lt;- pmin(1, pbar + sss) x } # Constants functions ########################################################## # # These functions calculate the constants that are used for calculating the # parameters of X-bar and S charts. Called from the spc.xbar() and spc.s() # functions # # Return a number, the constant for that subgroup size # # n: Number of elements in subgroup # a3 &lt;- function(n) { 3 / (c4(n) * sqrt(n)) } b3 &lt;- function(n) { pmax(0, 1 - 3 * c5(n) / c4(n), na.rm = TRUE) } b4 &lt;- function(n) { 1 + 3 * c5(n) / c4(n) } c4 &lt;- function(n) { n[n &lt;= 1] &lt;- NA sqrt(2 / (n - 1)) * exp(lgamma(n / 2) - lgamma((n - 1) / 2)) } c5 &lt;- function(n) { sqrt(1 - c4(n) ^ 2) } "],["ggplot.html", "Chapter 9 SPC Charts with ggplot2 9.1 Creating an SPC object for later plotting 9.2 Making a new plot function based on ggplot2 9.3 Customising the plotting theme 9.4 Preparing for qicharts2", " Chapter 9 SPC Charts with ggplot2 Armed with the battery of functions from Chapter 8 we are able to construct any of the most commonly used SPC charts using functionality from base R. Furthermore, it is easy to add new types of SPC charts to the library. To achieve this, all we have to do is to write an appropriate spc.*() function to handle the calculations of the centre line and limits and to include the function type in thespc() function’s chart argument. Because we have used a modularised approach and made a separate function for plotting spc objects, plot.spc(), it is also a simple task to use any plotting engine other than base R graphics. In this chapter we will build an alternative plot function, which uses ggplot2 as its plotting engine. ggplot2 has some advantages over plotting with base R function. Not because ggplot2 is able to do things that cannot be done with base R, but because it makes some operations a lot easier. For example, with ggplot2 we do not need to worry about scaling the axes to accommodate data that are added to the plot or to make room for axis labels and tick marks. These are all handled gracefully by ggplot2 itself. Also ggplot2 has an extensive theming engine that makes it (relatively) easy to customise the non-data parts of a plot, for example colours, legends, and number formats. 9.1 Creating an SPC object for later plotting With the spc() function we created in the previous chapter we will create an spc object and assign it to a variable, p, for later use: # make spc object p &lt;- spc(month, infections, data = cdiff, chart = &#39;c&#39;, plot = FALSE) Notice that we suppressed the plotting and assigned the (invisible) output, which is a data frame containing the coordinates to plot, to the variable p. We can now continue working with p as with any other R object. # check the class of p class(p) ## [1] &quot;spc&quot; &quot;data.frame&quot; # show the first six rows from p head(p) ## x y n lcl cl ucl sigma.signal runs.signal chart ## 1 2020-01-01 12 1 0 5.041667 11.77776 TRUE TRUE c ## 2 2020-02-01 7 1 0 5.041667 11.77776 FALSE TRUE c ## 3 2020-03-01 1 1 0 5.041667 11.77776 FALSE TRUE c ## 4 2020-04-01 4 1 0 5.041667 11.77776 FALSE TRUE c ## 5 2020-05-01 4 1 0 5.041667 11.77776 FALSE TRUE c ## 6 2020-06-01 5 1 0 5.041667 11.77776 FALSE TRUE c # show the C chart plot(p) # not necessary to call spc.plot(), just call the generic plot() function Figure 9.1: SPC chart Because p is an object of class “spc” we only need to call the generic plot() function, which in turn will pass its first argument to the specialised spc.plot() function. 9.2 Making a new plot function based on ggplot2 We may now create any number of alternative plotting functions for spc objects. In this example we will create a plotting function that uses ggplot2. # Load ggplot2 library(ggplot2) # Function for plotting spc objects with ggplot() ggspc &lt;- function(p) { # Set colours col1 &lt;- &#39;steelblue&#39; col2 &lt;- &#39;tomato&#39; linecol &lt;- &#39;gray50&#39; dotcol &lt;- ifelse(p$sigma.signal, col2, col1) clcol &lt;- ifelse(p$runs.signal[1], col2, linecol) cltyp &lt;- ifelse(p$runs.signal[1], &#39;dashed&#39;, &#39;solid&#39;) # Plot the dots and draw the lines ggplot(p, aes(x, y)) + geom_line(aes(y = lcl), colour = linecol, na.rm = TRUE) + geom_line(aes(y = ucl), colour = linecol, na.rm = TRUE) + geom_line(aes(y = cl), colour = clcol, linetype = cltyp, na.rm = TRUE) + geom_line(colour = col1, na.rm = TRUE) + geom_point(colour = dotcol, na.rm = TRUE) } # Plot an spc object ggspc(p) Figure 9.2: SPC chart using the ggspc() function We may also turn the spc object into a ggplot2 object: # make the spc object into a ggplot2 object p &lt;- ggspc(p) class(p) ## [1] &quot;gg&quot; &quot;ggplot&quot; # plot with modified theme and custom labels p + theme_light() + theme(panel.grid = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = &#39;gray&#39;)) + labs(title = &#39;CDiff infections&#39;, y = &#39;Count&#39;, x = &#39;Month&#39;) Figure 9.3: SPC chart with modified theme Now, if we wished, we could replace the plot.spc() function with this new function. We will leave it to you to decide which of the two you like best. 9.3 Customising the plotting theme The last example in this chapter demonstrates how to create our own custom theme and how to format y axis tick marks as percentages: mytheme &lt;- function() { theme_light() + theme(panel.grid = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = &#39;gray&#39;)) } p &lt;- spc(month, deaths, patients, data = bact, chart = &#39;p&#39;, plot = FALSE) ggspc(p) + mytheme() + scale_y_continuous(labels = scales::label_percent()) + labs(title = &#39;30-day mortality&#39;, y = NULL, x = &#39;Month&#39;) Figure 9.4: SPC chart with labels and custom y-axis In the long run, though, we might get tired of manually designing our own theme, modifying the plot function, and formatting tick mark labels for every plot. Wouldn’t it be nice to have this done automatically for us? This is exactly what qicharts2 does. 9.4 Preparing for qicharts2 qicharts2 is an R package for plotting SPC charts and is the subject of the next chapter. qicharts2 builds on the same principles we have developed so far but has a lot more facilities for customising charts. Most importantly, qicharts2 makes it easy to produce multidimensional plots using ggplot2’s faceting methods. "],["qicharts.html", "Chapter 10 Introducing qicharts2 10.1 A simple run chart 10.2 A simple control chart 10.3 Excluding data points from analysis 10.4 Freezing baseline period 10.5 Splitting chart by period 10.6 Small multiple plots for multivariate data 10.7 qicharts2 in short", " Chapter 10 Introducing qicharts2 qicharts2 (Quality Improvement Charts, Anhøj (2024), Anhøj (2018)) is an R package for SPC aimed at healthcare data analysts. It is based on the same principles that we have developed in the previous chapters of this book. It contains functions to construct run charts and all of the Magnificent Seven plus a number of specialised charts including pareto charts and control charts for rare events data. To learn everything about qicharts2, visit its website: https://anhoej.github.io/qicharts2/. In this chapter we will concentrate on some key facilities that is missing from the function library we have build so far: excluding data points from analysis freezing and splitting charts by periods multivariate plots (small multiples) To get started with qicharts2, install it and load it into your working environment: # install package install.packages(&#39;qicharts2&#39;) # load package library(qicharts2) Remember, you only need to install a package once, but you need to load it every time you want to use it. Next, you may want to read the vignette: vignette('qicharts2') – or you may want to get started right away. 10.1 A simple run chart The main function of qicharts2 is qic(). It takes the same arguments as the spc() function we built previously plus many more. Check the documentation for a complete list of arguments: ?qic. To reproduce our first run chart from Chapter 5, run: qic(systolic) Figure 10.1: Run chart produced with the qic() function from the qicharts2 package There are several things to note in Figure 10.1: Default chart title and axis labels are created automatically. These can be changed using the title, ylab, and xlab arguments. Data points that fall directly on the centre line are greyed out. These do not count as useful observation in the runs analysis. The centre line value is printed on the chart. 10.2 A simple control chart To produce a control chart, we simply add a chart argument (Figure 10.2): qic(systolic, chart = &#39;i&#39;) Figure 10.2: I chart produced with qic() By default qic() uses a grey background area to show the natural process limits. 10.3 Excluding data points from analysis Sometimes it is useful to exclude one or more data points from the calculation of control limits and from the runs analysis. This may be the case when specific data points are known to have been influenced by factors that are not part of the natural process, for example data points that fall outside the control limits. We use the exclude argument to do this: qic(systolic, chart = &#39;i&#39;, exclude = 6) Figure 10.3: I chart with one data point excluded from calculations Notice how the values for the centre line and control limits in Figure 10.3 changed a little. Specifically, the control limits became slightly narrower. Excluding data points should be a deliberate decision and not something that is done automatically just because one or more data points are outside the control limits. Exclusion should be based on a thorough understanding of the process and only when the reason(s) for a special cause has been established. Otherwise, the whole idea of SPC as a way of understanding variation and its sources is lost. 10.4 Freezing baseline period When data have been collected for a long enough period of time to establish the centre line and control limits of a stable and predictable process – that is, a process with only common cause variation – it is often useful to “freeze” the limits and use them for future data. In production industry this technique is referred to as phase one and phase two studies. In healthcare freezing is especially useful when we have historical data from before the start of some type of intervention or improvement programme. When plotting future data with the centre line and control limits from a stable baseline period shifts and trends will show up faster than if the limits were recalculated with every new data point. The cdi dataset comes with qicharts2 and contains monthly counts of infections two years before and one year after the initiation of an improvement programme. Check the documentation for details, ?cdi. qic(month, n, data = cdi, freeze = 24) Figure 10.4: Infections before and after intervention Figure 10.4 shows a run chart of data where the centre line has been established from the baseline period (month 1-24) using the freeze argument. After the intervention, marked by the dotted vertical line, there is a sustained shift in data in the desired direction. 10.5 Splitting chart by period When a sustained shift in data has been discovered and the cause is known it is allowable to split the graph by periods. We use the part argument for this (Figure 10.5). qic(month, n, data = cdi, part = 24) Figure 10.5: Splitting using index The part argument takes either the indices of the data points to split after, or a categorical variable naming the time periods in which case the periods will be labelled (Figure 10.6). qic(month, n, data = cdi, part = period) Figure 10.6: Splitting using a period variable As with excluding data points, splitting should be based on deliberate decisions and thorough understanding of the process. Some SPC applications allow for automatic splitting whenever a shift is detected. We strongly advise against this approach. Splitting may be useful when: there is a sustained shift in data the reason for the shift is known the shift is in the desired direction the shift is expected to continue If any of these conditions is not met we should rather look for the root cause and – if need be – eliminate it. Because we now have data from two very different but stable processes we may choose to add control limits to better detect future changes, especially freaks, in process behaviour (Figure 10.7). qic(month, n, data = cdi, part = period, chart = &#39;c&#39;) Figure 10.7: Splitting using a period variable 10.6 Small multiple plots for multivariate data Process data is all about time. But often data – not the least in healthcare – have more dimensions, which are important to understand in order to interpret data correctly. For example, the hospital_infections dataset, which is also included in the qicharts2 package, contains monthly counts of three types of hospital infections: bacteremia (BAC), C. diff. (CDI), and urinary tract infections (UTI) from six hospitals: AHH, BFH, BOH, HGH, NOH, RGH. # show the first six rows of the hospitals_infections dataset head(hospital_infections) ## hospital infection month n days ## 1 AHH BAC 2015-01-01 17 17233.67 ## 2 AHH BAC 2015-02-01 18 15308.25 ## 3 AHH BAC 2015-03-01 17 16883.67 ## 4 AHH BAC 2015-04-01 10 15463.83 ## 5 AHH BAC 2015-05-01 13 15788.96 ## 6 AHH BAC 2015-06-01 14 15660.04 In addition to the time dimension, these data have two extra dimensions, infection and hospital. Figure 10.8 shows the total (aggregated) monthly counts of hospital associated urinary tract infections from six hospitals. qic(month, n, days, data = subset(hospital_infections, infection == &#39;UTI&#39;), chart = &#39;u&#39;, multiply = 10000, title = &#39;Urinary tract infections&#39;, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 10.8: Aggregated U chart of urinary tract infections from six hospital Figure 10.9 shows the same data as Figure 10.8, but this time data have been stratified into so-called small multiple plots – one plot per hospital. qic(month, n, days, data = subset(hospital_infections, infection == &#39;UTI&#39;), chart = &#39;u&#39;, multiply = 10000, facets = ~hospital, # stratify by hospital ncol = 2, # two-column arrangement of plots title = &#39;Urinary tract infections&#39;, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 10.9: Stratified (small multiple) U charts of urinary tract infections from six hospital In the litterature, small multiples are also known as trellis, lattice, or grid plots. Likewise, we may construct a small multiple plot of different infection types from one hospital (Figure 10.10). qic(month, n, days, data = subset(hospital_infections, hospital == &#39;NOH&#39;), chart = &#39;u&#39;, multiply = 10000, facets = ~infection, # stratify by infection type ncol = 1, title = &#39;Hospital infections&#39;, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 10.10: U charts from one hospital stratified by infection type By default, qic() uses fixed axis scales. This makes it easy to compare both the indicator levels (y-axis) and the patterns of variation over time (x-axis) between facets. However, sometimes it makes little sense to compare levels from very different indicators as in this example where different types of infections occur at very different rates. Because urinary tract infections is much more frequent that the other two types of infection, it is hard to interpret the patterns over time from these. In Figure 10.11 we use individual y-axes. qic(month, n, days, data = subset(hospital_infections, hospital == &#39;NOH&#39;), chart = &#39;u&#39;, multiply = 10000, facets = ~infection, scales = &#39;free_y&#39;, # free y-axes ncol = 1, title = &#39;Hospital infections&#39;, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 10.11: Small multiple plot with individual y-axes The decision about when to use fixed or free axis scales should be taken deliberately depending on the purpose of the plot. Sometimes it may even be useful to display both plots with fixed and free axes side by side. Finally, we may want to display both dimensions, infection and hospital, at the same time as in Figure 10.12. qic(month, n, days, data = hospital_infections, chart = &#39;u&#39;, multiply = 10000, facets = infection ~ hospital, # two-dimensional faceting scales = &#39;free_y&#39;, title = &#39;Hospital infections&#39;, ylab = &#39;Count per 10,000 risk days&#39;, xlab = &#39;Month&#39;) Figure 10.12: Hospital infections stratified by infection and hospital 10.6.1 To aggregate or not to aggregate When data come from multiple organisational units, for example hospitals or hospital departments, we must decide if we want to aggregate or stratify data. Figures 10.8 and 10.9 demonstrate the difference. Notice how the aggregated data show no signs of special causes while the stratified data show non-random shifts in two hospitals (BOH and NOH). If data, as in this case, move in different directions in two or more units, aggregation has a tendency to mask or cancel out special causes. However, when minor shifts in data, that are too small to produce signals in the small multiple plots, move in the same direction the shifts tend to add up resulting in a better chance of detecting the special cause with aggregated data. As usual, the decision to aggregate or stratify must be taken deliberately, preferably by persons with a thorough understanding of the structures and processes that have produced data. And often it may be useful to produce several plots at different levels of aggregation. 10.7 qicharts2 in short qicharts2 is an R package for constructing SPC charts aimed specifically at healthcare but usefull in many other areas. Besides functions for the most commonly used SPC charts, qicharts2 is has a number of specialist charts for rare events data and count data with very large denominators. References ———. 2018. “qicharts2: Quality Improvement Charts for R.” JOSS. https://doi.org/10.21105/joss.0069. ———. 2024. Qicharts2: Quality Improvement Charts. https://CRAN.R-project.org/package=qicharts2. "],["data-sets.html", "A Data Sets Reading csv files Data summaries", " A Data Sets # Bacteremia # # Hospital acquired and all cause bacteremias and 30 days mortality # # Variables: # month (date): month of infection # ha_infections (numeric): number of hospital acquired infections # risk_days (numeric): number of patient days without infection # deaths (numeric): 30-day mortality after all-cause infection # patients (numeric): number of patients with all-cause infection month,ha_infections,risk_days,deaths,patients 2017-01-01,24,32421,23,100 2017-02-01,29,29349,22,105 2017-03-01,26,32981,13,99 2017-04-01,16,29588,14,85 2017-05-01,28,30856,17,98 2017-06-01,16,30544,15,85 Reading csv files Data summaries Bacteremia Hospital acquired and all cause bacteremias and 30 days mortality File: bacteremia.csv Variables: month (date): month of infection ha_infections (numeric): number of hospital acquired infections risk_days (numeric): number of patient days without infection deaths (numeric): 30-day mortality after all-cause infection patients (numeric): number of patients with all-cause infection Blood pressure Daily measurements of blood pressure and resting pulse. File: blood_pressure.csv Variables: date (date): date of measurement systolic (numeric): systolic blood pressure (mm Hg) diastolic (numeric): diastolic blood pressure (mm Hg) pulse (numeric): resting pulse (beats per minute) Clostridioides difficile infections Hospital acquired C. diff. infections File: cdiff.csv Variables: month (date): first day of month cases (numeric): number of cases risk_days (numeric): number of patient days without infection Ceasearian section delay Time to grade 2 C-section File: csection_delay.csv Variables: datetime (datetime): date and time of delivery month (date): first day of month delay (numeric): time in minutes between decision and delivery Emergency admission mortality 7-day mortality after emergency admission File: emergency_admission.csv Variables: month (date): first day of month deaths (numeric): number of deaths within 7 days after emergency admission admissions (numeric): number of emergency admissions On-time CT Patients with acute abdomen CT scanned within 3 hours after arrival File: ontime_ct.csv Variables: month (date): first day of month ct_on_time (numeric): number of patients scanned within 3 hours cases (numeric): number of patients with acute abdomen Radiation doses Radiation doses used for renography File: renography_doses.csv Variables: date (date): date of renography week (date): first day of week dose (numeric): radiation dose in megabequerel Robson group 1 births Outcomes and complications of Robson group 1 births: first time pregnancy, single baby, head first, gestational age at least 37 weeks. File: robson1_births.csv Variables: datetime (datetime): data and time of birth biweek (date): first day of biweekly period csect (logical): delivery by C-section cup (logical): delivery by vacuum extraction length (numeric): baby length in cm weight (numeric): baby weight in kg apgar (numeric): apgar score at 5 minutes ph (numeric): arterial umbilical chord pH asphyxia (logical): ph &lt; 7 or missing ph and apgar &lt; 7 "],["stat-concepts.html", "B Basic Statistical Concepts", " B Basic Statistical Concepts "],["diagnostics.html", "C Two types of errors when using SPC C.1 Quantifying diagnostic errors of SPC charts", " C Two types of errors when using SPC Classifying variation into common cause or special cause is the primary focus of statistical process control methodology. In practice, this classification is subject to two types of error which can be compared to an imperfect screening test that sometimes shows a patient has disease when in fact the patient is free from disease (false positive), or the patient is free from disease when in fact the patient has disease (false negative). Error 1 (false positive): Treating an outcome resulting from a common cause as if it were a special cause and (wrongly) seeking to find a special cause, when in fact the cause is the underlying process. Error 2 (false negative): Treating an outcome resulting from a special cause as if it were a common cause and so (wrongly) overlooking the special cause. Either mistake can cause losses. If all data were treated as special cause variation, this maximises the losses from mistake 1. And if all data were treated as common cause variation, this maximises the losses from mistake 2. Unfortunately, in practice it is impossible to reduce both mistakes to zero. Shewhart concluded that it was best to make either mistake only rarely and that this depended largely upon the costs of looking unnecessarily for special cause variation. Using mathematical theory, empirical evidence, and pragmatism, he argued that setting control limits to ± three standard deviations from the mean provides a reasonable balance between making the two types of mistakes. C.1 Quantifying diagnostic errors of SPC charts ARL Likelihood ratios "],["r-intro.html", "D Introduction to R", " D Introduction to R "],["runs-limits.html", "E Critical Values for Longest Runs and Number of Crossings", " E Critical Values for Longest Runs and Number of Crossings Number of useful observations Upper limit for longest run Lower limit for number of crossings 10 6 2 11 6 2 12 7 3 13 7 3 14 7 4 15 7 4 16 7 4 17 7 5 18 7 5 19 7 6 20 7 6 21 7 6 22 7 7 23 8 7 24 8 8 25 8 8 26 8 8 27 8 9 28 8 9 29 8 10 30 8 10 31 8 11 32 8 11 33 8 11 34 8 12 35 8 12 36 8 13 37 8 13 38 8 14 39 8 14 40 8 14 41 8 15 42 8 15 43 8 16 44 8 16 45 8 17 46 9 17 47 9 17 48 9 18 49 9 18 50 9 19 51 9 19 52 9 20 53 9 20 54 9 21 55 9 21 56 9 21 57 9 22 58 9 22 59 9 23 60 9 23 61 9 24 62 9 24 63 9 25 64 9 25 65 9 25 66 9 26 67 9 26 68 9 27 69 9 27 70 9 28 71 9 28 72 9 29 73 9 29 74 9 29 75 9 30 76 9 30 77 9 31 78 9 31 79 9 32 80 9 32 81 9 33 82 9 33 83 9 34 84 9 34 85 9 34 86 9 35 87 9 35 88 9 36 89 9 36 90 9 37 91 10 37 92 10 38 93 10 38 94 10 39 95 10 39 96 10 39 97 10 40 98 10 40 99 10 41 100 10 41 "],["resources.html", "F Resources and Further Readings", " F Resources and Further Readings books websites communities R packages "],["references.html", "References", " References Anhøj, Jacob. 2015. “Diagnostic Value of Run Chart Analysis: Using Likelihood Ratios to Compare Run Chart Rules on Simulated Data Series.” PLoS ONE. https://doi.org/10.1371/journal.pone.0121349. ———. 2018. “qicharts2: Quality Improvement Charts for R.” JOSS. https://doi.org/10.21105/joss.0069. ———. 2024. Qicharts2: Quality Improvement Charts. https://CRAN.R-project.org/package=qicharts2. Anhøj, Jacob, and Anne Vingaard Olesen. 2014. “Run Charts Revisited: A Simulation Study of Run Chart Rules for Detection of Non-Random Variation in Health Care Processes.” PLoS ONE. https://doi.org/10.1371/journal.pone.0113825. Anhøj, Jacob, and Tore Wentzel-Larsen. 2018. “Sense and Sensibility: On the Diagnostic Value of Control Chart Rules for Detection of Shifts in Time Series Data.” BMC Medical Research Methodology. https://doi.org/10.1186/s12874-018-0564-0. Chen, Zhenmin. 2010. “A Note on the Runs Test.” Model Assisted Statistics and Applications 5: 73–77. https://doi.org/10.3233/MAS-2010-0142. Goldratt, Eliyahu M., and Jeff Cox. 2022. The Goal: A Process of Ongoing Improvement, 3rd Edition. Routledge. Jeppegaard, Maria, Steen C. Rasmussen, Jacob Anhøj, and Lone Krebs. 2023. “Winter, Spring, Summer or Fall: Temporal Patterns in Placenta-Mediated Pregnancy Complications—an Exploratory Analysis.” Gynecol Obstet 309: 1991–98. https://doi.org/https://doi.org/10.1007/s00404-023-07094-6. Koetsier, A., S. N. van der Veer, K. J. Jager, N. Peek, and N. F. de Keizer. 2012. “Control Charts in Healthcare Quality Improvement.” Methods of Information in Medicine. https://doi.org/10.3414/ME11-01-0055. Langley, Gerald J, Ronald D Moen, Kevin M Nolan, Thomas W Nolan, Clifford L Norman, and Lloyd P Provost. 2009. The Improvement Guide. San Fracisco, CA: Jossey-bass. Lilford, Richard, Mohammed A Mohammed, David Spiegelhalter, and Richard Thomson. 2004. “Use and Misuse of Process and Outcome Data in Managing Performance of Acute Medical Care: Avoiding Institutional Stigma.” The Lancet 363: 1147–54. https://doi.org/https://doi.org/10.1016/S0140-6736(04)15901-1. Mohammed, M A. 2024. Statistical Process Control. Elements of Improving Quality and Safety in Healthcare. Cambridge University Press. https://www.cambridge.org/core/elements/statistical-process-control/60B6025BF62017A9A203960A9E223C10. Mohammed, M A, Rouse Cheng KK, and T Marshall. 2001. “Bristol, Shipman, and Clinical Governance: Shewhart’s Forgotten Lessons.” Lancet 357. https://doi.org/10.1016/s0140-6736(00)04019-8. Mohammed, M A, Anthony Rathbone, Paulette Myers, Divya Patel, Helen Onions, and Andrew Stevens. 2004. “An Investigation into General Practitioners Associated with High Patient Mortality Flagged up Through the Shipman Inquiry: Retrospective Analysis of Routine Data.” BMJ 328 (7454): 1474–77. https://doi.org/10.1136/bmj.328.7454.1474. Mohammed, M A, P Worthington, and W H Woodall. 2008. “Plotting Basic Control Charts: Tutorial Notes for Healthcare Practitioners.” BMJ Qual Saf 17 (2): 137–45. https://doi.org/10.1136/qshc.2004.012047. Montgomery, Douglas C. 2020. Introduction to Statistical Quality Control, Eighths Ed. Wiley. Rogers, Chris A., Barnaby C. Reeves, Massimo Caputo, J. Saravana Ganesh, Robert S. Bonser, and Gianni D. Angelini. 2004. “Control Chart Methods for Monitoring Cardiac Surgical Performance and Their Interpretation.” The Journal of Thoracic and Cardiovascular Surgery 128: 811–19. https://doi.org/https://doi.org/10.1016/j.jtcvs.2004.03.011. Schilling, Mark F. 2012. “The Surprising Predictability of Long Runs.” Mathematics Magazine 85: 141–49. https://doi.org/10.4169/math.mag.85.2.141. Shewhart, Walther A. 1931. Economic Control of Quality of Manufactured Product. New York: D. Van Nostrand Company. Thor, Johan, Jonas Lundberg, Jakob Ask, Jesper Olsson, Cheryl Carli, Karin Pukk Härenstam, and Mats Brommels. 2007. “Application of Statistical Process Control in Healthcare Improvement: Systematic Review.” BMJ Qual Saf 16: 387–99. https://doi.org/10.1136/qshc.2006.022194. Western Electric Company. 1956. Statistical Quality Control Handbook. New York: Western Electric Company inc. Wheeler, Donald J. 2000. Understanding Variation – the Key to Managing Chaos. Knoxville, Tennessee: SPC Press. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
