---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Understanding SPC Charts {#charts-intro}


```{r, echo=FALSE}
knitr::opts_chunk$set(fig.asp = 3/5,
                      echo = FALSE,
                      dev     = 'svg')
library(kableExtra)
library(qicharts2)

options(qic.clshade = F)

source('R/stdchart.R', local = knitr::knit_global())
source('R/load_data.R', local = knitr::knit_global())
```

So now that we have seen an intuitive demonstration of common and special cause variation using handwritten letters, how can we use these ideas in practice with data from healthcare processes? In practice this involves the production of SPC charts that depicts the voice or behaviour of a process over time and with the aid of statistical theory, shows if the process is consistent with common or special cause variation. Such charts are known as SPC charts, control charts or process behaviour charts.

SPC charts are point-and-line plots of data over time. In practice, SPC charts are operational definitions for identifying common and special cause variation. An operational definition is one which is designed to be practical and useful and leads to agreement between different people.

```{r spc-fig0, fig.cap='Control chart of systolic blood pressure'}
qic(systolic, 
    chart = 'i',
    title = 'Systolic blood pressure',
    ylab = 'mmHg',
    xlab = 'Day #')
```

Figure \@ref(fig:spc-fig0) is a control charts of daily measurements of blood pressure. One data point (#6, marked by a red dot) is positioned so far from the rest that it triggers a signal suggesting that this measurement represents a special cause.

Special causes are signalled by unusual patterns in data. By "unusual" we mean something that is unlikely to have happened purely by chance, like a freak data point. Common cause variation is simply noise. The absence of signals of special cause variation is evidence that the behaviour of the process is consistent with common cause variation. The presence of signals is consistent with special cause variation.

There are many different types of control charts and the chart to be used is determined mostly by the type of data to be plotted. But regardless of the type of data, SPC charts look the same and are interpreted the same by employing a set of statistical tests (or rules) to help identify unusual patterns.

In this chapter we will introduce the most common types of control charts that are used in healthcare and their use cases. In the next chapter (\@ref(testing)) we discuss different rules for identifying unusual patterns in data. In Part 2 of this book we will go into detail on how to do the actual calculations involved.

## Anatomy and physiology of SPC charts

Shewhart's brilliant invention was the idea of control limits to show the boundaries of the common cause variation in data. Data points that lie between the lines represent common cause variation and data points outside the limits represent special cause variation.

```{r spc-fig1, fig.cap='Standardised control chart. SD = standard deviation; CL = centre line; LCL = lower control limit; UCL = upper control limit', echo=FALSE}
set.seed(33)
y1 <- y2 <- y3 <- rnorm(24)

stdchart(y1)
```

Figure \@ref(fig:spc-fig1) shows a standardised Shewhart control chart made from random numbers from a normal distribution with mean = 0 and standard deviation = 1. The x-axis represents time or order, and the y-axis represents the indicator values. The dots connected with straight lines show the data values in the order they were sampled. The data included in each data point are called subgroups. The horizontal centre line (CL) shows the overall mean of the data values, and the lower (LCL) and upper (UCL) control lines show the boundaries of the common cause variation. Together LCL and UCL are often referred to as 3-sigma limits.

We see that the data points are distributed fairly symmetrically around the centre line, and that most data points are close to the centre. As we move away from the centre line, data become rarer. 
The control limits are positioned so that nearly all data points from a common cause process with fall between them. Conversely, data points outside the limits will most likely represent special causes.

Based on empirical evidence from designed experiments involving real life data Shewhart found that in practice most process data are found within three standard deviations from the process centre. This is especially true when data, as in Figure  \@ref(fig:spc-fig1), come from a normal distribution, where the 3-sigma limits are expected to contain over 99.7% of data. Consequently, the chance of any particular data point being outside the limits purely by chance is about three out of a thousand. Thus, in a control chart with a total of 20 data points the chance of *all* data points being within the control limits is about 95% (1 - 0.997^20^).

But before we go down that rabbit hole we must realise that these theoretical considerations were rejected by Shewhart who found that most real-life data are not normally distributed. Shewhart argued that the choice of 3-sigma limits was made simply because "it works" (@shewhart1931, p. 18). By this he meant that 3-sigma limits strike the best balance between finding or overlooking special causes regardless of the type and distribution of data. More on this later.

It is important to realise that the SD in question is that of the common cause variation, not the overall, pooled SD that would include both the common and any special cause variation. The procedure for calculating -- or rather estimating -- the common cause SD depends on the type of data involved.

## Some common types of control charts -- The Magnificient Seven


As described above, the control limits are positioned three times the common cause SD above and below the centre line. Thus, all types of control charts follow this general formula for control lines:

$$CL \pm 3SD$$

So to construct a control chart, all we need to know is how to find the process standard deviation. As mentioned before, we do *not* use the overall SD of all the data as this would include any variation due to special causes and inflate the control limits. Instead we use a pooled average of the *within* subgroup SDs, which in turn depend on the type of data involved. The impatient reader may find the formulas for constructing control limits in Table \@ref(tab:limits-tab1) later in the book.

Generally, data come in two flavours: count data and measurement data.

### Counts

Counts are positive integers that represent counts of events or cases. The distinction between events and cases is important but somewhat subtle. **Events** are phenomena that happen in time and space, for example patient falls. **Cases** are units with (or without) a certain property, for example patients who fell. 

When counting falls as events, every fall counts. When counting patients as units who fell, every patient counts -- but only once regardless of how many times each patient fell. 

Both events and cases may be expressed as ratios, that is counts divided by some denominator (area of opportunity). Events may be expressed as rates, that is number of events per unit of time, for example number of falls per 1,000 patient days. Cases may be expressed as proportions, that is number of cases per total number of cases and non-cases, for example the proportion (or percentage) of patients who fell one or more times.

Notice that with rates the denominator is in units of time, which is a continuous variable and represents something distinctly different from the numerator. With proportions the numerator and denominator are counts of the same thing, for example patients -- only the numerator is a subset of the denominator. Consequently, with proportions the numerators cannot be larger than the denominators.

The most common chart types for count data are:

* **C chart**: count of events, e.g. number of patient falls.
* **U chart**: event rates, e.g. number of patient falls per unit of time.
* **P chart**: case proportions, e.g. proportion of patients who fell.

### Measurements

Measurements are data that are measured on continuous scales and may have decimals, for example blood pressure, height and weight, or waiting times.

As an example, take waiting or "door-to-needle" times. These may be plotted as either **individual** times where each data point (subgroup) represents one patient or as **average** time for all patients in a certain period of time, for example an hour, day, week, or month.

When plotting individual measurement data we use the I chart (aka the X chart). When plotting the average of multiple measurement per subgroup we use the X-bar chart.

Sometimes it is also useful to plot a chart of the within subgroup SDs. For this we use the moving range (MR) chart together with the I chart and the S chart together with the X-bar chart. So for measurement data we have:

* **I and MR charts**: individual measurement, subgroup size = 1.
* **X-bar and S charts**: multiple measurements, subgroup size > 1.

## Common SPC charts in summary

In summary, a Shewhart control chart is a point-and-line plot of data over time with three added horizontal lines: the centre line representing the overall mean of data and the lower and upper control lines representing the limits of the natural process variation.

While there are many types of SPC charts for different types of data they all look and behave the same. In this chapter we introduced the most common types used in healthcare, The Magnificient Seven, and their use cases.

When choosing the right chart we must first decide what type of data we have. For count data there are three common types: C, U, and P charts for event counts, event rates, and proportions respectively. For measurement data we have I and X-bar charts for individual measurements and averages respectively. MR and S charts plot estimates of the within subgroup standard deviation and are often plotted alongside I and X-bar charts.

In the next chapter we will discuss different techniques and rules used to test for signals of special causes, and we will suggest a set of rules that have been thoroughly studied and validated and provide a high sensitivity to special cause variation while keeping the false alarm rate at a reasonable level.
